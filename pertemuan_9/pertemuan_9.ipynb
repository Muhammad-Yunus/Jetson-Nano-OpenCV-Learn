{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pertemuan 9\n",
    "- Image Pyramid\n",
    "    - Gaussian Pyramid \n",
    "    - Laplacian Pyramid\n",
    "    - CUDA Implementation\n",
    "- Image Gradient\n",
    "    - Sobel and Scharr Derivatives \n",
    "    - Laplacian Derivatives \n",
    "    - CUDA Implementation\n",
    "___\n",
    "### Maximizing Jetson Nano Perfomance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sudo nvpmodel -m 0\n",
    "# sudo jetson_clocks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# check OpenCV Version\n",
    "\n",
    "cv2.__version__"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 1. Image Pyramid\n",
    "\n",
    "<img src=\"resource/Pyramids.png\" style=\"width:400px\"></img>\n",
    "- An image pyramid is a collection of images - all arising from a single original image - that are successively downsampled until some desired stopping point is reached.\n",
    "- Although there is a *geometric transformation* function in OpenCV that -literally- resize an image (`cv2.resize()`), in this section we will use of Image Pyramids, which are widely applied in a huge range of vision applications.\n",
    "- There are two common kinds of image pyramids:\n",
    "    - **Gaussian pyramid**: Used to **downsample** & **upsampled** images\n",
    "    - **Laplacian pyramid**: Used to reconstruct an **upsampled** image from an image lower in the pyramid (with less resolution)<br><br><br><br>\n",
    "___\n",
    "## 1.1 Gaussian Pyramid\n",
    "- Imagine the pyramid as a set of layers in which the higher the layer, the smaller the size.\n",
    "- Every layer is numbered from bottom to top, so layer ($i+1$) (denoted as $G_i+1$ is smaller than layer $i ( G_i)$.<br><br>\n",
    "<img src=\"resource/Pyramids_Tutorial_Pyramid_Theory.png\" style=\"width:400px\"></img><br><br><br>\n",
    "\n",
    "- To produce layer ($i+1$) in the Gaussian pyramid, we do the following:\n",
    "    - **Convolve** $G_i$ with a *Gaussian kernel*:<br>\n",
    "    $\\frac{1}{16} \\begin{bmatrix} 1 & 4 & 6 & 4 & 1 \\\\ 4 & 16 & 24 & 16 & 4 \\\\ 6 & 24 & 36 & 24 & 6 \\\\ 4 & 16 & 24 & 16 & 4 \\\\ 1 & 4 & 6 & 4 & 1 \\end{bmatrix}$\n",
    "    - Remove every even-numbered row and column.   \n",
    "- The resulting image will be exactly *one-quarter* the area of its predecessor. Iterating this process on the input image $G_0$ (original image) produces the entire pyramid.\n",
    "- The procedure above was useful to **downsample** an image. What if we want to make it bigger?\n",
    "    - First, **upsize** the image to twice the original in each dimension, with the new even rows and\n",
    "    - Perform a**convolution** with the same kernel shown above (multiplied by 4) to approximate the values of the \"missing pixels\"\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Downsampling and upsampling method in OpenCV is used `cv2.pyrUp(img, dstsize, borderType)` and `cv2.pyrDown(img, dstsize, borderType)`\n",
    "- where :\n",
    "    - `img` : input image\n",
    "    - `dstsize` : image destination size, default ($0.5 w, 0.5 h$) for downscale, ($2w, 2h$) for upscale.\n",
    "    - `borderType` :\n",
    "        - `cv2.BORDER_DEFAULT`\n",
    "        - `cv2.BORDER_CONSTANT`\n",
    "        - `cv2.BORDER_REPLICATE`\n",
    "        - `cv2.BORDER_REFLECT`\n",
    "        - `cv2.BORDER_WRAP`\n",
    "        - `cv2.BORDER_ISOLATED`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "## EXAMPLE 1 | Downscale Image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "h, w, c = img.shape\n",
    "\n",
    "# apply down scaling to (0.5w, 0.5h)\n",
    "img_PD = cv2.pyrDown(img, dstsize=(w//2, h//2))\n",
    "\n",
    "# show result\n",
    "cv2.imshow(\"pyramid downscale 1/2\", img_PD)\n",
    "cv2.imshow(\"original\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EXAMPLE 2 | Upscale Image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "h, w, c = img.shape\n",
    "\n",
    "# apply up scaling to (2w, 2h)\n",
    "img_PU = cv2.pyrUp(img, dstsize=(w*2, h*2))\n",
    "\n",
    "# show result\n",
    "cv2.imshow(\"pyramid upscale 2x\", img_PU)\n",
    "cv2.imshow(\"original\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EXAMPLE 3 | Downscale & Upscale Image by press key"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "while True :\n",
    "    h, w, c = img.shape\n",
    "    # show image\n",
    "    cv2.imshow(\"Result Window\", img)\n",
    "    \n",
    "    key = cv2.waitKey(0)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    elif key == ord('i'):\n",
    "        # apply up scaling to (2w, 2h)\n",
    "        img = cv2.pyrUp(img, dstsize=(w*2, h*2))\n",
    "        print ('Zoom In: Image x 2')\n",
    "        \n",
    "    elif key == ord('o'):\n",
    "        # apply down scaling to (0.5w, 0.5h)\n",
    "        img = cv2.pyrDown(img, dstsize=(w//2, h//2))\n",
    "        print ('Zoom Out: Image / 2')\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 1.2 Laplacian Pyramid\n",
    "\n",
    "- **Laplacian Pyramid** can be used for **edge detection**.\n",
    "- $i$ layer on **Laplacian Pyramid** ($L_i$) created by **Gaussian Pyramid** $i$ ($G_i$) substracted by `cv2.pyrUp()` for Gaussian Pyramid layer in $i + 1$ (($G_{i+1}$)).<br><br>\n",
    "$L_i = G_i - pyrUp(G_{i+1})$<br><br>\n",
    "<img src=\"resource/Laplacian-Pyramids.png\" style=\"width:400px\"></img><br>\n",
    "*Example of 3 stage Laplacian Pyramid* "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EXAMPLE 4 | Apply Laplacian Pyramid (Single Stage)\n",
    "<img src=\"resource/Laplacian-Pyramids-1.png\" style=\"width:500px\"></img>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "GP_0 = cv2.imread(\"lena.jpg\") # 512x512\n",
    "\n",
    "GP_1 = cv2.pyrDown(GP_0) # 256x256 --> downscale (gaussian pyramid)\n",
    "LP_0 = cv2.subtract(GP_0, cv2.pyrUp(GP_1)) # 512x512 --> laplacian pyramid\n",
    "\n",
    "# show result\n",
    "cv2.imshow(\"GP 0\", GP_0)\n",
    "cv2.imshow(\"GP 1\", GP_1)\n",
    "cv2.imshow(\"LP 0\", LP_0)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EXAMPLE 4 | Apply Laplacian Pyramid (3 Stage)\n",
    "<img src=\"resource/Laplacian-Pyramids.png\" style=\"width:500px\"></img>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# define empty list of all Gaussian Pyramid Image\n",
    "GP_list = []\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "# load Original Image\n",
    "GP = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(GP[:,:,::-1])\n",
    "plt.title(GP.shape)\n",
    "\n",
    "# Insert Original Image as Base Gaussian Pyramid (512x512)\n",
    "GP_list.append(GP) \n",
    "\n",
    "\n",
    "for i in range (2, 5): # --> i : {2, 3, 4}\n",
    "\n",
    "    # Apply Gaussian Pyramid & Append to list\n",
    "    GP = cv2.pyrDown(GP)\n",
    "    GP_list.append(GP)\n",
    "\n",
    "    # show image\n",
    "    plt.subplot(1, 4, i)\n",
    "    plt.imshow(GP[:,:,::-1])\n",
    "    plt.title(GP.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- On above implementation, we have, <br><br>\n",
    "    $GP_0$ : 512x512 (original image)<br>\n",
    "    $GP_1$ : 256x256 <br>\n",
    "    $GP_2$ : 128x128 <br>\n",
    "    $GP_3$ : 64x64 <br><br>\n",
    "- Next, try to calculate $LP_i$, where $LP_i = GP_i - pyrUp(GP_{i+1})$, <br><br>\n",
    "    $LP_0$ : 64x64 (lowest GP image $GP_3$) <br>\n",
    "    $LP_1$ : 128x128 ($GP_2 - pyrUp(GP_3)$) <br>\n",
    "    $LP_2$ : 256x256 ($GP_1 - pyrUp(GP_2)$) <br>\n",
    "    $LP_3$ : 512x512 ($GP_0 - pyrUp(GP_1)$) <br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "LP = GP_list[-1] # insert lower GP image (index -1) to LP\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(LP[:,:,::-1])\n",
    "plt.title(LP.shape)\n",
    "\n",
    "for i in range(-2, -5, -1): # ---> i : {-2, -3, -4}\n",
    "    LP =  cv2.subtract(GP_list[i], cv2.pyrUp(GP_list[i+1])) # GPi - pyrUp(GPi+1)\n",
    "\n",
    "    # show result\n",
    "    plt.subplot(1, 4, -1*i)\n",
    "    plt.imshow(LP[:,:,::-1])\n",
    "    plt.title(LP.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "## IMPLEMENTATION : Image Pyramid for Image Stitching\n",
    "\n",
    "- Simple Striching using Numpy slicing (just for comparion)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# VERTICAL STITCHING (NUMPY)\n",
    "\n",
    "# load image img1 & img2 (img1 & img2 have the same size)\n",
    "img1 = cv2.imread(\"apple.jpg\")\n",
    "img2 = cv2.imread(\"orange.jpg\")\n",
    "\n",
    "h, w, c = img1.shape\n",
    "print(h,w,c)\n",
    "\n",
    "# create \n",
    "result = np.zeros_like(img1) # create black image with size & type similar to img1\n",
    "result[:, :w//2] = img1[:, :w//2] # fill left side result matrix by left side img1\n",
    "result[:, w//2:] = img2[:, w//2:] # fill right side result matrix by right side img2\n",
    "\n",
    "# show result\n",
    "cv2.imshow(\"stiching image\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# HORIZONTAL STITCHING (NUMPY)\n",
    "\n",
    "# load image img1 & img2 (img1 & img2 have the same size)\n",
    "img1 = cv2.imread(\"apple.jpg\")\n",
    "img2 = cv2.imread(\"orange.jpg\")\n",
    "\n",
    "h, w, c = img1.shape\n",
    "print(h,w,c)\n",
    "\n",
    "# create \n",
    "result = np.zeros_like(img1) # create black image with size & type similar to img1\n",
    "result[:h//2, :] = img1[:h//2, :] # fill upper side result matrix by left side img1\n",
    "result[h//2:, :] = img2[h//2:, :] # fill lower side result matrix by right side img2\n",
    "\n",
    "# show result\n",
    "cv2.imshow(\"stiching image\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# NOTE\n",
    "# Simple image stitching using numpy may not look good due to discontinuities between images."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Simple Image Stitching using Image Pyramid"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# VERTICAL STITCHING (IMAGE PYRAMID)\n",
    "\n",
    "# load image img1 & img2 (img1 & img2 have the same size)\n",
    "img1 = cv2.imread(\"apple.jpg\")\n",
    "img2 = cv2.imread(\"orange.jpg\")\n",
    "\n",
    "# Apply Gausian Pyramid to Image 1 and Image 2 and store into GP1_list & GP2_list\n",
    "GP1 = img1.copy()\n",
    "GP1_list = [GP1] \n",
    "for i in range (6):\n",
    "    GP1 = cv2.pyrDown(GP1)\n",
    "    GP1_list.append(GP1)\n",
    "\n",
    "GP2 = img2.copy()\n",
    "GP2_list = [GP2] \n",
    "for i in range (6):\n",
    "    GP2 = cv2.pyrDown(GP2)\n",
    "    GP2_list.append(GP2)\n",
    "    \n",
    "# Apply Laplacian Pyramid to Image 1 and Image 2 to generate Edge Image and store into LP1_list & LP2_list\n",
    "LP1_list = [GP1_list[-1]]  # insert lower GP1 image (index -1) to LP1\n",
    "for i in range (-2, -7, -1): # ---> i : {-2, -3, -4, -5, -6}\n",
    "    LP1 =  cv2.subtract(GP1_list[i], cv2.pyrUp(GP1_list[i+1])) # GPi - pyrUp(GPi+1)\n",
    "    LP1_list.append(LP1)\n",
    "    \n",
    "LP2_list = [GP2_list[-1]] # insert lower GP2 image (index -1) to LP2\n",
    "for i in range (-2, -7, -1): # ---> i : {-2, -3, -4, -5, -6}\n",
    "    LP2=  cv2.subtract(GP2_list[i], cv2.pyrUp(GP2_list[i+1])) # GPi - pyrUp(GPi+1)\n",
    "    LP2_list.append(LP2)\n",
    "\n",
    "# Stithing the laplacian image for all stage\n",
    "LS = [] \n",
    "for L1, L2 in zip(LP1_list, LP2_list):\n",
    "    h, w, c = L1.shape\n",
    "\n",
    "    result = np.zeros_like(L1) # create black image with size & type similar to Laplacian Image 1\n",
    "    result[:h//2, :] = L1[:h//2, :] # fill upper side result matrix by left side Laplacian Image 1\n",
    "    result[h//2:, :] = L2[h//2:, :] # fill lower side result matrix by right side Laplacian Image 2\n",
    "    LS.append(result)\n",
    "\n",
    "\n",
    "# Add all stiched image into a single image called 'output'\n",
    "output = LS[0]\n",
    "for i in range(1, 6):\n",
    "    output = cv2.add(cv2.pyrUp(output), LS[i]) # output_i = pyrUp(output_i-1) + LSi\n",
    "    \n",
    "\n",
    "cv2.imshow(\"stiching image pyramid\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "## PERFORMANCE COMPARIOSN EDGE DETECTION \n",
    "## (Canny Edge Detection vs Morphological Gradient vs Laplacian Pyramid)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EDGE DETECTION -- MORPHOLOGICAL GRADIENT\n",
    "\n",
    "times =[]\n",
    "for i in range (100) :\n",
    "    e1 = cv2.getTickCount()\n",
    "    # load image\n",
    "    img = cv2.imread('number_plate.jpg')\n",
    "\n",
    "    # convert to gray\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # apply morphological gradient with kernel 3x3\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    gradient = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel, iterations = 1)\n",
    "\n",
    "    # apply simple thresholding TOZERO \n",
    "    ret, thresh = cv2.threshold(gradient, 0, 255, cv2.THRESH_TOZERO + cv2.THRESH_OTSU)\n",
    "\n",
    "    # find contour & draw contour from binary image\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    for cnt in contours:\n",
    "        cv2.drawContours(img, [cnt], -1, (0,0,255), 1)\n",
    "\n",
    "    e2 = cv2.getTickCount()\n",
    "    t = (e2 - e1)/cv2.getTickFrequency()\n",
    "    times.append(t)\n",
    "\n",
    "print(\"Average execution : %.5f s\" % np.array(times).mean())\n",
    "# show image\n",
    "cv2.imshow(\"Morphological Gradient\", gradient)\n",
    "cv2.imshow(\"Edge - Thresholding\", thresh)\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EDGE DETECTION -- CANNY EDGE DETECTION\n",
    "\n",
    "times =[]\n",
    "for i in range (100) :\n",
    "    e1 = cv2.getTickCount()\n",
    "    # load image\n",
    "    img = cv2.imread('number_plate.jpg')\n",
    "\n",
    "    # convert to gray\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # apply Canny Edge Detection\n",
    "    canny = cv2.Canny(gray, 220, 230)\n",
    "\n",
    "    # apply simple thresholding TOZERO \n",
    "    ret, thresh = cv2.threshold(canny, 0, 255, cv2.THRESH_TOZERO + cv2.THRESH_OTSU)\n",
    "\n",
    "    # find contour & draw contour from binary image\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    for cnt in contours:\n",
    "        cv2.drawContours(img, [cnt], -1, (0,0,255), 1)\n",
    "\n",
    "    e2 = cv2.getTickCount()\n",
    "    t = (e2 - e1)/cv2.getTickFrequency()\n",
    "    times.append(t)\n",
    "\n",
    "print(\"Average execution : %.5f s\" % np.array(times).mean())\n",
    "# show image\n",
    "cv2.imshow(\"Canny Edge Detection\", canny)\n",
    "cv2.imshow(\"Edge - Thresholding\", thresh)\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EDGE DETECTION -- CANNY LAPLACIAN PYRAMID\n",
    "times =[]\n",
    "for i in range (100) :\n",
    "    e1 = cv2.getTickCount()\n",
    "    # load image\n",
    "    img = cv2.imread('number_plate.jpg')\n",
    "\n",
    "    # convert to gray\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # apply Laplacian Pyramid\n",
    "    GP0 = cv2.pyrDown(gray) # --> downscale (gaussian pyramid)\n",
    "    GP1 = cv2.pyrDown(GP0) # --> downscale (gaussian pyramid)\n",
    "    LP0 = cv2.subtract(gray, cv2.pyrUp(GP0)) # --> laplacian pyramid\n",
    "    LP1 = cv2.subtract(gray, cv2.pyrUp(GP1)) # --> laplacian pyramid\n",
    "\n",
    "    # apply simple thresholding TOZERO \n",
    "    ret, thresh = cv2.threshold(LP, 0, 255, cv2.THRESH_TOZERO + cv2.THRESH_OTSU)\n",
    "\n",
    "    # find contour & draw contour from binary image\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    for cnt in contours:\n",
    "        cv2.drawContours(img, [cnt], -1, (0,0,255), 1)\n",
    "\n",
    "    e2 = cv2.getTickCount()\n",
    "    t = (e2 - e1)/cv2.getTickFrequency()\n",
    "    times.append(t)\n",
    "\n",
    "print(\"Average execution : %.5f s\" % np.array(times).mean())\n",
    "# show image\n",
    "cv2.imshow(\"Laplacian Pyramid\", LP)\n",
    "cv2.imshow(\"Edge - Thresholding\", thresh)\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## CUDA Implementation Image Pyramid\n",
    "- Method `cv2.cuda.pyrUp(src, dst)` and `cv2.cuda.pyrDown(src, dst)`\n",
    "- Where : \n",
    "    - `src` : image input CUDA Matrix \n",
    "    - `dst` : image input CUDA Matrix "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# load image in Host memory\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "h, w, c = img.shape\n",
    "\n",
    "# GPU memory initialization\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "up_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "up_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "down_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "down_GpuMat.create((w//2, h//2), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "laplacian_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "laplacian_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "\n",
    "# upload to GPU memory\n",
    "img_GpuMat.upload(img)\n",
    "\n",
    "# apply CUDA Gaussian Pyramid\n",
    "cv2.cuda.pyrDown(img_GpuMat, down_GpuMat)  # downscale\n",
    "cv2.cuda.pyrUp(down_GpuMat, up_GpuMat) # upscale\n",
    "\n",
    "# Apply Laplacian Pyramid\n",
    "cv2.cuda.subtract(img_GpuMat, up_GpuMat, laplacian_GpuMat)\n",
    "\n",
    "# download to host memory\n",
    "GP = down_GpuMat.download()\n",
    "LP = laplacian_GpuMat.download()\n",
    "\n",
    "# show image\n",
    "cv2.imshow(\"Gaussian Pyramid\", GP)\n",
    "cv2.imshow(\"Laplacian Pyramid\", LP)\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_____\n",
    "# 2. Image Gradient\n",
    "- An image gradient is a directional change in the intensity or color in an image. \n",
    "- The gradient of the image is one of the fundamental building blocks in image processing. \n",
    "- For example, the **Canny edge detector** uses image gradient for edge detection. \n",
    "- Image gradients can be used to extract information from images. \n",
    "- Gradient images are created from the original image (generally by convolving with a filter, one of the simplest being the Sobel filter) for this purpose.[WIKIPEDIA](https://en.wikipedia.org/wiki/Image_gradient) <br><br><br><br>\n",
    "- On the left, an intensity image of a cat. \n",
    "- In the center, a gradient image in the x direction measuring horizontal change in intensity. \n",
    "- On the right, a gradient image in the y direction measuring vertical change in intensity. \n",
    "- Gray pixels have a small gradient; black or white pixels have a large gradient.\n",
    "![](resource/image_grad.png) <br><br>\n",
    "\n",
    "- Two types of gradients, with blue arrows to indicate the direction of the gradient. Dark areas indicate higher values. <br>\n",
    "![](resource/Gradient.png) <br><br>\n",
    "- OpenCV provides three types of gradient filters or High-pass filters, **Sobel**, **Scharr** and **Laplacian**. We will see each one of them.\n",
    "<br><br><br>\n",
    "____\n",
    "## 2.1 Sobel and Scharr Derivatives\n",
    "- Sobel operators is a joint **Gausssian smoothing** plus **differentiation operation**, so it is **more resistant to noise**.\n",
    "- You can specify the direction of derivatives to be taken, vertical or horizontal (by the arguments, yorder and xorder respectively). \n",
    "- You can also specify the size of kernel by the argument ksize. \n",
    "- If `ksize = -1`, a 3x3 Scharr filter is used which gives better results than 3x3 Sobel filter. \n",
    "- Method `cv2.Sobel(img, ddepth, dx, dy, ksize)`\n",
    "- Where : \n",
    "    - `img` : input image\n",
    "    - `ddepth` : image destitation depth, should be `cv2.CV_32F` or `cv2.CV_64F`\n",
    "    - `dx` : order of the derivative x.\n",
    "    - `dy` : order of the derivative y.\n",
    "    - `ksize` : size of the extended Sobel kernel; it must be 1, 3, 5, or 7.\n",
    "\n",
    "## 2.2 Laplacian Derivatives\n",
    "- It calculates the Laplacian of the image given by the relation, $\\Delta src = \\frac{\\partial ^2{src}}{\\partial x^2} + \\frac{\\partial ^2{src}}{\\partial y^2}$ where each derivative is found using Sobel derivatives. \n",
    "- If `ksize = 1`, then following kernel is used for filtering: <br>\n",
    "![](resource/laplacian_dev.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "## EXAMPLE 1 : Sobel Derivative & Laplacian Derivative feature image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread('sudoku.jpg')\n",
    "\n",
    "# convert to gray\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# apply sobel derivative for X and Y direction with kernel size 5x5\n",
    "sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "# apply laplacian derivative\n",
    "laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "\n",
    "# show the result\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original') \n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(laplacian, cmap = 'gray')\n",
    "plt.title('Laplacian')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(sobelx, cmap = 'gray')\n",
    "plt.title('Sobel X')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(sobely, cmap = 'gray')\n",
    "plt.title('Sobel Y')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "## EXAMPLE 2 : Sobel Derivative & Laplacian Derivative to detect Edge \n",
    "- If you want to detect **both edges**, better option is to keep the output datatype to some higher forms, like `cv2.CV_16S`, `cv2.CV_64F` etc, \n",
    "- Take its **absolute value** and then convert back to `cv2.CV_8U`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE | Edge Detection, convert cv2.CV_64F to cv2.CV_8U image \n",
    "\n",
    "# load image\n",
    "img = cv2.imread('box_edge.png')\n",
    "\n",
    "# convert to gray\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# apply sobel derivative for X and Y direction with kernel size 5x5\n",
    "sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "# apply laplacian derivative\n",
    "laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "\n",
    "# Output dtype = cv2.CV_64F. Then take its absolute and convert to cv2.CV_8U\n",
    "sobelx = np.uint8(np.absolute(sobelx))\n",
    "sobely = np.uint8(np.absolute(sobely))\n",
    "laplacian = np.uint8(np.absolute(laplacian))\n",
    "\n",
    "# show the result\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original') \n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(laplacian, cmap = 'gray')\n",
    "plt.title('Laplacian')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(sobelx, cmap = 'gray')\n",
    "plt.title('Sobel X')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(sobely, cmap = 'gray')\n",
    "plt.title('Sobel Y')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE | Edge Detection, Set cv2.Sobel & cv2.Laplacian with ddepth cv2.CV_8U\n",
    "\n",
    "# load image\n",
    "img = cv2.imread('box_edge.png')\n",
    "\n",
    "# convert to gray\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# apply sobel derivative for X and Y direction with kernel size 5x5\n",
    "sobelx = cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize=5)\n",
    "sobely = cv2.Sobel(gray, cv2.CV_8U, 0, 1, ksize=5)\n",
    "\n",
    "# apply laplacian derivative\n",
    "laplacian = cv2.Laplacian(gray, cv2.CV_8U)\n",
    "\n",
    "\n",
    "# show the result\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original') \n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(laplacian, cmap = 'gray')\n",
    "plt.title('Laplacian')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(sobelx, cmap = 'gray')\n",
    "plt.title('Sobel X')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(sobely, cmap = 'gray')\n",
    "plt.title('Sobel Y')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "## CUDA Implementation Image Gradient\n",
    "### CUDA Sobel Derivative\n",
    "- Create Object using class `cv2.cuda.createSobelFilter(srcType, dstType, dx, dy, ksize)`\n",
    "    - `srcType` : Source image type. \n",
    "    - `dstType` : Destination array type. only supported until `cv2.CV_32F`.\n",
    "    - `dx` : Derivative order in respect of x.\n",
    "    - `dy` : Derivative order in respect of y.\n",
    "    - `ksize` : Size of the extended Sobel kernel. Possible values are 1, 3, 5 or 7.\n",
    "- Use method `.apply(src, dst)` to generate sobel derivative images.\n",
    "- Where : \n",
    "    - `src` : Input Image Matrix (GPU Mat)\n",
    "    - `dst` : Output Image Matrix (GPU Mat)<br><br><br>\n",
    "### CUDA Laplacian Derivative\n",
    "- Create Object using class `cv2.cuda.createLaplacianFilter(srcType, dstType, ksize)`\n",
    "    - `srcType` : Source image type.\n",
    "    - `dstType` : Destination array type. only supported until `cv2.CV_32F`.\n",
    "    - `ksize` : Size of the extended Sobel kernel. Only `ksize = 1` and `ksize = 3` are supported.\n",
    "- Use method `.apply(src, dst)` to generate sobel derivative images.\n",
    "- Where : \n",
    "    - `src` : Input Image Matrix (GPU Mat)\n",
    "    - `dst` : Output Image Matrix (GPU Mat)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# load image in Host memory\n",
    "img = cv2.imread(\"box_edge.png\")\n",
    "h, w, c = img.shape\n",
    "\n",
    "# GPU memory initialization\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_32FC3) # cv2.CV_32FC1 -> 32 float image 3 channel\n",
    "gray_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "gray_GpuMat.create((w, h), cv2.CV_32FC1) # cv2.CV_32FC1 -> 32 float image 1 channel\n",
    "sobelx_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "sobelx_GpuMat.create((w, h), cv2.CV_32FC1) # cv2.CV_32FC1 -> 32 float image 1 channel\n",
    "sobely_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "sobely_GpuMat.create((w, h), cv2.CV_32FC1) # cv2.CV_32FC1 -> 32 float image 1 channel\n",
    "laplacian_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "laplacian_GpuMat.create((w, h), cv2.CV_32FC1) # cv2.CV_32FC1 -> 32 float image 1 channel\n",
    "\n",
    "# Create object CUDA Image Gradient\n",
    "SobelX_obj = cv2.cuda.createSobelFilter(cv2.CV_32F, cv2.CV_32F, 1, 0, ksize=5)\n",
    "SobelY_obj = cv2.cuda.createSobelFilter(cv2.CV_32F, cv2.CV_32F, 0, 1, ksize=5)\n",
    "Laplacian_obj = cv2.cuda.createLaplacianFilter(cv2.CV_32F, cv2.CV_32F, ksize=3)\n",
    "\n",
    "# upload to GPU memory as 32 bit float image\n",
    "img_GpuMat.upload(img.astype(np.float32))\n",
    "\n",
    "# convert to grayscale\n",
    "cv2.cuda.cvtColor(img_GpuMat, cv2.COLOR_BGR2GRAY, gray_GpuMat)\n",
    "\n",
    "# apply CUDA Image Gradient\n",
    "SobelX_obj.apply(gray_GpuMat, sobelx_GpuMat)\n",
    "SobelY_obj.apply(gray_GpuMat, sobely_GpuMat)\n",
    "Laplacian_obj.apply(gray_GpuMat, laplacian_GpuMat)\n",
    "\n",
    "\n",
    "# download to host memory\n",
    "sobelx = sobelx_GpuMat.download()\n",
    "sobely = sobely_GpuMat.download()\n",
    "laplacian = laplacian_GpuMat.download()\n",
    "\n",
    "# show the result\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original') \n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(laplacian, cmap = 'gray')\n",
    "plt.title('Laplacian')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(sobelx, cmap = 'gray')\n",
    "plt.title('Sobel X')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(sobely, cmap = 'gray')\n",
    "plt.title('Sobel Y')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# Source\n",
    "- [https://docs.opencv.org/4.5.1/d4/d1f/tutorial_pyramids.html](https://docs.opencv.org/4.5.1/d4/d1f/tutorial_pyramids.html)\n",
    "- [https://en.wikipedia.org/wiki/Pyramid_(image_processing)](https://en.wikipedia.org/wiki/Pyramid_(image_processing))\n",
    "- [https://docs.opencv.org/4.5.1/d5/d0f/tutorial_py_gradients.html](https://docs.opencv.org/4.5.1/d5/d0f/tutorial_py_gradients.html)\n",
    "- [https://en.wikipedia.org/wiki/Image_gradient](https://en.wikipedia.org/wiki/Image_gradient)\n",
    "- [https://docs.opencv.org/3.4.15/d2/d77/classcv_1_1cuda_1_1ImagePyramid.html](https://docs.opencv.org/3.4.15/d2/d77/classcv_1_1cuda_1_1ImagePyramid.html)\n",
    "- [https://docs.opencv.org/4.5.3/dc/d66/group__cudafilters.html#ga53126e88bb7e6185dcd5628e28e42cd2](https://docs.opencv.org/4.5.3/dc/d66/group__cudafilters.html#ga53126e88bb7e6185dcd5628e28e42cd2)\n",
    "- [https://docs.opencv.org/4.5.3/dc/d66/group__cudafilters.html#gabf85fe61958bb21e93211a6fcc7c5c3b](https://docs.opencv.org/4.5.3/dc/d66/group__cudafilters.html#gabf85fe61958bb21e93211a6fcc7c5c3b)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}