{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Peretemuan 6\n",
    "- Contour - Part 2\n",
    "    - Contour Detection & Application\n",
    "    - CUDA Contour Detection \n",
    "- Hough Transform\n",
    "    - Hough line\n",
    "    - Hough Circle\n",
    "    - Hough Line Application\n",
    "    - Hough Transform CUDA\n",
    "\n",
    "___\n",
    "### Maximizing Jetson Nano Perfomance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sudo nvpmodel -m 0\n",
    "# sudo jetson_clocks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# check OpenCV Version\n",
    "\n",
    "cv2.__version__"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# draw_ped() function to draw bounding box with top labeled text\n",
    "\n",
    "\n",
    "def draw_ped(img, label, x0, y0, xt, yt, font_size=0.4, alpha=0.5, bg_color=(255,0,0), ouline_color=(255,255,255), text_color=(0,0,0)):\n",
    "    overlay = np.zeros_like(img)\n",
    "\n",
    "    y0, yt = max(y0 - 15, 0) , min(yt + 15, img.shape[0])\n",
    "    x0, xt = max(x0 - 15, 0) , min(xt + 15, img.shape[1])\n",
    "\n",
    "    (w, h), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_size, 1)\n",
    "    cv2.rectangle(overlay,\n",
    "                    (x0, y0 + baseline),  \n",
    "                    (max(xt, x0 + w), yt), \n",
    "                    bg_color, \n",
    "                    -1)\n",
    "    cv2.rectangle(img,\n",
    "                    (x0, y0 + baseline),  \n",
    "                    (max(xt, x0 + w), yt), \n",
    "                    ouline_color, \n",
    "                    2)\n",
    "    pts = np.array([[x0, y0 - h - baseline], # top left\n",
    "                    [x0 + w, y0 - h - baseline], # top right\n",
    "                    [x0 + w + 10, y0 + baseline], # bolom right\n",
    "                    [x0,y0 + baseline]]) # bottom left\n",
    "    cv2.fillPoly(img, [pts], ouline_color) # add label white fill\n",
    "    cv2.polylines(img, [pts], True, ouline_color, 2) # add label white border \n",
    "    cv2.putText(img, \n",
    "                label, \n",
    "                (x0, y0),                   \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "                font_size,                          \n",
    "                text_color,                \n",
    "                1,\n",
    "                cv2.LINE_AA) \n",
    "\n",
    "    img_blend = cv2.addWeighted(img, 1, overlay, alpha, 0.0)\n",
    "\n",
    "    return img_blend"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 1. Contour - Part 2\n",
    "## 1.1 Contour Detection & Application\n",
    "## 1.1.1 Visual Inspection based on Simple Threshold \n",
    "- Image sample :</br>\n",
    "<img src=\"part_b.jpg\" width=200></img></br></br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Example 1 : (part_b.jpg)\n",
    "# Find Contour using Simple Thresholding + Otsu's\n",
    "\n",
    "img = cv2.imread(\"part_b.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "__, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for cnt in contours : \n",
    "    cv2.drawContours(img, cnt, -1, (0,0,255), 3)\n",
    "\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(thresh, cmap=\"gray\")\n",
    "plt.title(\"Binary Image\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Result\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# As you can see, Simple thresholding using Otsu's method giving us not a good result.\n",
    "# This is happen because the original image has light ilumination in it.\n",
    "# the option is using using Range Thresholding (based color)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## 1.1.2 Visual Inspection Based On Range Thresholding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# convert RGB to HSV\n",
    "\n",
    "rgb = np.array([[[136,119,114]]], np.uint8)\n",
    "\n",
    "hsv=cv2.cvtColor(rgb, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "hsv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# define range of gray color in HSV\n",
    "lower_gray = np.array([0, 0, 20])\n",
    "upper_gray = np.array([180, 100, 150])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 2 : (part_b.jpg)\n",
    "# Detect Contour from Binary Image (Range Thresholding)\n",
    "\n",
    "img = cv2.imread(\"part_b.jpg\")\n",
    "\n",
    "# convert to hsv\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Threshold the HSV image to get only gray colors\n",
    "mask = cv2.inRange(hsv.copy(), lower_gray, upper_gray)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for cnt in contours : \n",
    "    cv2.drawContours(img, cnt, -1, (0,0,0), 3)\n",
    "\n",
    "plt.figure(figsize=(20,14))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.title(\"Binary Image\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Result\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 3 : (part_b.jpg)\n",
    "# Detect Contour from Binary Image (Range Thresholding) + \n",
    "# Background removal\n",
    "\n",
    "img = cv2.imread(\"part_b.jpg\")\n",
    "\n",
    "#convert to hsv\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Threshold the HSV image to get only gray colors\n",
    "mask = cv2.inRange(hsv.copy(), lower_gray, upper_gray)\n",
    "\n",
    "res = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for cnt in contours : \n",
    "    cv2.drawContours(res, cnt, -1, (255,0,0), 3)\n",
    "\n",
    "plt.figure(figsize=(20,14))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.title(\"Binary Image\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(res[:,:,::-1])\n",
    "plt.title(\"Result\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## 1.1.3 Visual Inspection add Contour Filtering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 4 : (part_b.jpg)\n",
    "# Detect Contour from Binary Image (Range Thresholding) + \n",
    "# Background removal + \n",
    "# Contour Filter by hierarchy\n",
    "\n",
    "img = cv2.imread(\"part_b.jpg\")\n",
    "\n",
    "#convert to hsv\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Threshold the HSV image to get only gray colors\n",
    "mask = cv2.inRange(hsv.copy(), lower_gray, upper_gray)\n",
    "\n",
    "res = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for cnt, hrcy in zip(contours, hierarchy[0]):\n",
    "\n",
    "    # Find All Extreme Outer Contour [BLUE]\n",
    "    if hrcy[3] == -1 :      \n",
    "        cv2.drawContours(res, cnt, -1, (255,0,0), 3)\n",
    "\n",
    "    # Find All child contour [GREEN]\n",
    "    if hrcy[3] != -1 and hrcy[2] == -1:      \n",
    "        cv2.drawContours(res, cnt, -1, (0,255,0), 3)\n",
    "\n",
    "plt.figure(figsize=(20,14))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.title(\"Binary Image\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(res[:,:,::-1])\n",
    "plt.title(\"Result\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 4 : (part_b.jpg)\n",
    "# Detect Contour from Binary Image (Range Thresholding) + \n",
    "# Background removal + \n",
    "# Contour Filter by hierarchy + \n",
    "# Contour Filter by Contour Property\n",
    "\n",
    "img = cv2.imread(\"part_b.jpg\")\n",
    "\n",
    "#convert to hsv\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Threshold the HSV image to get only gray colors\n",
    "mask = cv2.inRange(hsv.copy(), lower_gray, upper_gray)\n",
    "\n",
    "res = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for cnt, hrcy in zip(contours, hierarchy[0]):\n",
    "    # find contour Area & boungin Rect\n",
    "    area = cv2.contourArea(cnt)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # calculate aspectRatio & extent\n",
    "    aspectRatio = float(w)/h \n",
    "    rect_area = w*h\n",
    "    extent = float(area)/rect_area\n",
    "    \n",
    "    # filter a small contour\n",
    "    if area <= 200:\n",
    "        continue \n",
    "\n",
    "    # Find All Extreme Outer Contour [BLUE]\n",
    "    if hrcy[3] == -1 :   \n",
    "        # Find contour with aspec ration between 0.1~0.3 (vertical rect), with extent 0.4\n",
    "        if aspectRatio < 0.3 and aspectRatio > 0.1 and extent > 0.4:   \n",
    "            cv2.drawContours(res, cnt, -1, (255,0,0), 3)\n",
    "\n",
    "    # Find All child contour [GREEN]\n",
    "    if hrcy[3] != -1 :#and hrcy[2] == -1:   \n",
    "        # Find contour with aspec ration between 0.5~1.5 (near square), with extent 0.4\n",
    "        if aspectRatio < 1.5 and aspectRatio > 0.5 and extent > 0.4:     \n",
    "            cv2.drawContours(res, cnt, -1, (0,255,0), 3)\n",
    "\n",
    "plt.figure(figsize=(20,14))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.title(\"Binary Image\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(res[:,:,::-1])\n",
    "plt.title(\"Result\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## 1.1.4 Visual Inspection add Child Contour Counting for each Parent"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 5 : (part_b.jpg)\n",
    "# Detect Contour from Binary Image (Range Thresholding) + \n",
    "# Background removal + \n",
    "# Contour Filter by hierarchy + \n",
    "# Contour Filter by Contour Property\n",
    "# Count Child Contour for each parent\n",
    "\n",
    "img = cv2.imread(\"part_b.jpg\")\n",
    "\n",
    "#convert to hsv\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Threshold the HSV image to get only gray colors\n",
    "mask = cv2.inRange(hsv.copy(), lower_gray, upper_gray)\n",
    "\n",
    "res = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "object_contour = {}\n",
    "object_count = {}\n",
    "object_id = 0\n",
    "for cnt, hrcy in zip(contours, hierarchy[0]):\n",
    "    # find contour Area & boungin Rect\n",
    "    area = cv2.contourArea(cnt)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # calculate aspectRatio & extent\n",
    "    aspectRatio = float(w)/h \n",
    "    rect_area = w*h\n",
    "    extent = float(area)/rect_area\n",
    "    \n",
    "    # filter a small contour\n",
    "    if area <= 200:\n",
    "        continue \n",
    "    \n",
    "   # Find All Extreme Outer Contour [BLUE]\n",
    "    if hrcy[3] == -1 :   \n",
    "        # Find contour with aspec ration between 0.1~0.3 (vertical rect), with extent 0.4\n",
    "        if aspectRatio < 0.3 and aspectRatio > 0.1 and extent > 0.4:      \n",
    "            cv2.drawContours(res, cnt, -1, (255,0,0), 3)\n",
    "            \n",
    "            object_contour[\"object_%d\" % object_id] = cnt # insert parent contour\n",
    "            object_count[\"object_%d\" % object_id] = 0 # set initinal count 0\n",
    "            object_id += 1\n",
    "\n",
    "    # Find All child contour [GREEN]\n",
    "    if hrcy[3] != -1 : #and hrcy[2] == -1:   \n",
    "        # Find contour with aspec ration between 0.5~1.5 (near square), with extent 0.4\n",
    "        if aspectRatio < 1.5 and aspectRatio > 0.5 and extent > 0.4: \n",
    "            cv2.drawContours(res, cnt, -1, (0,255,0), 3)\n",
    "\n",
    "            for cnt_obj in object_contour:\n",
    "                # find the child contour on wich parrent contour\n",
    "                if cv2.pointPolygonTest(object_contour[cnt_obj], (x, y), measureDist=True) > 0 :\n",
    "                    object_count[cnt_obj] += 1\n",
    "\n",
    "plt.figure(figsize=(20,14))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.title(\"Binary Image\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(res[:,:,::-1])\n",
    "plt.title(\"Result\")\n",
    "\n",
    "print(object_count)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## 1.1.5 Visual Inspection add Draw_Ped() box & Threshold Counter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 6 : (part_b.jpg)\n",
    "# Detect Contour from Binary Image (Range Thresholding) + \n",
    "# Background removal + \n",
    "# Contour Filter by hierarchy + \n",
    "# Contour Filter by Contour Property\n",
    "# Count Child Contour for each parent\n",
    "# Draw_Ped on object\n",
    "\n",
    "img = cv2.imread(\"part_b.jpg\")\n",
    "\n",
    "#convert to hsv\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Threshold the HSV image to get only gray colors\n",
    "mask = cv2.inRange(hsv.copy(), lower_gray, upper_gray)\n",
    "\n",
    "res = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "object_contour = {}\n",
    "object_count = {}\n",
    "object_id = 0\n",
    "threshold_count = 22 # min number of child contour \n",
    "\n",
    "for cnt, hrcy in zip(contours, hierarchy[0]):\n",
    "    # find contour Area & boungin Rect\n",
    "    area = cv2.contourArea(cnt)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # calculate aspectRatio & extent\n",
    "    aspectRatio = float(w)/h \n",
    "    rect_area = w*h\n",
    "    extent = float(area)/rect_area\n",
    "    \n",
    "    # filter a small contour\n",
    "    if area <= 200:\n",
    "        continue \n",
    "    \n",
    "   # Find All Extreme Outer Contour [BLUE]\n",
    "    if hrcy[3] == -1 :   \n",
    "        # Find contour with aspec ration between 0.1~0.3 (vertical rect), with extent 0.4\n",
    "        if aspectRatio < 0.3 and aspectRatio > 0.1 and extent > 0.4:      \n",
    "            cv2.drawContours(res, cnt, -1, (255,0,0), 3)\n",
    "            \n",
    "            object_contour[\"object_%d\" % object_id] = cnt # insert parent contour\n",
    "            object_count[\"object_%d\" % object_id] = 0 # set initinal count 0\n",
    "            object_id += 1\n",
    "\n",
    "    # Find All child contour [GREEN]\n",
    "    if hrcy[3] != -1 : #and hrcy[2] == -1:   \n",
    "        # Find contour with aspec ration between 0.5~1.5 (near square), with extent 0.4\n",
    "        if aspectRatio < 1.5 and aspectRatio > 0.5 and extent > 0.4:    \n",
    "            cv2.drawContours(res, cnt, -1, (0,255,0), 3)\n",
    "\n",
    "            for obj_name in object_contour:\n",
    "                # find the child contour on wich parrent contour\n",
    "                if cv2.pointPolygonTest(object_contour[obj_name], (x, y), measureDist=True) > 0 :\n",
    "                    object_count[obj_name] += 1\n",
    "\n",
    "\n",
    "for obj_name in object_count:\n",
    "    x, y, w, h = cv2.boundingRect(object_contour[obj_name])\n",
    "    # check if number of child contour inside parrent less than threshold count \n",
    "    if object_count[obj_name] < threshold_count :\n",
    "        img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                    font_size=0.7, alpha=0.6, bg_color=(0,0,255), ouline_color=(0,0,255), text_color=(0,0,0))\n",
    "    else :\n",
    "        img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                    font_size=0.7, alpha=0.6, bg_color=(0,255,0), ouline_color=(0,255,0), text_color=(0,0,0))        \n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(res[:,:,::-1])\n",
    "plt.title(\"Result\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 7 : (part_a.jpg)\n",
    "# Detect Contour from Binary Image (Range Thresholding) + \n",
    "# Background removal + \n",
    "# Contour Filter by hierarchy + \n",
    "# Contour Filter by Contour Property\n",
    "# Count Child Contour for each parent\n",
    "# Draw_Ped on object\n",
    "\n",
    "# define range of gray color in HSV\n",
    "lower_gray = np.array([0, 0, 10])\n",
    "upper_gray = np.array([180, 100, 170])\n",
    "\n",
    "\n",
    "img = cv2.imread(\"part_a.jpg\")\n",
    "\n",
    "#convert to hsv\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Threshold the HSV image to get only gray colors\n",
    "mask = cv2.inRange(hsv.copy(), lower_gray, upper_gray)\n",
    "\n",
    "res = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "object_contour = {}\n",
    "object_count = {}\n",
    "object_id = 0\n",
    "threshold_count = 2 # minimum number of child contour \n",
    "\n",
    "for cnt, hrcy in zip(contours, hierarchy[0]):\n",
    "    # find contour Area & boungin Rect\n",
    "    area = cv2.contourArea(cnt)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # calculate aspectRatio & extent\n",
    "    aspectRatio = float(w)/h \n",
    "    rect_area = w*h\n",
    "    extent = float(area)/rect_area\n",
    "    \n",
    "    # filter a small contour\n",
    "    if area <= 200:\n",
    "        continue \n",
    "\n",
    "   # Find All Extreme Outer Contour [BLUE]\n",
    "    if hrcy[3] == -1 :   \n",
    "        # Find contour with aspec ration between 0.3~0.5 (sort vertical rect), with extent 0.2 \n",
    "        if aspectRatio < 0.5 and aspectRatio > 0.3 and extent > 0.4 :      \n",
    "            cv2.drawContours(res, cnt, -1, (255,0,0), 3)\n",
    "            \n",
    "            object_contour[\"object_%d\" % object_id] = cnt # insert parent contour\n",
    "            object_count[\"object_%d\" % object_id] = 0 # set initinal count 0\n",
    "            object_id += 1\n",
    "\n",
    "    # Find All child contour [GREEN]\n",
    "    if hrcy[3] != -1 : #and hrcy[2] == -1:   \n",
    "        # Find contour with aspec ration between 0.5~1.5 (near square), with extent 0.4 \n",
    "        if aspectRatio < 1.5 and aspectRatio > 0.5 and extent > 0.4 :    \n",
    "            cv2.drawContours(res, cnt, -1, (0,255,0), 3)\n",
    "\n",
    "            for obj_name in object_contour:\n",
    "                # find the child contour on wich parrent contour\n",
    "                if cv2.pointPolygonTest(object_contour[obj_name], (x, y), measureDist=True) > 0 :\n",
    "                    object_count[obj_name] += 1\n",
    "\n",
    "\n",
    "for obj_name in object_count:\n",
    "    x, y, w, h = cv2.boundingRect(object_contour[obj_name])\n",
    "    # check if number of child contour inside parrent less than threshold count \n",
    "    if object_count[obj_name] < threshold_count :\n",
    "        img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                    font_size=0.7, alpha=0.6, bg_color=(0,0,255), ouline_color=(0,0,255), text_color=(0,0,0))\n",
    "    else :\n",
    "        img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                    font_size=0.7, alpha=0.6, bg_color=(0,255,0), ouline_color=(0,255,0), text_color=(0,0,0))        \n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(res[:,:,::-1])\n",
    "plt.title(\"Result\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## 1.1.6 Visual Inspection (Child Contour Counting based on Hierarchy)\n",
    "- this implementation NOT using `cv2.pointPolygonTest()` to determine the child contour inside which parent contour.\n",
    "- BUT using full hierarchial TREE on detected contour"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 8 : (part_b.jpg)\n",
    "# Detect Contour from Binary Image (Range Thresholding) + \n",
    "# Background removal + \n",
    "# Contour Filter by hierarchy + \n",
    "# Contour Filter by Contour Property\n",
    "# Count Child Contour for each parent using hierarchy\n",
    "# Draw_Ped on object\n",
    "\n",
    "img = cv2.imread(\"part_b.jpg\")\n",
    "\n",
    "#convert to hsv\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Threshold the HSV image to get only gray colors\n",
    "mask = cv2.inRange(hsv.copy(), lower_gray, upper_gray)\n",
    "\n",
    "res = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "object_hierarchy_id = {}\n",
    "object_contour = {}\n",
    "object_count = {}\n",
    "object_id = 0\n",
    "threshold_count = 22 # min number of child contour \n",
    "\n",
    "for i, (cnt, hrcy) in enumerate(zip(contours, hierarchy[0])):\n",
    "    # find contour Area & boungin Rect\n",
    "    area = cv2.contourArea(cnt)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # calculate aspectRatio & extent\n",
    "    aspectRatio = float(w)/h \n",
    "    rect_area = w*h\n",
    "    extent = float(area)/rect_area\n",
    "    \n",
    "    # filter a small contour\n",
    "    if area <= 200:\n",
    "        continue \n",
    "    \n",
    "   # Find All Extreme Outer Contour [BLUE]\n",
    "    if hrcy[3] == -1 :   \n",
    "        # Find contour with aspec ration between 0.1~0.3 (vertical rect), with extent 0.4\n",
    "        if aspectRatio < 0.3 and aspectRatio > 0.1 and extent > 0.4:      \n",
    "            cv2.drawContours(res, cnt, -1, (255,0,0), 3)\n",
    "            \n",
    "            object_hierarchy_id[\"object_%d\" % object_id] = i # insert parent hierarchy id\n",
    "            object_contour[\"object_%d\" % object_id] = cnt # insert parrent contour\n",
    "            object_count[\"object_%d\" % object_id] = 0 # set initinal count 0\n",
    "            object_id += 1\n",
    "\n",
    "    # Find All child contour [GREEN]\n",
    "    if hrcy[3] != -1 : #and hrcy[2] == -1:   \n",
    "        # Find contour with aspec ration between 0.5~1.5 (near square), with extent 0.4\n",
    "        if aspectRatio < 1.5 and aspectRatio > 0.5 and extent > 0.4:    \n",
    "            cv2.drawContours(res, cnt, -1, (0,255,0), 3)\n",
    "\n",
    "            for obj_name in object_hierarchy_id :\n",
    "                # check if parent for that child contour inside the parent contour\n",
    "                if hrcy[3] == object_hierarchy_id[obj_name] :\n",
    "                    object_count[obj_name] += 1\n",
    "\n",
    "\n",
    "for obj_name in object_count:\n",
    "    x, y, w, h = cv2.boundingRect(object_contour[obj_name])\n",
    "    # check if number of child contour inside parrent less than threshold count \n",
    "    if object_count[obj_name] < threshold_count :\n",
    "        img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                    font_size=0.7, alpha=0.6, bg_color=(0,0,255), ouline_color=(0,0,255), text_color=(0,0,0))\n",
    "    else :\n",
    "        img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                    font_size=0.7, alpha=0.6, bg_color=(0,255,0), ouline_color=(0,255,0), text_color=(0,0,0))        \n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(res[:,:,::-1])\n",
    "plt.title(\"Result\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "## 1.2 CUDA Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# load image in Host memory\n",
    "img = cv2.imread(\"part_b.jpg\")\n",
    "h, w, c = img.shape\n",
    "\n",
    "# GPU memory initialization\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "hsv_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "hsv_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "h_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "h_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "s_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "s_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "v_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "v_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "mask_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "mask_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "res_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "res_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "\n",
    "# upload to GPU memory\n",
    "img_GpuMat.upload(img)\n",
    "\n",
    "# CUDA convert to hsv\n",
    "cv2.cuda.cvtColor(img_GpuMat, cv2.COLOR_BGR2HSV, hsv_GpuMat)\n",
    "\n",
    "# split HSV GPU Mat\n",
    "cv2.cuda.split(hsv_GpuMat, [h_GpuMat, s_GpuMat, v_GpuMat])\n",
    "\n",
    "# CUDA Threshold the V(20,150) ~ HSV GPU Mat to get only gray colors\n",
    "cv2.cuda.inRange(v_GpuMat, 20, 150, mask_GpuMat)\n",
    "\n",
    "# CUDA bitwise operation\n",
    "cv2.cuda.bitwise_not(img_GpuMat, res_GpuMat, mask=mask_GpuMat) # apply bitwise NOT to original image -> result image\n",
    "cv2.cuda.bitwise_not(res_GpuMat, res_GpuMat, mask=mask_GpuMat) # apply bitwise NOT to result image \n",
    "\n",
    "# Download Matrix to Host Memory                                                               \n",
    "mask = mask_GpuMat.download()\n",
    "res = res_GpuMat.download()\n",
    "\n",
    "# find contour\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "object_hierarchy_id = {}\n",
    "object_contour = {}\n",
    "object_count = {}\n",
    "object_id = 0\n",
    "threshold_count = 22 # min number of child contour \n",
    "\n",
    "for i, (cnt, hrcy) in enumerate(zip(contours, hierarchy[0])):\n",
    "    # find contour Area & boungin Rect\n",
    "    area = cv2.contourArea(cnt)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # calculate aspectRatio & extent\n",
    "    aspectRatio = float(w)/h \n",
    "    rect_area = w*h\n",
    "    extent = float(area)/rect_area\n",
    "    \n",
    "    # filter a small contour\n",
    "    if area <= 200:\n",
    "        continue \n",
    "    \n",
    "   # Find All Extreme Outer Contour [BLUE]\n",
    "    if hrcy[3] == -1 :   \n",
    "        # Find contour with aspec ration between 0.1~0.3 (vertical rect), with extent 0.4\n",
    "        if aspectRatio < 0.3 and aspectRatio > 0.1 and extent > 0.4:      \n",
    "            cv2.drawContours(res, cnt, -1, (255,0,0), 3)\n",
    "            \n",
    "            object_hierarchy_id[\"object_%d\" % object_id] = i # insert parent hierarchy id\n",
    "            object_contour[\"object_%d\" % object_id] = cnt # insert parrent contour\n",
    "            object_count[\"object_%d\" % object_id] = 0 # set initinal count 0\n",
    "            object_id += 1\n",
    "\n",
    "    # Find All child contour [GREEN]\n",
    "    if hrcy[3] != -1 : #and hrcy[2] == -1:   \n",
    "        # Find contour with aspec ration between 0.5~1.5 (near square), with extent 0.4\n",
    "        if aspectRatio < 1.5 and aspectRatio > 0.5 and extent > 0.4:    \n",
    "            cv2.drawContours(res, cnt, -1, (0,255,0), 3)\n",
    "\n",
    "            for obj_name in object_hierarchy_id :\n",
    "                # check if parent for that child contour inside the parent contour\n",
    "                if hrcy[3] == object_hierarchy_id[obj_name] :\n",
    "                    object_count[obj_name] += 1\n",
    "\n",
    "\n",
    "for obj_name in object_count:\n",
    "    x, y, w, h = cv2.boundingRect(object_contour[obj_name])\n",
    "    # check if number of child contour inside parrent less than threshold count \n",
    "    if object_count[obj_name] < threshold_count :\n",
    "        img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                    font_size=0.7, alpha=0.6, bg_color=(0,0,255), ouline_color=(0,0,255), text_color=(0,0,0))\n",
    "    else :\n",
    "        img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                    font_size=0.7, alpha=0.6, bg_color=(0,255,0), ouline_color=(0,255,0), text_color=(0,0,0))\n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(res[:,:,::-1])\n",
    "plt.title(\"Result\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "____\n",
    "\n",
    "# 2. Shape Detection\n",
    "\n",
    "# 2.1 Hough Line Transform (Line Detector)\n",
    "\n",
    "<img src=\"res/lane.gif\" style=\"width:500px, margin-top:10px\"></img>\n",
    "- The Hough Line Transform is a transform used to detect **straight lines**.\n",
    "- To apply the Transform, first an **edge detection** pre-processing is desirable.\n",
    "- As you know, a line in the image space can be expressed with two variables. For example:\n",
    "    - In the **Cartesian** coordinate system: Parameters: ($m$,$b$).\n",
    "    - In the **Polar** coordinate system: Parameters: ($r$,$θ$). <br>\n",
    "      <img src=\"res/Hough_Lines_Tutorial_Theory_0.jpg\" style=\"width:400px, margin-top:10px\"></img> <br>\n",
    "    - For Hough Transforms, we will express lines in the *Polar system*. Hence, a line equation can be written as: <br>\n",
    "    $y = \\left ( -\\dfrac{\\cos \\theta}{\\sin \\theta} \\right ) x + \\left ( \\dfrac{r}{\\sin \\theta} \\right )$ <br>\n",
    "    Arranging the terms: $r = x \\cos \\theta + y \\sin \\theta$ <br>\n",
    "    - In general for each point ($x_{0}, y_{0}$), we can define the family of lines that goes through that point as: <br>\n",
    "        $r_{\\theta} = x_{0} \\cdot \\cos \\theta + y_{0} \\cdot \\sin \\theta$ <br>\n",
    "        Meaning that each pair ($r_{\\theta},\\theta$) represents each line that passes by ($x_{0}, y_{0}$).\n",
    "    - If for a given ($x_{0}, y_{0}$) we plot the family of lines that goes through it, we get a sinusoid. For instance, for $x_{0}$=8 and $y_{0}$=6 we get the following plot (in a plane $θ - r$): <br>\n",
    "        <img src=\"res/Hough_Lines_Tutorial_Theory_1.jpg\" style=\"width:400px, margin-top:10px\"></img> <br>\n",
    "        We consider only points such that $r > 0$ and $0< \\theta < 2 \\pi$.\n",
    "    - We can do the same operation above for all the points in an image. If the curves of two different points intersect in the plane $θ - r$, that means that both points belong to a same line. For instance, following with the example above and drawing the plot for two more points: $x_{1}=4, y_{1}=9$ and $x_{2}=12, y_{2}=3$, we get: <br>\n",
    "        <img src=\"res/Hough_Lines_Tutorial_Theory_2.jpg\" style=\"width:400px, margin-top:10px\"></img> <br>\n",
    "        The three plots intersect in one single point (0.925,9.6), these coordinates are the parameters (θ$,r$) or the line in which ($x_{0},y_{0}$), ($x_{1},y_{1}$) and ($x_{2},y_{2}$).<br><br>\n",
    "    > A line can be detected by finding the **number of intersections between curves**.The **more curves intersecting** means that the line represented by that **intersection have more points**.\n",
    "    > In general, we can define a **threshold** of the **minimum number of intersections** needed to **detect a line**.\n",
    "    > This is what the **Hough Line Transform** does. It keeps track of the intersection between curves of every point in the image. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- OpenCV implements two kind of Hough Line Transforms: <r><br>\n",
    "    - The **Standard Hough Transform** <br>\n",
    "        It consists in pretty much what we just explained in the previous section. It gives you as result a vector of couples ($θ,rθ$)\n",
    "        In OpenCV it is implemented with the function `cv2.HoughLines()`.\n",
    "\n",
    "    - The **Probabilistic Hough Line Transform** <br>\n",
    "        A more efficient implementation of the Hough Line Transform. It gives as output the extremes of the detected lines ($x_{0},y_{0},x_{1},y_{1}$)\n",
    "        In OpenCV it is implemented with the function `cv2.HoughLinesP()`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.1 Standard Hough Transform `cv2.HoughLines()`\n",
    "\n",
    "- menggunakan method `cv2.HoughLines(img, rho, theta, threshold, lines, srn, stn)`\n",
    "- with the following arguments:\n",
    "    - `img` : input image (edge image)\n",
    "    - `rho` : The resolution of the parameter r in pixels. We use 1 pixel.\n",
    "    - `theta` : The resolution of the parameter θ in radians. We use 1 degree (`np.pi/180`)\n",
    "    - `threshold` : The minimum number of intersections to *detect* a line\n",
    "    - `lines` : A vector that will store the parameters ($r,θ$) of the detected lines\n",
    "    - `srn` and `stn` : Default parameters to zero. \n",
    "- output `lines` is list with item `[[tho, theta]]`\n",
    "\n",
    "\n",
    "### 2.1.2 Probabilistic  Hough Transform `cv2.HoughLinesP()`\n",
    "\n",
    "- menggunakan method `cv2.HoughLinesP(img, res_rho, res_theta, threshold, lines, minLinLength, maxLineGap)`\n",
    "- with the following arguments:\n",
    "    - `img` : input image (edge image)\n",
    "    - `res_rho` : The resolution of the parameter r in pixels. We use 1 pixel.\n",
    "    - `res_theta` : The resolution of the parameter θ in radians. We use 1 degree (`np.pi/180`)\n",
    "    - `threshold` : The minimum number of intersections to *detect* a line\n",
    "    - `lines` : A vector that will store the parameters ($r,θ$) of the detected lines\n",
    "    - `minLinLength` : The minimum number of points that can form a line. Lines with less than this number of points are disregarded.\n",
    "    - `maxLineGap` : The maximum gap between two points to be considered in the same line.\n",
    "- output `lines` is list with item `[[tho, theta]]`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 1 : Hough Lines\n",
    "\n",
    "img = cv2.imread('road.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 200)\n",
    "\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, 100, None, 0, 0)\n",
    "\n",
    "if lines is not None :\n",
    "    for rho, theta in lines[:, 0, :]:\n",
    "        m = - 1 * np.cos(theta) / np.sin(theta)\n",
    "        c = rho / np.sin(theta)\n",
    "        \n",
    "        x0, x1 = 0, 1000\n",
    "        y0 = int(m*x0 + c)\n",
    "        y1 = int(m*x1 + c)\n",
    "        cv2.line(img, (x0, y0), (x1, y1), (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Hough Lines\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 2 : Hough Lines Probabilistic\n",
    "\n",
    "img = cv2.imread('road.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 200)\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, minLineLength=50, maxLineGap=30)\n",
    "\n",
    "if lines is not None : \n",
    "    for x1, y1, x2, y2 in lines[:, 0, :]:\n",
    "        cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Hough LinesP\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## 2.5 CUDA Implementation Hough Lines\n",
    "- Class `cv2.cuda.createHoughLinesDetector(res_rho, res_theta, threshold, doSort, maxLines)`\n",
    "- Where : \n",
    "    - `res_rho` : Distance resolution of the accumulator in pixels.\n",
    "    - `res_theta` : Angle resolution of the accumulator in radians.\n",
    "    - `threshold` : The minimum number of intersections to *detect* a line.\n",
    "    - `doSort` : Performs lines sort by votes.\n",
    "    - `maxLines` : Maximum number of output lines.\n",
    "- Method to finds lines in a binary image `.detect(src, d_lines)`\n",
    "- Where : \n",
    "    - `src` : GPU Mat CV_8UC1 (8 bit 1 channel)\n",
    "    - `d_lines` : GPU Mat vector of lines in GPU memory."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 3 : CUDA Hough Lines\n",
    "\n",
    "img = cv2.imread('road.jpg')\n",
    "h, w, c = img.shape\n",
    "\n",
    "# GPU memory initialization\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "gray_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "gray_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "edged_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "edged_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "\n",
    "# Define CUDA Canny Edge Detection & Hough Lines Object\n",
    "Canny = cv2.cuda.createCannyEdgeDetector(50, 200) # Initialize Canny Detector in CUDA\n",
    "HoughLines = cv2.cuda.createHoughLinesDetector(1, np.pi/180, 100, True, 100)\n",
    "\n",
    "# upload to GPU memory\n",
    "img_GpuMat.upload(img)\n",
    "\n",
    "# CUDA convert to Grayscale\n",
    "cv2.cuda.cvtColor(img_GpuMat, cv2.COLOR_BGR2GRAY, gray_GpuMat)\n",
    "\n",
    "# Apply Canny Object Detection using CUDA\n",
    "Canny.detect(gray_GpuMat, edged_GpuMat)\n",
    "\n",
    "# Apply Hough Lines Detection\n",
    "d_lines = HoughLines.detect(edged_GpuMat)\n",
    "\n",
    "# Download Lines to Host Memory\n",
    "lines = d_lines.download()\n",
    "\n",
    "# draw line\n",
    "if lines is not None :\n",
    "    for rho, theta in lines[0, :, :]:\n",
    "        m = - 1 * np.cos(theta) / np.sin(theta)\n",
    "        c = rho / np.sin(theta)\n",
    "        \n",
    "        x0, x1 = 0, 1000\n",
    "        y0 = int(m*x0 + c)\n",
    "        y1 = int(m*x1 + c)\n",
    "        cv2.line(img, (x0, y0), (x1, y1), (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Hough Lines\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## 2.2 Hough Circle Transform\n",
    "- The Hough Circle Transform works in a roughly analogous way to the Hough Line Transform explained in the previous tutorial.\n",
    "- In the line detection case, a line was defined by two parameters ($r,θ$). \n",
    "- Parameters to define a circle:\n",
    "$C : ( x_{center}, y_{center}, r )$\n",
    "- where ($x_{center},y_{center}$) define the center position (green point) and $r$ is the radius, which allows us to completely define a circle, as it can be seen below:<br>\n",
    " <img src=\"res/Hough_Circle_Tutorial_Theory_0.jpg\" style=\"width:400px, margin-top:10px\"></img><br><br>\n",
    "- menggunakan method `cv2.HoughCircles(img, mode, dp, min_dist_center, param1, param2, min_radius, max_radius)`\n",
    "- with the arguments:\n",
    "    - `img` : input image.\n",
    "    - `mode` : \n",
    "        - `cv2.HOUGH_STANDARD` : Classical or standard Hough transform.\n",
    "        - `cv2.HOUGH_PROBABILISTIC` : Probabilistic Hough transform (more efficient in case if the picture contains a few long linear segments).\n",
    "        - `cv2.HOUGH_MULTI_SCALE` : multi-scale variant of the classical Hough transform. \n",
    "        - `cv2.HOUGH_GRADIENT`\n",
    "    - `dp` : The inverse ratio of resolution (default 1).\n",
    "    - `min_dist_center` : Minimum distance between detected centers.\n",
    "    - `param1` : Upper threshold for the internal Canny edge detector.\n",
    "    - `param2` : Threshold for center detection.\n",
    "    - `min_radius` : Minimum radius to be detected. If unknown, put zero as default.\n",
    "    - `max_radius` : Maximum radius to be detected. If unknown, put zero as default."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# EXAMPLE 4 : Hough Circle\n",
    "\n",
    "img = cv2.imread('eye.jpg')\n",
    "h, w, c = img.shape\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.GaussianBlur(gray,(5,5), 0, 0)\n",
    "\n",
    "circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1, h/64, param1=200, param2=17, minRadius=21, maxRadius=30)\n",
    "\n",
    "if circles is not None :\n",
    "    for x, y, r in np.uint0(circles[0, :, :]):\n",
    "        cv2.circle(img, (x, y), r, (0, 255, 0), 2)\n",
    "        \n",
    "plt.figure(figsize=(20,30))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Hough Circle\")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "error",
     "evalue": "OpenCV(4.5.3) /tmp/build_opencv/opencv/modules/imgproc/src/hough.cpp:2318: error: (-5:Bad argument) Unrecognized method id. Actually only CV_HOUGH_GRADIENT is supported. in function 'HoughCircles'\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-fd112bde5b85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mblur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcircles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHoughCircles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHOUGH_PROBABILISTIC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminRadius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxRadius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcircles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.3) /tmp/build_opencv/opencv/modules/imgproc/src/hough.cpp:2318: error: (-5:Bad argument) Unrecognized method id. Actually only CV_HOUGH_GRADIENT is supported. in function 'HoughCircles'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## 2.5 CUDA Implementation Hough Circle\n",
    "- Class `cv2.cuda.createHoughCirclesDetector(dp, min_dist_center, param1, param2, minRadius, maxRadius)`\n",
    "- Where : \n",
    "    - `dp` : The inverse ratio of resolution (default 1).\n",
    "    - `min_dist_center` : Minimum distance between detected centers.\n",
    "    - `param1` : Upper threshold for the internal Canny edge detector.\n",
    "    - `param2` : Threshold for center detection.\n",
    "    - `min_radius` : Minimum radius to be detected. If unknown, put zero as default.\n",
    "    - `max_radius` : Maximum radius to be detected. If unknown, put zero as default.\n",
    "- Method to finds circles  in a binary image `.detect(src, d_circles)`\n",
    "- Where : \n",
    "    - `src` : GPU Mat CV_8UC1 (8 bit 1 channel)\n",
    "    - `d_circles` : GPU Mat vector of circles in GPU memory."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 5 : CUDA Hough Circle\n",
    "\n",
    "img = cv2.imread('eye.jpg')\n",
    "h, w, c = img.shape\n",
    "\n",
    "# GPU memory initialization\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "gray_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "gray_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "res_Gaussian_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "res_Gaussian_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "\n",
    "# Create CUDA Gaussian Filter Object with kernel size 7x7\n",
    "cuda_GaussianFilter = cv2.cuda.createGaussianFilter(cv2.CV_8UC1, cv2.CV_8UC1, (5,5), 0, 0)\n",
    "# Define CUDA Hough Circles Object\n",
    "HoughCircles = cv2.cuda.createHoughCirclesDetector(1, h/64, 200, 17, 21, 30)\n",
    "\n",
    "# upload to GPU memory\n",
    "img_GpuMat.upload(img)\n",
    "\n",
    "# CUDA convert to Grayscale\n",
    "cv2.cuda.cvtColor(img_GpuMat, cv2.COLOR_BGR2GRAY, gray_GpuMat)\n",
    "\n",
    "# apply CUDA Gaussian Filter\n",
    "cuda_GaussianFilter.apply(gray_GpuMat, res_Gaussian_GpuMat)\n",
    "\n",
    "# Apply Hough Circles Detection\n",
    "d_circles = HoughCircles.detect(res_Gaussian_GpuMat)\n",
    "\n",
    "# Download Circles to Host Memory\n",
    "circles = d_circles.download()\n",
    "\n",
    "# draw circle\n",
    "if circles is not None :\n",
    "    for x, y, r in np.uint0(circles[0, :, :]):\n",
    "        cv2.circle(img, (x, y), r, (0, 255, 0), 2)\n",
    "        \n",
    "plt.figure(figsize=(20,30))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Hough Circle\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## 2.3 Hough Transform Application (Hough Circle) - Real-time Circle Detection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 6 : Detect Yellow Ball using Hough Circles\n",
    "\n",
    "cap = cv2.VideoCapture(\"yellow_ball.mp4\")\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret :\n",
    "        break \n",
    "\n",
    "    frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "    h, w, c = frame.shape\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, h/2, param1=180, param2=17, minRadius=21, maxRadius=100)\n",
    "\n",
    "    if circles is not None :\n",
    "        for x, y, r in np.uint0(circles[0, :, :]):\n",
    "            cv2.circle(frame, (x, y), r, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Hough Circle - Video', frame)\n",
    "\n",
    "    if cv2.waitKey(10) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- CUDA Version for Detect Yellow Ball"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 7 : Detect Yellow Circle using CUDA Hough Circles\n",
    "\n",
    "cap = cv2.VideoCapture(\"yellow_ball.mp4\")\n",
    "\n",
    "h, w, c = cap.read()[1].shape\n",
    "h, w = h//2, w//2\n",
    "\n",
    "# GPU memory initialization\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "gray_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "gray_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "\n",
    "# Define CUDA Hough Circles Object\n",
    "HoughCircles = cv2.cuda.createHoughCirclesDetector(1, h/2, 180, 17, 21, 100)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret :\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (w,h))\n",
    "\n",
    "    # upload to GPU memory\n",
    "    img_GpuMat.upload(frame)\n",
    "    \n",
    "    # CUDA convert to Grayscale\n",
    "    cv2.cuda.cvtColor(img_GpuMat, cv2.COLOR_BGR2GRAY, gray_GpuMat)\n",
    "\n",
    "    # Apply Hough Circles Detection\n",
    "    d_circles = HoughCircles.detect(gray_GpuMat)\n",
    "\n",
    "    # Download Circles to Host Memory\n",
    "    circles = d_circles.download()\n",
    "\n",
    "    # draw circle\n",
    "    if circles is not None :\n",
    "        for x, y, r in np.uint0(circles[0, :, :]):\n",
    "            cv2.circle(frame, (x, y), r, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Hough Circle - Video', frame)\n",
    "    if cv2.waitKey(10) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## 2.4 Real-tim Road Line Detection <br>\n",
    "Original Video : [https://www.youtube.com/watch?v=KWJaBJYJIjI](https://www.youtube.com/watch?v=KWJaBJYJIjI)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "maxLineGap = 200\n",
    "minLineLength = 50\n",
    "title_window = \"Road Lane Detector\"\n",
    "\n",
    "# define ROI polygon in video frame with size 720x1280\n",
    "dim = [720, 1280]\n",
    "roi_poly = np.array([[ 118,  678],\n",
    "                    [ 586,  434],\n",
    "                    [ 868,  420],\n",
    "                    [1226,  650]])\n",
    "\n",
    "# find fraction ROI polygon (0-1)\n",
    "f_roi_poly = roi_poly/dim\n",
    "f = 0.5\n",
    "\n",
    "# load video file\n",
    "cap = cv2.VideoCapture('drive.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret :\n",
    "        break # stop loop\n",
    "\n",
    "    # resize frame\n",
    "    frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "    dim = frame.shape[:2]\n",
    "\n",
    "    # convert to gray\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # create masking image\n",
    "    mask = np.zeros(gray.shape).astype(np.uint8)\n",
    "    \n",
    "    # draw polygone in new frame size\n",
    "    pts = f_roi_poly*dim\n",
    "    cv2.fillPoly(mask, [pts.astype(np.int64)], (255,255,255))\n",
    "    \n",
    "    # apply bitwise operation\n",
    "    roi = cv2.bitwise_and(gray, gray, mask=mask)\n",
    "\n",
    "    # apply simple thresholding \n",
    "    ___, thresh = cv2.threshold(roi, 130, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # apply Canny edge detection\n",
    "    edged = cv2.Canny(thresh, 127, 200)\n",
    "\n",
    "    # find lines using Hough Line Probabilistic\n",
    "    lines = cv2.HoughLinesP(edged, 1, np.pi/180, 10, None, minLineLength=20, maxLineGap=250)\n",
    "\n",
    "    # draw lines\n",
    "    if lines is not None:\n",
    "        for x1, y1, x2, y2 in lines[:,0,:]:\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('roi', roi)\n",
    "    cv2.imshow(title_window, frame)\n",
    "\n",
    "    if cv2.waitKey(25) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Dari hasil sebelumnya kita dapat mendeteksi Road Lane dengan menggunakan `cv2.HoughLinesP()`\n",
    "- Namun banyak `lines` yang terdeteksi disisi kanan maupun  kiri,<br>\n",
    "<img src=\"res/overlay_v1.png\" style=\"width: 500px; margin-top:10px;\" > </img> <br>\n",
    "<img src=\"res/slope_intersect.png\" style=\"width: 400px; margin-top:10px;\" > </img> <br>\n",
    "- Rata-ratakan slope ($m$) dan Intersept ($c$), disisi kanan dan kiri,<br>\n",
    "<img src=\"res/slope_intersect_mean.png\" style=\"width: 400px; margin-top:10px;\" > </img>\n",
    "- Setelahnya tentukan ($x_1, y_1$) dan ($x_2, y_2$) sisi kanan dan kiri,<br>\n",
    "<img src=\"res/coordinate.png\" style=\"width: 500px; margin-top:10px;\" > </img>\n",
    "- Tambahkan overlay sebagai berikut dari `lines` yang didapatkan  `cv2.HoughLinesP()` <br>\n",
    "<img src=\"res/overlay.png\" style=\"width: 500px; margin-top:10px;\" > </img> \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "r_m, l_m, r_c, l_c = [],[],[],[]\n",
    "def draw_lines(shape, lines, thickness=3, margin_top = 0.65):\n",
    "    global r_m, l_m, r_c, l_c\n",
    "    h, w = shape\n",
    "    overlay = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    \n",
    "    if lines is not None :\n",
    "        for x1, y1, x2, y2 in lines[:,0,:]:\n",
    "\n",
    "            m = (y1-y2)/(x1-x2)\n",
    "            c = y2 - (m*x2)\n",
    "            if m > 0.3:\n",
    "                r_m.append(m)\n",
    "                r_c.append(c)\n",
    "            elif m < -0.3:\n",
    "                l_m.append(m)\n",
    "                l_c.append(c)\n",
    "\n",
    "    # find average m and c for left and right line for the last 30 data.\n",
    "    avg_l_m = np.mean(l_m[-30:])\n",
    "    avg_l_c = np.mean(l_c[-30:])\n",
    "    avg_r_m = np.mean(r_m[-30:])\n",
    "    avg_r_c = np.mean(r_c[-30:])\n",
    "\n",
    "    # delete data\n",
    "    del l_m[:-30]\n",
    "    del l_c[:-30]\n",
    "    del r_m[:-30]\n",
    "    del r_c[:-30]\n",
    "\n",
    "    try:\n",
    "        y1, y2 = int(margin_top*h), h\n",
    "        l_x1 = int((y1 - avg_l_c)/avg_l_m)\n",
    "        l_x2 = int((y2 - avg_l_c)/avg_l_m)\n",
    "        r_x1 = int((y1- avg_r_c)/avg_r_m)\n",
    "        r_x2 = int((y2 - avg_r_c)/avg_r_m)\n",
    "        \n",
    "        pts = np.array([[l_x1, y1],[l_x2, y2],[r_x2, y2],[r_x1, y1]]).astype(np.int32)\n",
    "        pts = pts.reshape((-1,1,2))\n",
    "        cv2.fillPoly(overlay, [pts], (0,127,50))\n",
    "        cv2.line(overlay, (l_x1, y1), (l_x2, y2), (0,255,255), thickness)\n",
    "        cv2.line(overlay, (r_x1, y1), (r_x2, y2), (0,255,255), thickness)\n",
    "        return overlay\n",
    "    except ValueError:\n",
    "        pass\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "maxLineGap = 200\n",
    "minLineLength = 50\n",
    "title_window = \"Road Lane Detector\"\n",
    "\n",
    "# define ROI polygon in video frame with size 720x1280\n",
    "dim = [720, 1280]\n",
    "roi_poly = np.array([[ 118,  678],\n",
    "                    [ 586,  434],\n",
    "                    [ 868,  420],\n",
    "                    [1226,  650]])\n",
    "\n",
    "# find fraction ROI polygon (0-1)\n",
    "f_roi_poly = roi_poly/dim\n",
    "f = 0.5\n",
    "\n",
    "# load video file\n",
    "cap = cv2.VideoCapture('drive.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret :\n",
    "        break # stop loop\n",
    "\n",
    "    # resize frame\n",
    "    frame = cv2.resize(frame, (0,0), fx=0.25, fy=0.25)\n",
    "    dim = frame.shape[:2]\n",
    "\n",
    "    # convert to gray\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # create masking image\n",
    "    mask = np.zeros(gray.shape).astype(np.uint8)\n",
    "    \n",
    "    # draw polygone in new frame size\n",
    "    pts = f_roi_poly*dim\n",
    "    cv2.fillPoly(mask, [pts.astype(np.int64)], (255,255,255))\n",
    "    \n",
    "    # apply bitwise operation\n",
    "    roi = cv2.bitwise_and(gray, gray, mask=mask)\n",
    "\n",
    "    # apply simple thresholding \n",
    "    ___, thresh = cv2.threshold(roi, 130, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # apply Canny edge detection\n",
    "    edged = cv2.Canny(thresh, 127, 200)\n",
    "\n",
    "    # find lines using Hough Line Probabilistic\n",
    "    lines = cv2.HoughLinesP(edged, 1, np.pi/180, 10, None, minLineLength=20, maxLineGap=250)\n",
    "\n",
    "    overlay = draw_lines(edged.shape, lines, thickness = 3, margin_top = 0.65)\n",
    "    frame = cv2.addWeighted(frame, 1, overlay, 0.7, 0)\n",
    "\n",
    "    cv2.imshow(title_window, frame)\n",
    "    cv2.imshow(title_window + \"- ROI\", roi)\n",
    "    cv2.imshow(title_window + \"- Edge\", edged)\n",
    "    cv2.imshow(title_window + \"- Thresh\", thresh)\n",
    "    \n",
    "    if cv2.waitKey(25) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}