{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pertemuan 13\n",
    "- OpenCV Video Decoding\n",
    "- OpenCV Image Rendering\n",
    "- Realtime Object Segmentation - Contour Based\n",
    "- Realtime Object Segmentation - OpenCV Tracking API\n",
    "___\n",
    "### Maximizing Jetson Nano Perfomance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sudo nvpmodel -m 0\n",
    "# sudo jetson_clocks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-  load some utility function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from gst_file import gst_file_loader\n",
    "from draw_utils import draw_ped"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# check OpenCV Version\n",
    "\n",
    "cv2.__version__"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 1. OpenCV Video Decoding - GStreamer vs FFMPEG"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load video file using GStreamer\n",
    "#cap = cv2.VideoCapture(gst_file_loader(\"video_a.mp4\"), cv2.CAP_GSTREAMER)  # backend GSTREAMER\n",
    "\n",
    "gst = \"rtspsrc location=https://192.168.0.103:8081/index.jpg latency=0 ! rtph264depay ! h264parse ! omxh264dec ! videoconvert ! appsink\"\n",
    "cap = cv2.VideoCapture(gst, cv2.CAP_GSTREAMER)\n",
    "# cap = cv2.VideoCapture(\"video_a.mp4\")  # backend FFMPEG\n",
    "# cap.set(cv2.CAP_PROP_ORIENTATION_AUTO, 1) # applicable for backend FFMPEG only\n",
    "\n",
    "times = []\n",
    "while cap.isOpened() : \n",
    "    e1 = cv2.getTickCount()\n",
    "    ret, frame = cap.read()\n",
    "    if not ret : \n",
    "        break \n",
    "\n",
    "    cv2.imshow(\"window\", frame)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "    e2 = cv2.getTickCount()\n",
    "    times.append((e2 - e1)/ cv2.getTickFrequency())\n",
    "\n",
    "time_avg = np.array(times).mean()\n",
    "print(\"Average execution time : %.4fs\" % time_avg)\n",
    "print(\"Average FPS : %.2f\" % (1/time_avg))\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result Benchmark Video Decoding\n",
    "- Source video : `video_a.mp4` \n",
    "- `cv2.VideoCapture()` with backend FFMPEG\n",
    "    - Average execution time : 0.1627s\n",
    "    - Average FPS : 6.15\n",
    "- `cv2.VideoCapture()` with backend GStreamer\n",
    "    - Average execution time : 0.1587s\n",
    "    - Average FPS : 6.30\n",
    "- `cv2.VideoCapture()` with backend FFMPEG + Jetson maximized performance\n",
    "    - Average execution time : 0.1615s\n",
    "    - Average FPS : 6.19\n",
    "- `cv2.VideoCapture()` with backend GStreamer + Jetson maximized performance\n",
    "    - Average execution time : 0.1347s\n",
    "    - Average FPS : 7.42"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 2. OpenCV Image Rendering - Standard vs OPENGL\n",
    "- To use OpenGL in Jetson Nano try to build OpenCV with OpenGL Enable by following [this tutorial](https://yunusmuhammad007.medium.com/build-and-install-opencv-4-5-3-on-jetson-nano-with-cuda-opencl-opengl-and-gstreamer-enable-6dc7141be272). <br><br>\n",
    "- Install `mesa-utils` to help us check OpenGL available on our machine (Jetson Nano)\n",
    "    ```\n",
    "    sudo apt-get install mesa-utils\n",
    "    ```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  ---- Check OpenGL Version ----\n",
    "# glxinfo | grep OpenGL\n",
    "#\n",
    "# \n",
    "# ---- Check DISPLAY variable ----\n",
    "# echo $DISPLAY\n",
    "#\n",
    "#\n",
    "# ---- Enable NVIDIA OpenGL ----\n",
    "# sudo service gdm3 stop\n",
    "# sudo X\n",
    "# export DISPLAY=:0\n",
    "# xrandr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%env DISPLAY=:0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE Play Video Stream + OpenGL Image Rendering\n",
    "\n",
    "window_name = \"Window\"\n",
    "cv2.namedWindow(window_name, flags=cv2.WINDOW_OPENGL)    # Window with OpenGL\n",
    "\n",
    "# load video file using GStreaqmer\n",
    "cap = cv2.VideoCapture(gst_file_loader(\"video_a.mp4\"), cv2.CAP_GSTREAMER)  # backend GSTREAMER\n",
    "\n",
    "# cap = cv2.VideoCapture(\"video_a.mp4\", cv2.CAP_FFMPEG)  # backend FFMPEG\n",
    "# cap.set(cv2.CAP_PROP_ORIENTATION_AUTO, 1) # applicable for backend FFMPEG only\n",
    "\n",
    "times = []\n",
    "while cap.isOpened() : \n",
    "    e1 = cv2.getTickCount()\n",
    "    ret, frame = cap.read()\n",
    "    if not ret : \n",
    "        break \n",
    "\n",
    "    cv2.imshow(window_name, frame)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "    e2 = cv2.getTickCount()\n",
    "    times.append((e2 - e1)/ cv2.getTickFrequency())\n",
    "\n",
    "time_avg = np.array(times).mean()\n",
    "print(\"Average execution time : %.4fs\" % time_avg)\n",
    "print(\"Average FPS : %.2f\" % (1/time_avg))\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result Benchmark \n",
    "- `cv2.VideoCapture()` with backend GStreamer + Jetson maximized performance + OpenGL Image Rendering\n",
    "    - Average execution time : 0.0332s\n",
    "    - Average FPS : 30.09\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "# 3. Realtime Object Segmentation - Contour Based\n",
    "- This is based on example in [section 6](https://github.com/Muhammad-Yunus/Jetson-Nano-OpenCV-Learn/tree/main/pertemuan_6)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 Example 6 From Section 6"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "######### EXAMPLE 6 FROM SECTION 6 : (part_b.jpg) ##########\n",
    "#\n",
    "# Detect Contour from Binary Image (Range Thresholding) + \n",
    "# Background removal + \n",
    "# Contour Filter by hierarchy + \n",
    "# Contour Filter by Contour Property\n",
    "# Count Child Contour for each parent\n",
    "# Draw_Ped on object\n",
    "#\n",
    "############################################################\n",
    "\n",
    "\n",
    "img = cv2.imread(\"part_b.jpg\")\n",
    "\n",
    "#convert to hsv\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# define range of gray color in HSV \n",
    "lower_gray = np.array([0, 0, 20])       # (part_a.jpg : [0, 0, 20] | part_b.jpg : [0, 0, 10])\n",
    "upper_gray = np.array([180, 100, 150])  # (part_a.jpg : [180, 100, 150]| part_b.jpg : [180, 100, 170])\n",
    "\n",
    "# Threshold the HSV image to get only gray colors\n",
    "mask = cv2.inRange(hsv.copy(), lower_gray, upper_gray)\n",
    "\n",
    "res = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "object_contour = {}\n",
    "object_count = {}\n",
    "object_id = 0\n",
    "\n",
    "THRESHOLD_COUNT = 22 # min number of child contour  (part_a.jpg : 22 | part_b.jpg : 2)\n",
    "MIN_AREA = 200 # minimum number of pixel to be counted to reject small contour\n",
    "\n",
    "# Contour Property parameter for parent contour\n",
    "MAX_ASPECT_RATIO = 0.3 # (part_a.jpg : 0.3 | part_b.jpg : 0.5)\n",
    "MIN_ASPECT_RATIO = 0.1 # (part_a.jpg : 0.1 | part_b.jpg : 0.3)\n",
    "MIN_EXTENT = 0.4\n",
    "\n",
    "# Contour Property parameter for child contour\n",
    "MAX_ASPECT_RATIO_CHILD = 1.5\n",
    "MIN_ASPECT_RATIO_CHILD = 0.5\n",
    "MIN_EXTENT_CHILD = 0.4\n",
    "\n",
    "for cnt, hrcy in zip(contours, hierarchy[0]):\n",
    "    # find contour Area & boungin Rect\n",
    "    area = cv2.contourArea(cnt)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # calculate aspectRatio & extent\n",
    "    aspectRatio = float(w)/h \n",
    "    rect_area = w*h\n",
    "    extent = float(area)/rect_area\n",
    "    \n",
    "    # filter a small contour\n",
    "    if area <= MIN_AREA:\n",
    "        continue \n",
    "    \n",
    "   # Find All Extreme Outer Contour [BLUE]\n",
    "    if hrcy[3] == -1 :   \n",
    "        if aspectRatio < MAX_ASPECT_RATIO and aspectRatio > MIN_ASPECT_RATIO and extent > MIN_EXTENT:      \n",
    "            cv2.drawContours(res, cnt, -1, (255,0,0), 3)\n",
    "            \n",
    "            object_contour[\"object_%d\" % object_id] = cnt # insert parent contour\n",
    "            object_count[\"object_%d\" % object_id] = 0 # set initinal count 0\n",
    "            object_id += 1\n",
    "\n",
    "    # Find All child contour [GREEN]\n",
    "    if hrcy[3] != -1 :  \n",
    "        if aspectRatio < MAX_ASPECT_RATIO_CHILD and aspectRatio > MIN_ASPECT_RATIO_CHILD and extent > MIN_EXTENT_CHILD:    \n",
    "            cv2.drawContours(res, cnt, -1, (0,255,0), 3)\n",
    "\n",
    "            for obj_name in object_contour:\n",
    "                # find the child contour on wich parrent contour\n",
    "                if cv2.pointPolygonTest(object_contour[obj_name], (x, y), measureDist=True) > 0 :\n",
    "                    object_count[obj_name] += 1\n",
    "\n",
    "\n",
    "for obj_name in object_count:\n",
    "    x, y, w, h = cv2.boundingRect(object_contour[obj_name])\n",
    "    # check if number of child contour inside parrent less than threshold count \n",
    "    if object_count[obj_name] < THRESHOLD_COUNT :\n",
    "        img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                    font_size=0.7, alpha=0.6, bg_color=(0,0,255), ouline_color=(0,0,255), text_color=(0,0,0))\n",
    "    else :\n",
    "        img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                    font_size=0.7, alpha=0.6, bg_color=(0,255,0), ouline_color=(0,255,0), text_color=(0,0,0))        \n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(res[:,:,::-1])\n",
    "plt.title(\"Result\")\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Implementation in Video Stream"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 3.2.1 | Apply Contour Based Visual Inspection Engine for Video Stream\n",
    "\n",
    "# Uncomment this if using OpenGL for image rendering\n",
    "window_name_1 = \"Detected Object\"\n",
    "window_name_2 = \"Detected Contour\"\n",
    "cv2.namedWindow(window_name_1, flags=cv2.WINDOW_OPENGL)    # Window with OpenGL\n",
    "cv2.namedWindow(window_name_2, flags=cv2.WINDOW_OPENGL)    # Window with OpenGL\n",
    "\n",
    "# define range of gray color in HSV \n",
    "lower_gray = np.array([0, 0, 20])       # (part_a.jpg : [0, 0, 20] | part_b.jpg : [0, 0, 10])\n",
    "upper_gray = np.array([180, 100, 150])  # (part_a.jpg : [180, 100, 150]| part_b.jpg : [180, 100, 170])\n",
    "\n",
    "THRESHOLD_COUNT = 22 # min number of child contour  (part_a.jpg : 22 | part_b.jpg : 2)\n",
    "MIN_AREA = 100 # minimum number of pixel to be counted to reject small contour\n",
    "\n",
    "# Contour Property parameter for parent contour\n",
    "MAX_ASPECT_RATIO = 0.3 # (part_a.jpg : 0.3 | part_b.jpg : 0.5)\n",
    "MIN_ASPECT_RATIO = 0.1 # (part_a.jpg : 0.1 | part_b.jpg : 0.3)\n",
    "MIN_EXTENT = 0.4\n",
    "\n",
    "# Contour Property parameter for child contour\n",
    "MAX_ASPECT_RATIO_CHILD = 1.5\n",
    "MIN_ASPECT_RATIO_CHILD = 0.5\n",
    "MIN_EXTENT_CHILD = 0.4\n",
    "\n",
    "\n",
    "# load video file using GStreamer\n",
    "cap = cv2.VideoCapture(gst_file_loader(\"video_a.mp4\", useRotate90=True), cv2.CAP_GSTREAMER)  # backend GSTREAMER \n",
    "\n",
    "# cap = cv2.VideoCapture(\"video_a.mp4\", cv2.CAP_FFMPEG)  # backend FFMPEG\n",
    "# cap.set(cv2.CAP_PROP_ORIENTATION_AUTO, 1) # applicable for backend FFMPEG only\n",
    "\n",
    "times = []\n",
    "while cap.isOpened() :\n",
    "    object_contour = {}\n",
    "    object_count = {}\n",
    "    object_id = 0 \n",
    "\n",
    "    e1 = cv2.getTickCount()\n",
    "    ret, img = cap.read()\n",
    "    if not ret : \n",
    "        break \n",
    "\n",
    "    #convert to hsv\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Threshold the HSV image to get only gray colors\n",
    "    mask = cv2.inRange(hsv.copy(), lower_gray, upper_gray)\n",
    "\n",
    "    # apply eroding into mask\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    erosion = cv2.erode(mask, kernel, iterations = 2)\n",
    "\n",
    "    # apply bitwise operation (for background removal), if needed.\n",
    "    res = cv2.bitwise_and(img, img, mask=erosion)\n",
    "\n",
    "    # find contour from range thresholding\n",
    "    contours, hierarchy = cv2.findContours(erosion, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    for cnt, hrcy in zip(contours, hierarchy[0]):\n",
    "        # find contour Area & boungin Rect\n",
    "        area = cv2.contourArea(cnt)\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "        # calculate aspectRatio & extent\n",
    "        aspectRatio = float(w)/h \n",
    "        rect_area = w*h\n",
    "        extent = float(area)/rect_area\n",
    "        \n",
    "        # filter a small contour\n",
    "        if area <= MIN_AREA:\n",
    "            continue \n",
    "        \n",
    "        # Find All Extreme Outer Contour [BLUE]\n",
    "        if hrcy[3] == -1 :   \n",
    "            if aspectRatio < MAX_ASPECT_RATIO and aspectRatio > MIN_ASPECT_RATIO and extent > MIN_EXTENT:      \n",
    "                cv2.drawContours(res, cnt, -1, (255,0,0), 2)\n",
    "                \n",
    "                object_contour[\"object_%d\" % object_id] = cnt # insert parent contour\n",
    "                object_count[\"object_%d\" % object_id] = 0 # set initinal count 0\n",
    "                object_id += 1\n",
    "\n",
    "        # Find All child contour [GREEN]\n",
    "        if hrcy[3] != -1 :  \n",
    "            if aspectRatio < MAX_ASPECT_RATIO_CHILD and aspectRatio > MIN_ASPECT_RATIO_CHILD and extent > MIN_EXTENT_CHILD:    \n",
    "                cv2.drawContours(res, cnt, -1, (0,255,0), 2)\n",
    "\n",
    "                for obj_name in object_contour:\n",
    "                    # find the child contour on wich parrent contour\n",
    "                    if cv2.pointPolygonTest(object_contour[obj_name], (x, y), measureDist=True) > 0 :\n",
    "                        object_count[obj_name] += 1\n",
    "\n",
    "\n",
    "    for obj_name in object_count:\n",
    "        x, y, w, h = cv2.boundingRect(object_contour[obj_name])\n",
    "        # check if number of child contour inside parrent less than threshold count \n",
    "        if object_count[obj_name] < THRESHOLD_COUNT :\n",
    "            img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                        font_size=0.4, alpha=0.6, bg_color=(0,0,255), ouline_color=(0,0,255), text_color=(0,0,0))\n",
    "        else :\n",
    "            img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                        font_size=0.4, alpha=0.6, bg_color=(0,255,0), ouline_color=(0,255,0), text_color=(0,0,0)) \n",
    "\n",
    "    cv2.imshow(window_name_1, img)\n",
    "    cv2.imshow(window_name_2, res)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "    e2 = cv2.getTickCount()\n",
    "    times.append((e2 - e1)/ cv2.getTickFrequency())\n",
    "\n",
    "time_avg = np.array(times).mean()\n",
    "print(\"Average execution time : %.4fs\" % time_avg)\n",
    "print(\"Average FPS : %.2f\" % (1/time_avg))\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result Benchmark\n",
    "- Contour Based Visual Inspection Engine for Video Stream (FFMPEG Backend) + Jetson Maximized Performance\n",
    "    - Average execution time : 0.2012s\n",
    "    - Average FPS : 4.97\n",
    "- Contour Based Visual Inspection Engine for Video Stream (GStreamer Backend) + Jetson Maximized Performance\n",
    "    - Average execution time : 0.1938s\n",
    "    - Average FPS : 5.16\n",
    "- Contour Based Visual Inspection Engine for Video Stream (FFMPEG Backend) + Jetson Maximized Performance + OpenGL Image Rendering\n",
    "    - Average execution time : 0.0604s\n",
    "    - Average FPS : 16.55"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 CUDA Implemetation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "########## EXAMPLE CUDA Implementation from Section 6 ##########\n",
    "\n",
    "# load image in Host memory\n",
    "img = cv2.imread(\"part_b.jpg\")\n",
    "h, w, c = img.shape\n",
    "\n",
    "# GPU memory initialization\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "hsv_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "hsv_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "h_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "h_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "s_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "s_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "v_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "v_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "mask_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "mask_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "res_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "res_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "\n",
    "# upload to GPU memory\n",
    "img_GpuMat.upload(img)\n",
    "\n",
    "# CUDA convert to hsv\n",
    "cv2.cuda.cvtColor(img_GpuMat, cv2.COLOR_BGR2HSV, hsv_GpuMat)\n",
    "\n",
    "# split HSV GPU Mat\n",
    "cv2.cuda.split(hsv_GpuMat, [h_GpuMat, s_GpuMat, v_GpuMat])\n",
    "\n",
    "# CUDA Threshold the V(20,150) ~ HSV GPU Mat to get only gray colors\n",
    "cv2.cuda.inRange(v_GpuMat, 20, 150, mask_GpuMat)\n",
    "\n",
    "# CUDA bitwise operation\n",
    "cv2.cuda.bitwise_not(img_GpuMat, res_GpuMat, mask=mask_GpuMat) # apply bitwise NOT to original image -> result image\n",
    "cv2.cuda.bitwise_not(res_GpuMat, res_GpuMat, mask=mask_GpuMat) # apply bitwise NOT to result image \n",
    "\n",
    "# Download Matrix to Host Memory                                                               \n",
    "mask = mask_GpuMat.download()\n",
    "res = res_GpuMat.download()\n",
    "\n",
    "# find contour\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "object_contour = {}\n",
    "object_count = {}\n",
    "object_id = 0\n",
    "\n",
    "THRESHOLD_COUNT = 22 # min number of child contour  (part_a.jpg : 22 | part_b.jpg : 2)\n",
    "MIN_AREA = 200 # minimum number of pixel to be counted to reject small contour\n",
    "\n",
    "# Contour Property parameter for parent contour\n",
    "MAX_ASPECT_RATIO = 0.3 # (part_a.jpg : 0.3 | part_b.jpg : 0.5)\n",
    "MIN_ASPECT_RATIO = 0.1 # (part_a.jpg : 0.1 | part_b.jpg : 0.3)\n",
    "MIN_EXTENT = 0.4\n",
    "\n",
    "# Contour Property parameter for child contour\n",
    "MAX_ASPECT_RATIO_CHILD = 1.5\n",
    "MIN_ASPECT_RATIO_CHILD = 0.5\n",
    "MIN_EXTENT_CHILD = 0.4\n",
    "\n",
    "for cnt, hrcy in zip(contours, hierarchy[0]):\n",
    "    # find contour Area & boungin Rect\n",
    "    area = cv2.contourArea(cnt)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # calculate aspectRatio & extent\n",
    "    aspectRatio = float(w)/h \n",
    "    rect_area = w*h\n",
    "    extent = float(area)/rect_area\n",
    "    \n",
    "    # filter a small contour\n",
    "    if area <= MIN_AREA:\n",
    "        continue \n",
    "    \n",
    "   # Find All Extreme Outer Contour [BLUE]\n",
    "    if hrcy[3] == -1 :   \n",
    "        if aspectRatio < MAX_ASPECT_RATIO and aspectRatio > MIN_ASPECT_RATIO and extent > MIN_EXTENT:      \n",
    "            cv2.drawContours(res, cnt, -1, (255,0,0), 3)\n",
    "            \n",
    "            object_contour[\"object_%d\" % object_id] = cnt # insert parent contour\n",
    "            object_count[\"object_%d\" % object_id] = 0 # set initinal count 0\n",
    "            object_id += 1\n",
    "\n",
    "    # Find All child contour [GREEN]\n",
    "    if hrcy[3] != -1 :  \n",
    "        if aspectRatio < MAX_ASPECT_RATIO_CHILD and aspectRatio > MIN_ASPECT_RATIO_CHILD and extent > MIN_EXTENT_CHILD:    \n",
    "            cv2.drawContours(res, cnt, -1, (0,255,0), 3)\n",
    "\n",
    "            for obj_name in object_contour:\n",
    "                # find the child contour on wich parrent contour\n",
    "                if cv2.pointPolygonTest(object_contour[obj_name], (x, y), measureDist=True) > 0 :\n",
    "                    object_count[obj_name] += 1\n",
    "\n",
    "\n",
    "for obj_name in object_count:\n",
    "    x, y, w, h = cv2.boundingRect(object_contour[obj_name])\n",
    "    # check if number of child contour inside parrent less than threshold count \n",
    "    if object_count[obj_name] < THRESHOLD_COUNT :\n",
    "        img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                    font_size=0.7, alpha=0.6, bg_color=(0,0,255), ouline_color=(0,0,255), text_color=(0,0,0))\n",
    "    else :\n",
    "        img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                    font_size=0.7, alpha=0.6, bg_color=(0,255,0), ouline_color=(0,255,0), text_color=(0,0,0)) \n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(res[:,:,::-1])\n",
    "plt.title(\"Result\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 3.3.1 | Apply CUDA Contour Based Visual Inspection Engine for Video Stream\n",
    "\n",
    "# Uncomment this if using OpenGL for image rendering\n",
    "window_name_1 = \"Detected Object\"\n",
    "window_name_2 = \"Detected Contour\"\n",
    "cv2.namedWindow(window_name_1, flags=cv2.WINDOW_OPENGL)    # Window with OpenGL\n",
    "cv2.namedWindow(window_name_2, flags=cv2.WINDOW_OPENGL)    # Window with OpenGL\n",
    "\n",
    "THRESHOLD_COUNT = 22 # min number of child contour  (part_a.jpg : 22 | part_b.jpg : 2)\n",
    "MIN_AREA = 100 # minimum number of pixel to be counted to reject small contour\n",
    "\n",
    "# Contour Property parameter for parent contour\n",
    "MAX_ASPECT_RATIO = 0.3 # (part_a.jpg : 0.3 | part_b.jpg : 0.5)\n",
    "MIN_ASPECT_RATIO = 0.1 # (part_a.jpg : 0.1 | part_b.jpg : 0.3)\n",
    "MIN_EXTENT = 0.4\n",
    "\n",
    "# Contour Property parameter for child contour\n",
    "MAX_ASPECT_RATIO_CHILD = 1.5\n",
    "MIN_ASPECT_RATIO_CHILD = 0.5\n",
    "MIN_EXTENT_CHILD = 0.4\n",
    "\n",
    "\n",
    "#load video file using GStreamer\n",
    "cap = cv2.VideoCapture(gst_file_loader(\"video_a.mp4\", useRotate90=True), cv2.CAP_GSTREAMER)  # backend GSTREAMER \n",
    "\n",
    "# cap = cv2.VideoCapture(\"video_a.mp4\", cv2.CAP_FFMPEG)  # backend FFMPEG\n",
    "# cap.set(cv2.CAP_PROP_ORIENTATION_AUTO, 1) # applicable for backend FFMPEG only\n",
    "\n",
    "\n",
    "# GPU memory initialization\n",
    "ret, img = cap.read()\n",
    "h, w, c = img.shape\n",
    "\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "hsv_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "hsv_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "h_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "h_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "s_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "s_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "v_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "v_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "mask_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "mask_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "res_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "res_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "\n",
    "# create CUDA eroding morphological transform object with kernel 3x3\n",
    "kernel = np.ones((2,2),np.uint8)\n",
    "MorphObj = cv2.cuda.createMorphologyFilter(cv2.MORPH_ERODE, cv2.CV_8UC1, kernel, iterations = 1)\n",
    "\n",
    "times = []\n",
    "while cap.isOpened() :\n",
    "    object_contour = {}\n",
    "    object_count = {}\n",
    "    object_id = 0 \n",
    "\n",
    "    e1 = cv2.getTickCount()\n",
    "    ret, img = cap.read()\n",
    "    if not ret : \n",
    "        break \n",
    "\n",
    "    # upload to GPU memory\n",
    "    img_GpuMat.upload(img)\n",
    "\n",
    "    # CUDA convert to hsv\n",
    "    cv2.cuda.cvtColor(img_GpuMat, cv2.COLOR_BGR2HSV, hsv_GpuMat)\n",
    "\n",
    "    # split HSV GPU Mat\n",
    "    cv2.cuda.split(hsv_GpuMat, [h_GpuMat, s_GpuMat, v_GpuMat])\n",
    "\n",
    "    # CUDA Threshold the V(20,150) ~ HSV GPU Mat to get only gray colors\n",
    "    cv2.cuda.inRange(v_GpuMat, 20, 150, mask_GpuMat)\n",
    "\n",
    "    # CUDA Eroding Morphological Transform\n",
    "    MorphObj.apply(mask_GpuMat, mask_GpuMat)\n",
    "\n",
    "    # CUDA bitwise operation\n",
    "    cv2.cuda.bitwise_not(img_GpuMat, res_GpuMat, mask=mask_GpuMat) # apply bitwise NOT to original image -> result image\n",
    "    cv2.cuda.bitwise_not(res_GpuMat, res_GpuMat, mask=mask_GpuMat) # apply bitwise NOT to result image \n",
    "\n",
    "    # Download Matrix to Host Memory                                                               \n",
    "    mask = mask_GpuMat.download()\n",
    "    res = res_GpuMat.download()\n",
    "\n",
    "    # find contour from range thresholding\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    for cnt, hrcy in zip(contours, hierarchy[0]):\n",
    "        # find contour Area & boungin Rect\n",
    "        area = cv2.contourArea(cnt)\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "        # calculate aspectRatio & extent\n",
    "        aspectRatio = float(w)/h \n",
    "        rect_area = w*h\n",
    "        extent = float(area)/rect_area\n",
    "        \n",
    "        # filter a small contour\n",
    "        if area <= MIN_AREA:\n",
    "            continue \n",
    "        \n",
    "        # Find All Extreme Outer Contour [BLUE]\n",
    "        if hrcy[3] == -1 :   \n",
    "            if aspectRatio < MAX_ASPECT_RATIO and aspectRatio > MIN_ASPECT_RATIO and extent > MIN_EXTENT:      \n",
    "                cv2.drawContours(res, cnt, -1, (255,0,0), 2)\n",
    "                \n",
    "                object_contour[\"object_%d\" % object_id] = cnt # insert parent contour\n",
    "                object_count[\"object_%d\" % object_id] = 0 # set initinal count 0\n",
    "                object_id += 1\n",
    "\n",
    "        # Find All child contour [GREEN]\n",
    "        if hrcy[3] != -1 :  \n",
    "            if aspectRatio < MAX_ASPECT_RATIO_CHILD and aspectRatio > MIN_ASPECT_RATIO_CHILD and extent > MIN_EXTENT_CHILD:    \n",
    "                cv2.drawContours(res, cnt, -1, (0,255,0), 2)\n",
    "\n",
    "                for obj_name in object_contour:\n",
    "                    # find the child contour on wich parrent contour\n",
    "                    if cv2.pointPolygonTest(object_contour[obj_name], (x, y), measureDist=True) > 0 :\n",
    "                        object_count[obj_name] += 1\n",
    "\n",
    "\n",
    "    for obj_name in object_count:\n",
    "        x, y, w, h = cv2.boundingRect(object_contour[obj_name])\n",
    "        # check if number of child contour inside parrent less than threshold count \n",
    "        if object_count[obj_name] < THRESHOLD_COUNT :\n",
    "            img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                        font_size=0.4, alpha=0.6, bg_color=(0,0,255), ouline_color=(0,0,255), text_color=(0,0,0))\n",
    "        else :\n",
    "            img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                        font_size=0.4, alpha=0.6, bg_color=(0,255,0), ouline_color=(0,255,0), text_color=(0,0,0)) \n",
    "\n",
    "    cv2.imshow(window_name_1, img)\n",
    "    cv2.imshow(window_name_2, res)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "    e2 = cv2.getTickCount()\n",
    "    times.append((e2 - e1)/ cv2.getTickFrequency())\n",
    "\n",
    "time_avg = np.array(times).mean()\n",
    "print(\"Average execution time : %.4fs\" % time_avg)\n",
    "print(\"Average FPS : %.2f\" % (1/time_avg))\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result Benchmark\n",
    "- CUDA Contour Based Visual Inspection Engine for Video Stream (FFMPEG Backend) + Jetson Maximized Performance\n",
    "    - Average execution time : 0.3222s\n",
    "    - Average FPS : 3.10\n",
    "- CUDA Contour Based Visual Inspection Engine for Video Stream (GStreamer Backend) + Jetson Maximized Performance\n",
    "    - Average execution time : 0.2777s\n",
    "    - Average FPS : 3.60\n",
    "- CUDA Contour Based Visual Inspection Engine for Video Stream (FFMPEG Backend) + Jetson Maximized Performance + OpenGL Image Rendering\n",
    "    - Average execution time : 0.0654s\n",
    "    - Average FPS : 15.30"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 4. Object Segmentation using OpenCV Tracking API"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# load GStreamer File Loader \n",
    "from gst_file import gst_file_loader\n",
    "\n",
    "# load video file using GStreamer \n",
    "cap = cv2.VideoCapture(gst_file_loader(\"video_a.mp4\", useRotate90=True), cv2.CAP_GSTREAMER)  \n",
    "\n",
    "# Choose tracker\n",
    "#tracker = cv2.TrackerCSRT_create()\n",
    "tracker = cv2.TrackerKCF_create()\n",
    "\n",
    "___, img = cap.read()\n",
    "\n",
    "# create initial bounding box\n",
    "bbox = cv2.selectROI(\"Tracking\",img,False)\n",
    "\n",
    "tracker.init(img, bbox)\n",
    "\n",
    "while cap.isOpened():\n",
    "    e1 = cv2.getTickCount()\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    if not ret : \n",
    "        break\n",
    "\n",
    "    success, bbox = tracker.update(img)\n",
    "\n",
    "    if success:\n",
    "        # draw bounding box\n",
    "        x ,y ,w ,h = np.int0(bbox)\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255,0,255), 3, 1)\n",
    "        cv2.putText(img, \"Tracking\", (75, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 1)\n",
    "    else:\n",
    "        cv2.putText(img,\"Lost\", (75, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 1)\n",
    "    \n",
    "    e2 = cv2.getTickCount()\n",
    "    fps = cv2.getTickFrequency()/(e2-e1)\n",
    "    \n",
    "    cv2.putText(img,\"%d FPS \" % fps, (75,50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 1)\n",
    "    cv2.imshow(\"Tracking\",img)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## 4.2 Combine Contour Based + Tracking API"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 4.2.1 | Apply OpenCV Tracking API + Contour Based Visual Inspection Engine for Video Stream\n",
    "\n",
    "# Uncomment this if using OpenGL for image rendering\n",
    "window_name_1 = \"Detected Object\"\n",
    "window_name_2 = \"Detected Contour\"\n",
    "# cv2.namedWindow(window_name_1, flags=cv2.WINDOW_OPENGL)    # Window with OpenGL\n",
    "# cv2.namedWindow(window_name_2, flags=cv2.WINDOW_OPENGL)    # Window with OpenGL\n",
    "\n",
    "# define range of gray color in HSV \n",
    "lower_gray = np.array([0, 0, 20])       # (part_a.jpg : [0, 0, 20] | part_b.jpg : [0, 0, 10])\n",
    "upper_gray = np.array([180, 100, 150])  # (part_a.jpg : [180, 100, 150]| part_b.jpg : [180, 100, 170])\n",
    "\n",
    "THRESHOLD_COUNT = 22 # min number of child contour  (part_a.jpg : 22 | part_b.jpg : 2)\n",
    "MIN_AREA = 100 # minimum number of pixel to be counted to reject small contour\n",
    "\n",
    "# Contour Property parameter for parent contour\n",
    "MAX_ASPECT_RATIO = 0.3 # (part_a.jpg : 0.3 | part_b.jpg : 0.5)\n",
    "MIN_ASPECT_RATIO = 0.1 # (part_a.jpg : 0.1 | part_b.jpg : 0.3)\n",
    "MIN_EXTENT = 0.4\n",
    "\n",
    "# Contour Property parameter for child contour\n",
    "MAX_ASPECT_RATIO_CHILD = 1.5\n",
    "MIN_ASPECT_RATIO_CHILD = 0.5\n",
    "MIN_EXTENT_CHILD = 0.4\n",
    "\n",
    "\n",
    "# load video file using GStreamer\n",
    "# cap = cv2.VideoCapture(gst_file_loader(\"video_a.mp4\", useRotate90=True), cv2.CAP_GSTREAMER)  # backend GSTREAMER \n",
    "\n",
    "cap = cv2.VideoCapture(\"video_a.mp4\", cv2.CAP_FFMPEG)  # backend FFMPEG\n",
    "cap.set(cv2.CAP_PROP_ORIENTATION_AUTO, 1) # applicable for backend FFMPEG only\n",
    "\n",
    "# Initialize OpenCV Tracking API\n",
    "tracker_green = cv2.TrackerKCF_create()\n",
    "tracker_red = cv2.TrackerKCF_create()\n",
    "is_tracker_green_available = False\n",
    "is_tracker_red_available = False\n",
    "print(\"Tracking started...\")\n",
    "\n",
    "\n",
    "times = []\n",
    "while cap.isOpened() :\n",
    "    object_contour = {}\n",
    "    object_count = {}\n",
    "    object_id = 0 \n",
    "\n",
    "    e1 = cv2.getTickCount()\n",
    "    ret, img = cap.read()\n",
    "    if not ret : \n",
    "        break \n",
    "\n",
    "    if not (is_tracker_green_available or is_tracker_red_available):\n",
    "        #convert to hsv\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Threshold the HSV image to get only gray colors\n",
    "        mask = cv2.inRange(hsv.copy(), lower_gray, upper_gray)\n",
    "\n",
    "        # apply eroding into mask\n",
    "        kernel = np.ones((2,2),np.uint8)\n",
    "        erosion = cv2.erode(mask, kernel, iterations = 2)\n",
    "\n",
    "        # apply bitwise operation (for background removal), if needed.\n",
    "        res = cv2.bitwise_and(img, img, mask=erosion)\n",
    "\n",
    "        # find contour from range thresholding\n",
    "        contours, hierarchy = cv2.findContours(erosion, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        for cnt, hrcy in zip(contours, hierarchy[0]):\n",
    "            # find contour Area & boungin Rect\n",
    "            area = cv2.contourArea(cnt)\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "            # calculate aspectRatio & extent\n",
    "            aspectRatio = float(w)/h \n",
    "            rect_area = w*h\n",
    "            extent = float(area)/rect_area\n",
    "            \n",
    "            # filter a small contour\n",
    "            if area <= MIN_AREA:\n",
    "                continue \n",
    "            \n",
    "            # Find All Extreme Outer Contour [BLUE]\n",
    "            if hrcy[3] == -1 :   \n",
    "                if aspectRatio < MAX_ASPECT_RATIO and aspectRatio > MIN_ASPECT_RATIO and extent > MIN_EXTENT:      \n",
    "                    cv2.drawContours(res, cnt, -1, (255,0,0), 2)\n",
    "                    \n",
    "                    object_contour[\"object_%d\" % object_id] = cnt # insert parent contour\n",
    "                    object_count[\"object_%d\" % object_id] = 0 # set initinal count 0\n",
    "                    object_id += 1\n",
    "\n",
    "            # Find All child contour [GREEN]\n",
    "            if hrcy[3] != -1 :  \n",
    "                if aspectRatio < MAX_ASPECT_RATIO_CHILD and aspectRatio > MIN_ASPECT_RATIO_CHILD and extent > MIN_EXTENT_CHILD:    \n",
    "                    cv2.drawContours(res, cnt, -1, (0,255,0), 2)\n",
    "\n",
    "                    for obj_name in object_contour:\n",
    "                        # find the child contour on wich parrent contour\n",
    "                        if cv2.pointPolygonTest(object_contour[obj_name], (x, y), measureDist=True) > 0 :\n",
    "                            object_count[obj_name] += 1\n",
    "\n",
    "\n",
    "        for obj_name in object_count:\n",
    "            x, y, w, h = cv2.boundingRect(object_contour[obj_name])\n",
    "            # check if number of child contour inside parrent less than threshold count \n",
    "            if object_count[obj_name] < THRESHOLD_COUNT :\n",
    "                try :\n",
    "                    tracker_red.init(img, [x, y, w, h])\n",
    "                    is_tracker_red_available = True\n",
    "                except : \n",
    "                    pass\n",
    "                img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                            font_size=0.4, alpha=0.6, bg_color=(0,0,255), ouline_color=(0,0,255), text_color=(0,0,0))\n",
    "            else :\n",
    "                try :\n",
    "                    tracker_green.init(img, [x, y, w, h])\n",
    "                    is_tracker_green_available = True\n",
    "                except : \n",
    "                    pass\n",
    "                img = draw_ped(img, \"%s (%d)\" % (obj_name, object_count[obj_name])  , x, y, x+w, y+h, \n",
    "                            font_size=0.4, alpha=0.6, bg_color=(0,255,0), ouline_color=(0,255,0), text_color=(0,0,0)) \n",
    "\n",
    "    elif is_tracker_red_available : \n",
    "        try :\n",
    "            is_tracker_red_available, bbox_red = tracker_red.update(img)\n",
    "            if is_tracker_red_available :\n",
    "                x ,y ,w ,h = np.int0(bbox_red)\n",
    "                img = draw_ped(img, \"Tracking - 1\"  , x, y, x+w, y+h, \n",
    "                            font_size=0.4, alpha=0.6, bg_color=(0,0,255), ouline_color=(0,0,255), text_color=(0,0,0))\n",
    "        except : \n",
    "            pass\n",
    "        \n",
    "    elif is_tracker_green_available : \n",
    "        try :\n",
    "            is_tracker_green_available, bbox_green = tracker_green.update(img)\n",
    "            if is_tracker_green_available :\n",
    "                x ,y ,w ,h = np.int0(bbox_green)\n",
    "                img = draw_ped(img, \"Tracking - 2\"  , x, y, x+w, y+h, \n",
    "                            font_size=0.4, alpha=0.6, bg_color=(0,0,255), ouline_color=(0,0,255), text_color=(0,0,0))\n",
    "        except :\n",
    "            pass\n",
    "\n",
    "    cv2.imshow(window_name_1, img)\n",
    "    cv2.imshow(window_name_2, res)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    e2 = cv2.getTickCount()\n",
    "    times.append((e2 - e1)/ cv2.getTickFrequency())\n",
    "\n",
    "time_avg = np.array(times).mean()\n",
    "print(\"Average execution time : %.4fs\" % time_avg)\n",
    "print(\"Average FPS : %.2f\" % (1/time_avg))\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}