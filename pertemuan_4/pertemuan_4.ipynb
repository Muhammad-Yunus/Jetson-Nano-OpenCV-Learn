{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pertemuan 4\n",
    "- Image Blending\n",
    "- Image Bitwise Operation\n",
    "- Range Thresholding\n",
    "- Canny Edge Detection\n",
    "\n",
    "___\n",
    "\n",
    "### Maximizing Jetson Nano Perfomance\n",
    "```\n",
    "sudo nvpmodel -m 0\n",
    "sudo jetson_clocks\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 1. Image Blending\n",
    "Image blending formula, <br>\n",
    "$g(x)=(1−α)f0(x)+αf1(x)$ <br><br>\n",
    "$f0$ is the first image, $f1$ is the second image, <br>\n",
    "and $α$ is *temporal cross-dissolve* parameter between the two image, where α  value between 0→1. <br><br>\n",
    "- function `cv2.addWeighted(src1, alpha, src2, beta, gamma, dst)`\n",
    "- where : \n",
    "    - `src1` : First source array.\n",
    "    - `alpha` : Weight for the first array elements.\n",
    "    - `src2` : Second source array of the same size and channel number as src1 .\n",
    "    - `beta` : Weight for the second array elements.\n",
    "    - `gamma` : Scalar added to each sum.\n",
    "    - `dst` : Destination array that has the same size and number of channels as the input arrays."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "alpha = 0.5\n",
    "\n",
    "img1 = cv2.imread('lena.jpg')\n",
    "img2 = cv2.imread('apple.jpg')\n",
    "    \n",
    "beta = (1.0 - alpha)\n",
    "blending_img = cv2.addWeighted(img1, alpha, img2, beta, 0.0)\n",
    "\n",
    "cv2.imshow('Blending Result', blending_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Overlay Transparent Shape "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Example Overlay Transparent Shape\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "overlay = np.zeros_like(img)\n",
    "cv2.rectangle(overlay, (80,50), (300,320), (255, 0, 0), -1) # add blue overlay\n",
    "\n",
    "img_blend = cv2.addWeighted(img, 1, overlay, alpha, 0.0)\n",
    "\n",
    "cv2.imshow(\"Overlay Image\", img_blend)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Bounding Box Detection Transparent"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Example Bounding Box Detection Transparent\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "pts = np.array([[80,30], [200, 30], [210,50], [80,50]])\n",
    "overlay = np.zeros_like(img)\n",
    "cv2.rectangle(overlay, (80,50), (300,320), (255, 0, 0), -1) # add blue overlay\n",
    "cv2.fillPoly(overlay, [pts], (255, 255, 255)) # add label blue overlay\n",
    "cv2.rectangle(overlay, (80,50), (300,320), (255, 255, 255), 2) # add white border\n",
    "cv2.polylines(overlay, [pts], True, (255, 255, 255), 2) # add label white border\n",
    "cv2.putText(overlay,  \"lena (98%)\", (85, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "img_blend = cv2.addWeighted(img, 1, overlay, alpha, 0.0)\n",
    "\n",
    "cv2.imshow(\"Overlay Image\", img_blend)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Bounding Box Detection Half Transparent"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Example Bounding Box Detection Half Transparent\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "pts = np.array([[80,30], [200, 30], [210,50], [80,50]])\n",
    "overlay = np.zeros_like(img)\n",
    "cv2.rectangle(overlay, (80,50), (300,320), (255, 0, 0), -1) # add blue overlay\n",
    "cv2.fillPoly(img, [pts], (255, 255, 255)) # add label blue overlay\n",
    "cv2.rectangle(overlay, (80,50), (300,320), (255, 255, 255), 2) # add white border\n",
    "cv2.polylines(img, [pts], True, (255, 255, 255), 2) # add label white border\n",
    "cv2.putText(img,  \"lena (98%)\", (85, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "img_blend = cv2.addWeighted(img, 1, overlay, alpha, 0.0)\n",
    "\n",
    "cv2.imshow(\"Overlay Image\", img_blend)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Modifying draw_ped() "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# previous draw_ped() implementation in Training Jetson Nano Object Detection\n",
    "\n",
    "def draw_ped(img, label, x0, y0, xt, yt, font_size=0.4, color=(255,127,0), text_color=(255,255,255)):\n",
    "\n",
    "    y0, yt = max(y0 - 15, 0) , min(yt + 15, img.shape[0])\n",
    "    x0, xt = max(x0 - 15, 0) , min(xt + 15, img.shape[1])\n",
    "\n",
    "    (w, h), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_size, 1)\n",
    "    cv2.rectangle(img,\n",
    "                    (x0, y0 + baseline),  \n",
    "                    (max(xt, x0 + w), yt), \n",
    "                    color, \n",
    "                    2)\n",
    "    cv2.rectangle(img,\n",
    "                    (x0, y0 - h - baseline),  \n",
    "                    (x0 + w, y0 + baseline), \n",
    "                    color, \n",
    "                    -1)\n",
    "    cv2.rectangle(img,\n",
    "                    (x0, y0 - h - baseline),  \n",
    "                    (x0 + w, y0 + baseline), \n",
    "                    color, \n",
    "                    2)  \n",
    "    cv2.putText(img, \n",
    "                label, \n",
    "                (x0, y0),                   \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "                font_size,                          \n",
    "                text_color,                \n",
    "                1,\n",
    "                cv2.LINE_AA) \n",
    "    return img"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "# draw_ped(img, label, x0, y0, xt, yt, ...)\n",
    "img = draw_ped(img, \"lena (98%)\", 80, 50, 300, 320)\n",
    "\n",
    "cv2.imshow(\"Draw Ped Original\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Modified draw_ped() implementation using image blending\n",
    "\n",
    "def draw_ped(img, label, x0, y0, xt, yt, font_size=0.4, alpha=0.5, bg_color=(255,0,0), ouline_color=(255,255,255), text_color=(0,0,0)):\n",
    "    overlay = np.zeros_like(img)\n",
    "\n",
    "    y0, yt = max(y0 - 15, 0) , min(yt + 15, img.shape[0])\n",
    "    x0, xt = max(x0 - 15, 0) , min(xt + 15, img.shape[1])\n",
    "\n",
    "    (w, h), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_size, 1)\n",
    "    cv2.rectangle(overlay,\n",
    "                    (x0, y0 + baseline),  \n",
    "                    (max(xt, x0 + w), yt), \n",
    "                    bg_color, \n",
    "                    -1)\n",
    "    cv2.rectangle(overlay,\n",
    "                    (x0, y0 + baseline),  \n",
    "                    (max(xt, x0 + w), yt), \n",
    "                    ouline_color, \n",
    "                    2)\n",
    "    pts = np.array([[x0, y0 - h - baseline], # top left\n",
    "                    [x0 + w, y0 - h - baseline], # top right\n",
    "                    [x0 + w + 10, y0 + baseline], # bolom right\n",
    "                    [x0,y0 + baseline]]) # bottom left\n",
    "    cv2.fillPoly(img, [pts], ouline_color) # add label white fill\n",
    "    cv2.polylines(img, [pts], True, ouline_color, 2) # add label white border \n",
    "    cv2.putText(img, \n",
    "                label, \n",
    "                (x0, y0),                   \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "                font_size,                          \n",
    "                text_color,                \n",
    "                1,\n",
    "                cv2.LINE_AA) \n",
    "\n",
    "    img_blend = cv2.addWeighted(img, 1, overlay, alpha, 0.0)\n",
    "\n",
    "    return img_blend"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "# draw_ped(img, label, x0, y0, xt, yt, ....)\n",
    "img = draw_ped(img, \"lena (98%)\", 80, 50, 300, 320, \n",
    "                font_size=0.4, alpha=0.5, bg_color=(255,0,0), ouline_color=(255,255,255), text_color=(0,0,0))\n",
    "\n",
    "cv2.imshow(\"Draw Ped Original\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 CUDA Implementation Image Blending\n",
    "- function `cv2.cuda.addWeighted(src1, alpha, src2, beta, gamma, dst)`\n",
    "- where : \n",
    "    - `src1` : First source array / GPU Mat.\n",
    "    - `alpha` : Weight for the first array elements.\n",
    "    - `src2` : Second source array of the same size and channel number as src1 / GPU Mat.\n",
    "    - `beta` : Weight for the second array elements.\n",
    "    - `gamma` : Scalar added to each sum.\n",
    "    - `dst` : Destination array that has the same size and number of channels as the input arrays / GPU Mat."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "alpha = 0.5\n",
    "\n",
    "img1 = cv2.imread('lena.jpg')\n",
    "img2 = cv2.imread('apple.jpg')\n",
    "h, w, c = img1.shape \n",
    "\n",
    "img1_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img1_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "img2_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img2_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "blending_img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "blending_img_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "\n",
    "# Upload to GPU memory\n",
    "img1_GpuMat.upload(img1)\n",
    "img2_GpuMat.upload(img2)\n",
    "\n",
    "beta = (1.0 - alpha)\n",
    "cv2.cuda.addWeighted(img1_GpuMat, alpha, img2_GpuMat, beta, 0.0, blending_img_GpuMat)\n",
    "\n",
    "# Download to Host memory\n",
    "blending_img = blending_img_GpuMat.download()\n",
    "\n",
    "\n",
    "cv2.imshow('Blending Result', blending_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 2. Image Bitwise Operation\n",
    "\n",
    "- Highly useful while extracting any part of the image, defining and working with **non-rectangular ROI** (region of interest). <br>\n",
    "<img src=\"res/sssample_mask.png\" style=\"width:500px; margin-top:10px\"></img><br>\n",
    "- Review **Bitwise Operation** (AND, OR, NOT, and XOR operation).<br>\n",
    "<img src=\"res/bitwise_operator.jpg\" style=\"width:500px; margin-top:10px\"></img><br>\n",
    "- Method :\n",
    "    - Bitwise AND : `cv2.bitwise_and(img1, img2, mask)`\n",
    "    - Bitwise OR : `cv2.bitwise_or(img1, img2, mask)`\n",
    "    - Bitwise NOT : `cv2.bitwise_not(img1, mask)` , only one image required.\n",
    "    - Bitwise XOR : `cv2.bitwise_xor(img1, img2, mask)`\n",
    "- with parameter :\n",
    "    - `img1` : input image 1\n",
    "    - `img2` : input image 2\n",
    "    - `mask` : optional operation mask, **8-bit single channel** array, that specifies **elements of the output array to be changed**. <br>\n",
    "    <img src=\"res/mask_hand.png\" style=\"width:200px; margin-top:10px\"></img>\n",
    "    \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Create Masking Circle"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask = np.zeros((300,300), np.uint8) # create black image using numpy\n",
    "cv2.circle(mask, (150, 150), 80, (255, 255,  255), -1) # draw circle in mask\n",
    "\n",
    "# show \n",
    "cv2.imshow('Circle Mask', mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Apply masking to image using bitwise and"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Crop Lena face in Circle ROI\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "h, w, c = img.shape\n",
    "\n",
    "mask = np.zeros((h,w), np.uint8) # create black image using numpy\n",
    "cv2.circle(mask, (w//2, h//2), 150, (255, 255,  255), -1) # draw circle in mask\n",
    "\n",
    "res = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "# show \n",
    "cv2.imshow('Circle Mask', res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- what happend if we use different image on `cv2.bitwise_and` ?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img1 = cv2.imread(\"lena.jpg\")\n",
    "img2 = cv2.imread(\"apple.jpg\")\n",
    "h, w, c = img1.shape\n",
    "\n",
    "mask = np.zeros((h,w), np.uint8) # create black image using numpy\n",
    "cv2.circle(mask, (w//2, h//2), 150, (255, 255,  255), -1) # draw circle in mask\n",
    "\n",
    "res = cv2.bitwise_and(img1, img2, mask=mask)\n",
    "\n",
    "# show \n",
    "plt.figure(figsize=(20,7))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"Original Image 1\")\n",
    "plt.imshow(img1[:,:,::-1])\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"Original Image 2\")\n",
    "plt.imshow(img2[:,:,::-1])\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"Masking Image\")\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"Bitwise Result\")\n",
    "plt.imshow(res[:,:,::-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Create Masking Polyfill"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask = np.ones((720, 960), np.uint8) # create black image using numpy\n",
    "pts= np.array([[290,460],\n",
    "                [530, 460],\n",
    "                [900, 690],\n",
    "                [60, 690]])\n",
    "cv2.fillPoly(mask, [pts], (255, 255,  255)) # draw polyfill in mask\n",
    "\n",
    "# show \n",
    "cv2.imshow('Polyfill Mask', mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Apply masking to image using bitwise and"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Crop Highway roadline in polygon shape\n",
    "\n",
    "img = cv2.imread(\"highway.png\")\n",
    "h, w, c = img.shape\n",
    "\n",
    "mask = np.zeros((h, w), np.uint8) # create black image using numpy\n",
    "pts= np.array([[290,460],\n",
    "                [530, 460],\n",
    "                [900, 690],\n",
    "                [60, 690]])\n",
    "cv2.fillPoly(mask, [pts], (255, 255,  255)) # draw polyfill in mask\n",
    "\n",
    "res = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "# show \n",
    "plt.figure(figsize=(20,7))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:,:,::-1])\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Masking Image\")\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Bitwise Result\")\n",
    "plt.imshow(res[:,:,::-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 CUDA Implementation Image Bitwise Operation\n",
    "\n",
    "- Method :\n",
    "    - Bitwise AND : `cv2.cuda.bitwise_and(img1, img2, dst, mask)`\n",
    "    - Bitwise OR : `cv2.cuda.bitwise_or(img1, img2, dst, mask)`\n",
    "    - Bitwise NOT : `cv2.cuda.bitwise_not(img1, dst, mask)` , only one image required.\n",
    "    - Bitwise XOR : `cv2.cuda.bitwise_xor(img1, img2, dst, mask)`\n",
    "- with parameter :\n",
    "    - `img1` : input image 1 (GPU Mat)\n",
    "    - `img2` : input image 2 (GPU Mat)\n",
    "    - `dst` : output image (GPU Mat)\n",
    "    - `mask` : optional operation mask, **8-bit single channel** array, that specifies **elements of the output array to be changed** (GPU Mat). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "alpha = 0.5\n",
    "\n",
    "img = cv2.imread('highway.png')\n",
    "h, w, c = img.shape\n",
    "\n",
    "# create mask\n",
    "mask = np.zeros((h, w), np.uint8) # create black image using numpy\n",
    "pts= np.array([[290,460],\n",
    "                [530, 460],\n",
    "                [900, 690],\n",
    "                [60, 690]])\n",
    "cv2.fillPoly(mask, [pts], (255, 255,  255)) # draw polyfill in mask\n",
    "\n",
    "# GPU memory initialization\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "mask_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "mask_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "res_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "res_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "\n",
    "# Upload to GPU memory\n",
    "img_GpuMat.upload(img)\n",
    "mask_GpuMat.upload(mask)\n",
    "\n",
    "# apply CUDA bitwise operation \n",
    "# bitwise AND, OR & XOR ERROR - OpenCV 4.4.0\n",
    "cv2.cuda.bitwise_not(img_GpuMat, res_GpuMat, mask=mask_GpuMat) # apply bitwise NOT to original image -> result image\n",
    "cv2.cuda.bitwise_not(res_GpuMat, res_GpuMat, mask=mask_GpuMat) # apply bitwise NOT to result image \n",
    "                                                               # (now, color is the same as original)\n",
    "\n",
    "# Download to Host memory\n",
    "res = res_GpuMat.download()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:,:,::-1])\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Masking Image\")\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"CUDA Bitwise Result\")\n",
    "plt.imshow(res[:,:,::-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 Use Simple Thresholding to create Mask"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img = cv2.imread(\"Tomat.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "res = cv2.bitwise_and(img, img, mask=thresh)\n",
    "\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:,:,::-1])\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Masking Image\")\n",
    "plt.imshow(thresh, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Bitwise And Result\")\n",
    "plt.imshow(res[:,:,::-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 3. Range Thresholding\n",
    "- Image thresholding using `cv2.threshold()` function. <br>\n",
    "<img src=\"res/Binary_Thresh.png\" style=\"width: 500px; margin-top:10px;\" > </img>\n",
    "- Now we will learn how to do **range based thresholding** using  `cv2.inRange()` function. <br>\n",
    "<img src=\"res/Range_Thresh_.png\" style=\"width: 500px; margin-top:10px;\" > </img>\n",
    "- The concept remains the same, but now we add a range of pixel values we need.\n",
    "- Method `cv2.inRange(img, lower_color, upper_color)`\n",
    "- where theparameter :\n",
    "    - `img` : input image (HSV color space)\n",
    "    - `lower_color` : tuple (H, S, V) of lower color \n",
    "    - `upper_color` : tuple (H, S, V) of upper color \n",
    "- `H, S, V` value range in OpenCV:\n",
    "    - `H` (0 - 180)\n",
    "    - `S` (0 - 255)\n",
    "    - `V` (0 - 255)\n",
    "- `cv2.inRange()` using **HSV colorspace**, since the **hue channel** models the **color type**, it is very useful in image processing tasks that need to **segment objects based on its color**.<br>\n",
    "<img src=\"res/Threshold_inRange_HSV_colorspace.jpg\" style=\"width: 300px; margin-top:10px;\" > </img>\n",
    "- Since colors in the **RGB colorspace** are coded using the **three channels**, it is **more difficult** to segment an object in the image based on its color.<br>\n",
    "<img src=\"res/Threshold_inRange_RGB_colorspace.jpg\" style=\"width: 300px; margin-top:10px;\" > </img>\n",
    "- **HSV colorspace** model : <br>\n",
    "<img src=\"res/HSV_hue_model.png\" style=\"width: 300px; margin-top:10px;\" > </img>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 Convert to HSV Color space\n",
    "- Conver RGB value to HSV (`cv2.cvtColor()`)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "blue = np.uint8([[[0,255,0 ]]]) # single pixel green color RGB\n",
    "\n",
    "hsv_blue = cv2.cvtColor(blue, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "print( hsv_blue )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- HSV Color Range for Range Thresholding "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# define range of blue color in HSV\n",
    "lower_blue = np.array([110, 50, 50])\n",
    "upper_blue = np.array([130, 255, 255])\n",
    "\n",
    "# define range of red color in HSV\n",
    "lower_red = np.array([-10, 50, 50])\n",
    "upper_red = np.array([10, 255, 255])\n",
    "\n",
    "# define range of green color in HSV\n",
    "lower_green = np.array([35, 50, 25])\n",
    "upper_green = np.array([70, 255, 255])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img = cv2.imread('blocks.jpg')\n",
    "\n",
    "#convert to hsv\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Threshold the HSV image to get only green colors\n",
    "mask = cv2.inRange(hsv.copy(), lower_red, upper_red)\n",
    "\n",
    "# apply thresholding result to bitwise and as mask\n",
    "res = cv2.bitwise_and(img, img, mask= mask)\n",
    "\n",
    "# show result\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:,:,::-1])\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Masking Image\")\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Segmented Image\")\n",
    "plt.imshow(res[:,:,::-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Combine multiple color range in one detection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img = cv2.imread('Tomat.jpg')\n",
    "\n",
    "#convert to hsv\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Threshold the HSV image to get only red, green & blue colors\n",
    "mask_blue = cv2.inRange(hsv.copy(), lower_blue, upper_blue)\n",
    "mask_green = cv2.inRange(hsv.copy(), lower_green, upper_green)\n",
    "mask_red = cv2.inRange(hsv.copy(), lower_red, upper_red)\n",
    "\n",
    "# combine all mask\n",
    "mask = mask_blue + mask_green + mask_red\n",
    "\n",
    "# apply thresholding result to bitwise and as mask\n",
    "res = cv2.bitwise_and(img, img, mask= mask)\n",
    "\n",
    "# show result\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:,:,::-1])\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Masking Image\")\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Segmented Image\")\n",
    "plt.imshow(res[:,:,::-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 CUDA Implementation Range Thresholding \n",
    "## !!! cv2.cuda.inRange only implemented on OpenCV 4.5.2 or above !!!\n",
    "- Method `cv2.cuda.inRange(img, lower_color, upper_color, dst)`\n",
    "- where theparameter :\n",
    "    - `img` : input image (HSV color space) in GPU Mat\n",
    "    - `lower_color` : tuple (H, S, V) of lower color \n",
    "    - `upper_color` : tuple (H, S, V) of upper color \n",
    "    - `dst` : output image (HSV Color Space) in GPU Mat\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img = cv2.imread('blocks.jpg')\n",
    "h, w, c = img.shape\n",
    "\n",
    "# GPU memory initialization\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "hsv_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "hsv_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "mask_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "mask_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "res_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "res_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "\n",
    "# upload to GPU memory\n",
    "img_GpuMat.upload(img)\n",
    "\n",
    "#convert to hsv\n",
    "cv2.cuda.cvtColor(img_GpuMat, cv2.COLOR_BGR2HSV, hsv_GpuMat)\n",
    "\n",
    "# Threshold the HSV image to get only colors\n",
    "cv2.cuda.inRange(hsv_GpuMat, lower_blue, upper_blue, mask_GpuMat)\n",
    "\n",
    "# apply thresholding result to bitwise and as mask\n",
    "cv2.cuda.bitwise_and(img_GpuMat, img_GpuMat, res_GpuMat, mask= mask_GpuMat)\n",
    "\n",
    "# Download to Host Memory\n",
    "mask = mask_GpuMat.download()\n",
    "res = res_GpuMat.download()\n",
    "\n",
    "# show result\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:,:,::-1])\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Masking Image\")\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Segmented Image\")\n",
    "plt.imshow(res[:,:,::-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 4. Canny Edge Detection\n",
    "\n",
    "- Canny Edge detection is most popular edge detection algorithm. \n",
    "- Can be used to find the edges of objects in the image.\n",
    "- Canny Edge detection is illustrated as follows,<br>\n",
    "![](res/canny.png)<br><br>\n",
    "- method `cv2.Canny(img, threshMin, threshMax)`\n",
    "- where : \n",
    "    - `img` : input image\n",
    "    - `threshMin` : minimum threshold for the hysteresis procedure.\n",
    "    - `threshMax` : maximum threshold for the hysteresis procedure."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 1 : Find Edge image from Grayscale image\n",
    "\n",
    "img = cv2.imread('blocks.jpg')\n",
    "\n",
    "# convert to Gray\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Apply canny edge detection from grayscale image\n",
    "edged = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "#show image \n",
    "# show result\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:,:,::-1])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Edged Image\")\n",
    "plt.imshow(edged, cmap=\"gray\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 2 : Find Edge image from Binary Image\n",
    "\n",
    "img = cv2.imread('blocks.jpg')\n",
    "\n",
    "# convert to Gray\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply simple binary thresholding\n",
    "_, thresh = cv2.threshold(gray, 230, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "#Apply canny edge detection from grayscale image\n",
    "edged = cv2.Canny(thresh, 100, 250)\n",
    "\n",
    "#show image \n",
    "# show result\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:,:,::-1])\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Gray Image\")\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Binary Image\")\n",
    "plt.imshow(thresh, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"Edged Image\")\n",
    "plt.imshow(edged, cmap=\"gray\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXAMPLE 3 : Find Edge image from Range Thresholding\n",
    "\n",
    "img = cv2.imread('Tomat.jpg')\n",
    "\n",
    "#convert to hsv\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Threshold the HSV image to get only red, green & blue colors\n",
    "mask_blue = cv2.inRange(hsv.copy(), lower_blue, upper_blue)\n",
    "mask_green = cv2.inRange(hsv.copy(), lower_green, upper_green)\n",
    "mask_red = cv2.inRange(hsv.copy(), lower_red, upper_red)\n",
    "\n",
    "# combine all mask\n",
    "mask = mask_blue + mask_green + mask_red\n",
    "\n",
    "#Apply canny edge detection from grayscale image\n",
    "edged = cv2.Canny(mask, 100, 250)\n",
    "\n",
    "#show image \n",
    "# show result\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:,:,::-1])\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Binary Image (Range Thresholding)\")\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Edged Image\")\n",
    "plt.imshow(edged, cmap=\"gray\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 CUDA Implementation Canny Edge Detection\n",
    "- Create Canny Detector Object using `cv2.cuda.createCannyEdgeDetector(threshMin, threshMax)`\n",
    "- Where : \n",
    "    - `threshMin` : minimum threshold for the hysteresis procedure.\n",
    "    - `threshMax` : maximum threshold for the hysteresis procedure.\n",
    "\n",
    "- Call `.detect(src, dst)` to get edged image.\n",
    "- where :\n",
    "    - `src` : source image (GPU Mat)\n",
    "    - `dst` : output image (GPU Mat)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Example CUDA Canny Edge Detection from Binary Image (Simple Thresholding)\n",
    "img = cv2.imread('blocks.jpg')\n",
    "h, w, c = img.shape\n",
    "\n",
    "\n",
    "# GPU memory initialization\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "gray_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "gray_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "thresh_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "thresh_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "edged_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "edged_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "\n",
    "Canny = cv2.cuda.createCannyEdgeDetector(100, 250) # Initialize Canny Detector in CUDA\n",
    "\n",
    "# upload to GPU memory\n",
    "img_GpuMat.upload(img)\n",
    "\n",
    "# convert to Gray using CUDA\n",
    "cv2.cuda.cvtColor(img_GpuMat, cv2.COLOR_BGR2GRAY, gray_GpuMat)\n",
    "\n",
    "# Apply simple binary thresholding using CUDA\n",
    "cv2.cuda.threshold(gray_GpuMat, 230, 255, cv2.THRESH_BINARY, thresh_GpuMat)\n",
    "\n",
    "# Apply Canny Object Detection using CUDA\n",
    "Canny.detect(thresh_GpuMat, edged_GpuMat) \n",
    "\n",
    "# Download to Host Memory\n",
    "gray =gray_GpuMat.download()\n",
    "thresh = thresh_GpuMat.download()\n",
    "edged = edged_GpuMat.download()\n",
    "\n",
    "# show result\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img[:,:,::-1])\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Gray Image\")\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Binary Image\")\n",
    "plt.imshow(thresh, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"Edged Image\")\n",
    "plt.imshow(edged, cmap=\"gray\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}