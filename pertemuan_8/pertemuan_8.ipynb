{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pertemuan 8\n",
    "\n",
    "- Geometric Transformation\n",
    "    - Warp Affine\n",
    "    - Rotation\n",
    "    - Translation\n",
    "    - Affine Transform\n",
    "    - Perspective Transform\n",
    "    - CUDA Implementation\n",
    "\n",
    "___\n",
    "### Maximizing Jetson Nano Perfomance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sudo nvpmodel -m 0\n",
    "# sudo jetson_clocks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# check OpenCV Version\n",
    "\n",
    "cv2.__version__"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 1. Geometric Transformation\n",
    "- Geometric transformation is to geometrically **transform positions** and **orientation** of an image to another position/orientation following a formula function. ([Source](https://medium.com/analytics-vidhya/computer-vision-series-geometric-transformation-89477a7fc0ab#:~:text=Geometric%20transformation%20is%20to%20geometrically,is%20nothing%20without%20colored%20pixels.))\n",
    "- OpenCV Provide Geometric Transformation Function like Rotation, Translation, Affine Transformation, etc.<br><br>\n",
    "<img src=\"resource/geometric_transformation.jpg\" style=\"width:600px\"></img>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 1.1 Image Scaling / Resizing\n",
    "- Scaling is just **resizing** of the image. \n",
    "- OpenCV comes with a function `cv2.resize()` for this purpose. \n",
    "- The size of the image can be specified manually, or you can specify the scaling factor. \n",
    "- Different interpolation methods are used. \n",
    "- Preferable interpolation methods are `cv2.INTER_AREA` for **shrinking** and `cv2.INTER_CUBIC` (slow) & `cv2.INTER_LINEAR` for **zooming**.\n",
    "- We use the function: `cv2.resize (src, dst, dsize, fx, fy, interpolation)` previously discussed at session 1."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 1.2 Transform Warp Affine\n",
    "- method `cv2.warpAffine(img, M, (w,h), borderValue)`\n",
    "- where :\n",
    "    - `img` : input image \n",
    "    - `M` : input matrix (rotation/translation/scale)\n",
    "    - `(w,h)` : size output image \n",
    "    - `borderValue` : background color\n",
    "\n",
    "___\n",
    "## 1.2.1 Image Translation\n",
    "![](resource/translation.png)\n",
    "- Translation matrix : <br>\n",
    "![](resource/matrix_translation.png)\n",
    "- **Negative** values of **tx** will shift the image to the **left**\n",
    "- **Positive** values of **tx** will shift the image to the **right**\n",
    "- **Negative** values of **ty** will shift the image **up**\n",
    "- **Positive** values of **ty** will shift the image **down**    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread('lena.jpg')\n",
    "h, w, c= img.shape\n",
    "\n",
    "# create Translation Matrix\n",
    "M = np.float32([[1, 0, 0], \n",
    "                [0, 1, -100]])\n",
    "\n",
    "# Apply Warp Affine\n",
    "translated = cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "# Show result\n",
    "cv2.imshow(\"Image Translation\", translated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## 1.2.2 Rotate Image using Affine Transform\n",
    "- Matrix rotation : <br>\n",
    "![](resource/matrix_rotation.png) <br>\n",
    "<br>\n",
    "where , <br>\n",
    "![](resource/matrix_rotation_2.png) <br><br>\n",
    "\n",
    "- method `cv2.getRotationMatrix2D(center, degre, scale)`\n",
    "- where :\n",
    "    - `center` : center of rotation (tuple), c/ (30,30)\n",
    "    - `degre` : rotation angel\n",
    "    - `scale` : image scale factor\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "h, w, c = img.shape\n",
    "\n",
    "# create Rotation Matrix\n",
    "center = (w // 2, h // 2)\n",
    "M = cv2.getRotationMatrix2D(center, 45, 1.0)\n",
    "\n",
    "# Apply Warp Affine\n",
    "rotated = cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "# show result                      \n",
    "cv2.imshow(\"rotated image\", rotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "## IMPLEMENTTAION 1 : Translation + Contour Detection\n",
    "- make the box at the center of image\n",
    "![](box.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read image \n",
    "img = cv2.imread(\"box.png\")\n",
    "h0, w0, c = img.shape \n",
    "\n",
    "# convert to gray\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# apply bianry thresholding\n",
    "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "# find contour\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "\n",
    "# draw contours on image\n",
    "for i, cnt in enumerate(contours):\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    \n",
    "    # create Translation Matrix\n",
    "    M = np.float32([[1, 0, w0//2 - (x + w//2) ], \n",
    "                    [0, 1, h0//2 - (y + h//2)]])\n",
    "\n",
    "    # Apply Warp Affine\n",
    "    img = cv2.warpAffine(img, M, (w0, h0), borderValue=(255,255,255) )\n",
    "\n",
    "# show Image\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(img[:,:,::-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IMPLEMENTTAION 2 : Rotation + Contour Detection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read image \n",
    "img = cv2.imread(\"book.png\")\n",
    "h0, w0, c = img.shape \n",
    "\n",
    "# convert to gray\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# apply bianry thresholding\n",
    "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "# apply eroding\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "eroding = cv2.erode(thresh, kernel, iterations = 2)\n",
    "\n",
    "# find contour\n",
    "contours, hierarchy = cv2.findContours(eroding, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "\n",
    "# draw contours on image\n",
    "for cnt in contours :\n",
    "    # find contour feature\n",
    "    area = cv2.contourArea(cnt)\n",
    "    (x,y), (w,h), angel = cv2.minAreaRect(cnt) # find minimum rectangle enclosing contour\n",
    "\n",
    "    # filter small contour\n",
    "    if area < 500 :\n",
    "        continue\n",
    "\n",
    "    # filter contour with small area\n",
    "    extent = area / (w*h)\n",
    "    if extent > 0.5 : \n",
    "\n",
    "        # background removal (create mask from final contour) \n",
    "        mask = np.zeros_like(gray)\n",
    "        cv2.drawContours(mask, [cnt], 0, (255,255,255), -1) # apply white color\n",
    "        result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "        # create Rotation Matrix\n",
    "        center = (w0 // 2, h0 // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angel - 90, 1.0) # angel = angel - 90\n",
    "\n",
    "        # Apply Warp Affine\n",
    "        rotated = cv2.warpAffine(result, M, (w0, h0))\n",
    "\n",
    "\n",
    "# show Image\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(rotated[:,:,::-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## CUDA Warp Affine (Translation & Rotation)\n",
    "\n",
    "- method `cv2.cuda.warpAffine(src, M, (w,h), dst, borderValue)`\n",
    "- where :\n",
    "    - `src` : input image (GPU Mat)\n",
    "    - `M` : input matrix (rotation/translation/scale)\n",
    "    - `(w,h)` : size output image \n",
    "    - `dst` : output image (GPU Mat)\n",
    "    - `borderValue` : background color "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# load image in Host memory\n",
    "img = cv2.imread(\"book.png\")\n",
    "h0, w0, c = img.shape\n",
    "\n",
    "# GPU memory initialization\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w0, h0), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "gray_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "gray_GpuMat.create((w0, h0), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "thresh_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "thresh_GpuMat.create((w0, h0), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "erode_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "erode_GpuMat.create((w0, h0), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "mask_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "mask_GpuMat.create((w0, h0), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "result_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "result_GpuMat.create((w0, h0), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "rotated_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "rotated_GpuMat.create((w0, h0), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "\n",
    "# create CUDA morphological eroding object with kernel 3x3\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "MorhErode = cv2.cuda.createMorphologyFilter(cv2.MORPH_ERODE, cv2.CV_8UC1, kernel, iterations = 1)\n",
    "\n",
    "# upload to GPU memory\n",
    "img_GpuMat.upload(img)\n",
    "\n",
    "# CUDA convert to gray\n",
    "cv2.cuda.cvtColor(img_GpuMat, cv2.COLOR_BGR2GRAY, gray_GpuMat)\n",
    "\n",
    "# apply CUDA thresholding\n",
    "cv2.cuda.threshold(gray_GpuMat, 72, 255, cv2.THRESH_BINARY_INV, thresh_GpuMat)\n",
    "\n",
    "# Apply CUDA Morphological Erode\n",
    "MorhErode.apply(thresh_GpuMat, erode_GpuMat)\n",
    "\n",
    "\n",
    "# Download Matrix to Host Memory                                                               \n",
    "eroding = erode_GpuMat.download()\n",
    "\n",
    "# find contour\n",
    "contours, hierarchy = cv2.findContours(eroding, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# draw contours on image\n",
    "for cnt in contours :\n",
    "    # find contour feature\n",
    "    area = cv2.contourArea(cnt)\n",
    "    (x,y), (w,h), angel = cv2.minAreaRect(cnt) # find minimum rectangle enclosing contour\n",
    "\n",
    "    # filter small contour\n",
    "    if area < 500 :\n",
    "        continue\n",
    "\n",
    "    # filter contour with small area\n",
    "    extent = area / (w*h)\n",
    "    if extent > 0.5 : \n",
    "\n",
    "        # background removal (create mask from final contour) \n",
    "        mask = np.zeros_like(gray)\n",
    "        cv2.drawContours(mask, [cnt], 0, (255,255,255), -1) # apply white color\n",
    "\n",
    "        # Upload mask matrix to GPU Memory\n",
    "        mask_GpuMat.upload(mask)\n",
    "\n",
    "        # Apply CUDA bitwise operation\n",
    "        cv2.cuda.bitwise_not(img_GpuMat, result_GpuMat, mask=mask_GpuMat)\n",
    "        cv2.cuda.bitwise_not(result_GpuMat, result_GpuMat, mask=mask_GpuMat)\n",
    "\n",
    "        # create Rotation Matrix\n",
    "        center = (w0 // 2, h0 // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angel - 90, 1.0) # angel = angel - 90\n",
    "\n",
    "        # Apply CUDA Warp Affine\n",
    "        cv2.cuda.warpAffine(result_GpuMat, M, (w0, h0), rotated_GpuMat)\n",
    "\n",
    "\n",
    "# Download Matrix to Host Memory \n",
    "rotated = rotated_GpuMat.download()\n",
    "\n",
    "# show Image\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(rotated[:,:,::-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 3. Affine Tranform & Perspective Transform\n",
    "<img src=\"resource/TransformationsDifference.png\" style=\"width:500px\"></img>\n",
    "\n",
    "\n",
    "## 3.1 Affine Transform\n",
    "- $M$ is 2x3 tranfromation matrix to pass throuh `cv2.warpAffine()`\n",
    "- method `cv.getAffineTransform(pts1, pts2)`\n",
    "- where :\n",
    "    - `pts1` :  triangle vertices source image\n",
    "    - `pts2` :  triangle vertices destination image <br>\n",
    "<img src=\"resource/Warp_Affine_Tutorial_Theory_0.jpg\" style=\"width:300px\"></img>\n",
    "- source image :\n",
    "    - point 0,0\n",
    "    - point w, 0\n",
    "    - point 0, h"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read image\n",
    "img = cv2.imread('book_standing.jpg')\n",
    "h, w, c = img.shape \n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# convert to binary image\n",
    "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# find contour\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt, hrcy in zip(contours, hierarchy[0]) :\n",
    "    # find contour feature\n",
    "    area = cv2.contourArea(cnt)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # filter small contour\n",
    "    if area < 200 :\n",
    "        continue\n",
    "\n",
    "    # filter contour with small area and doesnt have a parent (hole contour)\n",
    "    extent = area / (w*h)\n",
    "    if extent > 0.4 and hrcy[3] != -1:\n",
    "        cv2.drawContours(img, [cnt], 0, (0,255,0), 2) # apply white color\n",
    "\n",
    "        # find minimum enclosing object\n",
    "        perimeter = cv2.arcLength(cnt, True)\n",
    "        eMin = cv2.approxPolyDP(cnt, 0.02 * perimeter, True)\n",
    "        eMin = np.array(eMin[:,0,:]) # enclosing min point in counter clockwise direction \n",
    "                                                     # tr, br, bl, tl\n",
    "\n",
    "        # draw point on enclosing minimum \n",
    "        \n",
    "        # tl, tr, br, bl\n",
    "        for pt in eMin : \n",
    "            cv2.circle(img, pt, 10, (0,0,255), -1)\n",
    "\n",
    "        pts1 = np.array([eMin[0], eMin[1], eMin[2], ], np.float32) # bl, tl, tr\n",
    "        pts2 = np.array([[w,0], [w,h], [0,h]], np.float32)\n",
    "        M = cv2.getAffineTransform(pts1, pts2)\n",
    "        result = cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(result[:,:,::-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "## 3.2 Perspective Transformation\n",
    "\n",
    "- M is 3x3 transformation matrix for Perspective Transform.\n",
    "- to create M matrix, we need **4 points on the input image** and corresponding points on the **output image**\n",
    "- method `cv2.getPerspectiveTransform(pts1, pts2)`\n",
    "- where :\n",
    "    - `pts1` : four vertices source image\n",
    "    - `pts2` : four vertices destination image <br><br>\n",
    "<img src=\"resource/perspective.png\" style=\"width:400px\"></img> <br><br><br>\n",
    "- sudoku image problem : <br><br>\n",
    "<img src=\"resource/sudoku.png\" style=\"width:400px\"></img> "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread('sudoku.jpg')\n",
    "h, w, c = img.shape\n",
    "\n",
    "# define four vertices of source & destination image\n",
    "# tl, tr, br, bl\n",
    "pts1 = np.float32([[56,65],[368,52],[389,390], [28,387]]) # the corder of sudoku image\n",
    "pts2 = np.float32([[0,0],[w,0],[w,h],[0,h]]) # the image corner \n",
    "\n",
    "# create Perpective Transform Matrix\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "\n",
    "# Apply Warp perspective transform\n",
    "output = cv2.warpPerspective(img, M, (w,h))\n",
    "\n",
    "# draw small dot in original image based on `pts1`\n",
    "for x, y in pts1.astype(np.uint16):\n",
    "    cv2.circle(img, (x,y), 4, (255, 255, 0), -1)\n",
    "\n",
    "# display result\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Perspective Transform Image\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "## IMPLEMENTATION : Affine Transform Implementation to Crop ID Card Photo\n",
    "<img src=\"resource/crop_ktp.png\" style=\"width:400px\"></img>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read image\n",
    "img = cv2.imread('ktp5.jpg')\n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# convert to binary image\n",
    "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# find contour\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt, hrcy in zip(contours, hierarchy[0]) :\n",
    "    # find contour feature\n",
    "    area = cv2.contourArea(cnt)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # filter small contour\n",
    "    if area < 200 :\n",
    "        continue\n",
    "\n",
    "    # filter contour with small area and doesnt have a parent (hole contour)\n",
    "    extent = area / (w*h)\n",
    "    if extent > 0.4 and hrcy[3] != -1:\n",
    "\n",
    "        (x,y), (w_ma, h_ma), angel = cv2.minAreaRect(cnt)\n",
    "        box = (x,y), (w_ma, h_ma), angel \n",
    "        \n",
    "        bbox = cv2.boxPoints(box).astype(np.float32) # bbox output in counter clockwise direction point -> bl, tl, tr, br\n",
    "        bbox = np.array([bbox[1], bbox[2], bbox[3], bbox[0]]) # re-arange bbox in clockwise direction -> tl, tr, br, bl\n",
    "        \n",
    "        dst = np.array([[0, 0],\n",
    "                        [w_ma, 0], \n",
    "                        [w_ma, h_ma], \n",
    "                        [0, h_ma]], np.float32)\n",
    "\n",
    "        M = cv2.getPerspectiveTransform(bbox, dst)\n",
    "        warped = cv2.warpPerspective(img, M, (int(w_ma), int(h_ma)))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(warped[:,:,::-1])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# Source\n",
    "- [tutorial_warp_affine](https://docs.opencv.org/master/d4/d61/tutorial_warp_affine.html)\n",
    "- [py_geometric_transformations](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.html)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}