{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pertemuan 2\n",
    "- OpenCV Image Datastructure\n",
    "- Split & Merge Image Channel \n",
    "- Image Croping & Resizing \n",
    "- Change Colorspace (RGB - GRAY - HSV)\n",
    "\n",
    "# Maximizing Jetson Nano Perfomance\n",
    "```\n",
    "sudo nvpmodel -m 0\n",
    "sudo jetson_clocks\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. OpenCV Image Datastructure\n",
    "## 1.1 OpenCV Python Bindings\n",
    "- In OpenCV, all algorithms are implemented in C++. \n",
    "- But these algorithms can be used from different languages like Python, Java etc. \n",
    "- We can call it as **Python-OpenCV Bindings**\n",
    "## 1.2 OpenCV Matrix (cv::Mat)\n",
    "- **Numpy Array** is used as Image datastructure in Python-OpenCV bindding,\n",
    "- And will be converted to `cv::Mat` when calling a specific OpenCV method or function then proceed the rest of task in C++ side.\n",
    "## 1.3 OpenCV Unified Matrix (cv::UMat)\n",
    "- The `cv::UMat` is the C++ class, which is very similar to `cv::Mat`.\n",
    "- In Python we call it as `cv2.UMat`\n",
    "- The `UMat` class tells OpenCV functions to process images with an **OpenCL** specific code which uses an **OpenCL-enabled GPU** if exists in the system (automatically switching to **CPU** otherwise).\n",
    "    - **OpenCL™** (Open Computing Language) is a framework for writing programs that execute across heterogeneous platforms consisting of *central processing units (CPUs)*, *graphics processing units (GPUs)*, *digital signal processors (DSPs)*, *field-programmable gate arrays (FPGAs)* and other *processors or hardware accelerators*. \n",
    "    - Check our OpenCV build is OpenCL enable or not using `cv2.getBuildInformation()`.\n",
    "- Performance comparison between `cv::Mat` and `cv::UMat` (run OpenCL)<br>\n",
    "    <img src=\"res/OpenCL.jpg\" style=\"width: 450px;\"></img>\n",
    "## 1.4 OpenCV CUDA GPU Matrix(cv::cuda::GpuMat)\n",
    "- The `cv::gpu::GpuMat` is the C++ class inside **OpenCV GPU Module** (`cv::cuda`) written using CUDA.\n",
    "- The GPU module is designed as host API extension.\n",
    "- This design provides the user an explicit control on how data is **moved between CPU and GPU memory**. \n",
    "- `cv::gpu::GpuMat` which is a primary container for data kept in **GPU memory**.\n",
    "- It’s interface is very similar with `cv::Mat`, its CPU counterpart. \n",
    "- All GPU functions receive `GpuMat` as **input** and **output** arguments. \n",
    "- In Python we call it as `cv2.cuda_GpuMat`\n",
    "- Performance comparison between `cv::Mat` and `cv::cuda::GPUMat` (Tesla C2050 vs Core i5-760 2.8Ghz, SSE, TBB)<br>\n",
    "    <img src=\"res/cuda_gpumat.png\" style=\"width: 450px;\"></img>\n",
    "## 1.5 OpenCV Matrix Python vs C++\n",
    "- OpenCV Matrix comparison between Python and C++<br>\n",
    "    <img src=\"res/datastructure.png\" style=\"width: 450px;\"></img>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# OpenCV Image Matrix (Numpy Array)\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "print(type(img))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Converting Image Matrix to UMat\n",
    "\n",
    "img_Umat = cv2.UMat(img)\n",
    "\n",
    "print(type(img_Umat))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Umat Object Property\n",
    "\n",
    "print(dir(img_Umat))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Converting Umat to Image Matrix (Numpy Array)\n",
    "\n",
    "img = img_Umat.get()\n",
    "\n",
    "print(type(img))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Check OpenCL Enable in OpenCV Build Information\n",
    "\n",
    "print(cv2.getBuildInformation())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Performance comparison Image Matrix (Numpy Array) vs UMat (OpenCL)\n",
    "\n",
    "# Resizing to super big image -> rotate -90 -> grayscaling -> do Canny detection -> rotate 90 -> resizing back to original size\n",
    "# Image Matrix Implementation\n",
    "\n",
    "times = []\n",
    "big_h, big_w = 3440, 3540\n",
    "h, w = 344, 354\n",
    "gray = None\n",
    "for _ in range(100):\n",
    "    e1 = cv2.getTickCount()\n",
    "\n",
    "    img = cv2.imread(\"lena.jpg\", cv2.IMREAD_COLOR)\n",
    "    img = cv2.resize(img, (big_w, big_h))\n",
    "    img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.Canny(gray, 0, 20)\n",
    "    gray = cv2.rotate(gray, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    gray = cv2.resize(gray, (w, h))\n",
    "\n",
    "    e2 = cv2.getTickCount()\n",
    "    times.append((e2 - e1)/ cv2.getTickFrequency())\n",
    "    \n",
    "avg_time_mat = np.array(times).mean()\n",
    "print(\"Average processing time CPU : %.2fs\" % avg_time_mat)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Performance comparison Image Matrix (Numpy Array) vs UMat (OpenCL)\n",
    "\n",
    "# Resizing to super big image -> rotate -90 -> grayscaling -> do Canny detection -> rotate 90 -> resizing back to original size\n",
    "# UMat (OpenCL) Implementation\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "times = []\n",
    "big_w, big_h = 3440, 3540\n",
    "h, w = 344, 354\n",
    "\n",
    "for _ in range(100):\n",
    "    e1 = cv2.getTickCount()\n",
    "\n",
    "    img = cv2.imread(\"lena.jpg\", cv2.IMREAD_COLOR)\n",
    "    imgUMat = cv2.UMat(img)\n",
    "    imgUMat = cv2.resize(imgUMat, (big_w, big_h))\n",
    "    imgUMat = cv2.rotate(imgUMat, cv2.ROTATE_90_CLOCKWISE)\n",
    "    gray = cv2.cvtColor(imgUMat, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.Canny(gray, 0, 20)\n",
    "    gray = cv2.rotate(gray, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    gray = cv2.resize(gray, (w, h))\n",
    "\n",
    "    e2 = cv2.getTickCount()\n",
    "    times.append((e2 - e1)/ cv2.getTickFrequency())\n",
    "    \n",
    "avg_time_umat = np.array(times).mean()\n",
    "print(\"Average processing time UMat (OpenCL) : %.2fs\" % avg_time_umat)\n",
    "print(\"Speedup over Mat : %.2fs\" % (avg_time_mat/avg_time_umat))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv2.imshow(\"window\", gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Why UMat (OpenCL) is not utilizing Jetson Nano GPU ?\n",
    "- Because NVIDIA Tegra (Processor used in Jetson Nano) is not supported OpenCL (event it installed in OS)\n",
    "- related note  : [https://forums.developer.nvidia.com/t/opencl-support/74071](https://forums.developer.nvidia.com/t/opencl-support/74071)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## OpenCV Gpu::Mat Datastructure in Python"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Converting Image Mtrix to cuda::GPUMat\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object\n",
    "\n",
    "img_GpuMat.upload(img) # Upload Image Matrix (Host Memory) to GpuMat (GPU Memory)\n",
    "\n",
    "type(img_GpuMat)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# GpuMat Property\n",
    "\n",
    "print(dir(img_GpuMat))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# check GpuMat size\n",
    "\n",
    "print(img_GpuMat.size())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert GpuMat (GPU Memory) to Image Matrix (Host Memory)\n",
    "\n",
    "img = img_GpuMat.download()\n",
    "\n",
    "print(type(img))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Performance comparison Image Matrix (Numpy Array) vs GpuMat (CUDA)\n",
    "\n",
    "# cuda::Resizing to super big image -> rotate -90 -> cuda::grayscaling -> do cuda::Canny detection -> rotate 90 -> cuda::resizing back to original size\n",
    "# GpuMat (CUDA) Implementation\n",
    "\n",
    "times = []\n",
    "big_h, big_w = 3440, 3540\n",
    "h, w = 344, 354\n",
    "\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object\n",
    "img_GpuMat.create((w, h), cv2.CV_8UC3) # Initialize GPU (memory allocation & etc.), cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "\n",
    "img_big_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object for Big Matrix\n",
    "img_big_GpuMat.create((big_w, big_h), cv2.CV_8UC3) # cv2.CV_8UC1 -> 8bit image 3 channel\n",
    "\n",
    "gray_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object for Grayscale Matrix\n",
    "gray_GpuMat.create((big_w, big_h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "\n",
    "res_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object for Result Matrix\n",
    "res_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "\n",
    "Canny = cv2.cuda.createCannyEdgeDetector(0, 20) # Initialize Canny Detector in CUDA\n",
    "\n",
    "\n",
    "for _ in range(100):\n",
    "    e1 = cv2.getTickCount()\n",
    "\n",
    "    img = cv2.imread(\"lena.jpg\")\n",
    "    img_GpuMat.upload(img)\n",
    "    cv2.cuda.resize(img_GpuMat, (big_w, big_h), img_big_GpuMat) # Resize in CUDA context\n",
    "    cv2.cuda.rotate(img_big_GpuMat, (big_w*2, big_h*2), -90, img_big_GpuMat) # rotate -90\n",
    "    cv2.cuda.cvtColor(img_big_GpuMat, cv2.COLOR_BGR2GRAY, gray_GpuMat) # Grayscaling in CUDA context\n",
    "    Canny.detect(gray_GpuMat, gray_GpuMat) # Call Canny Detector\n",
    "    cv2.cuda.rotate(gray_GpuMat, (big_w*2, big_h*2), 90, gray_GpuMat) # rotate 90\n",
    "    cv2.cuda.resize(gray_GpuMat, (w, h), res_GpuMat) # Resizig back\n",
    "\n",
    "    e2 = cv2.getTickCount()\n",
    "    times.append((e2 - e1)/ cv2.getTickFrequency())\n",
    "    \n",
    "    \n",
    "avg_time_gpumat = np.array(times).mean()\n",
    "print(\"Average processing time GpuMat (CUDA) : %.2fs\" % avg_time_gpumat)\n",
    "print(\"Speedup over Mat : %.2fs\" % (avg_time_mat/avg_time_gpumat))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv2.imshow(\"window\", res_GpuMat.download())\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Special Note : \n",
    "- Performance improvement in GPU (CUDA) over CPU is depend on : \n",
    "    - How complex task to be executed, if there is **simple task**, using **GPU implementation** maybe **worse** compare to CPU, because time for upload / download data from or to GPU memory to Host Memory will give a lot portion to overall processing time.\n",
    "    - Keep Processing in GPU space (GPU Memory) and download (if necassary) at the end processing.\n",
    "    - Depend on compute capability on GPU Device : \n",
    "        - Jetson Nano GPU : \n",
    "            - NVIDIA Maxwell architecture NVIDIA CUDA® cores\n",
    "            - Shared Memory \n",
    "            - Compute Capability : 5.3\n",
    "        - Jetson Nano GPU relative performance comparison :<br>\n",
    "        ![](res/jetson_nano_gpu.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 2 Split & Merging Image Channel\n",
    "- Using Numpy Matrix slicing\n",
    "- Using OpenCV method\n",
    "- CUDA Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Using Numpy Matrix Slicing "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "e1 = cv2.getTickCount()\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "# split channel\n",
    "img_b = img[:,:,0]\n",
    "img_g = img[:,:,1]\n",
    "img_r = img[:,:,2]\n",
    "\n",
    "# merging back\n",
    "# merging using np.dstack : stack arrays in sequence depth wise (along third axis).\n",
    "img_res = np.dstack([img_b, img_g, img_r])\n",
    "\n",
    "e2 = cv2.getTickCount()\n",
    "numpy_time = (e2 - e1)/ cv2.getTickFrequency()\n",
    "print(\"numpy implementation execution time : %.6fs\" % numpy_time)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- method `np.dstack(tup)`\n",
    "    - `tup` : sequence numpy array, `[arr1, arr2, arr3]`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv2.imshow(\"window\", img_res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Using OpenCV Method"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "e1 = cv2.getTickCount()\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "# split using cv2.split\n",
    "img_b, img_g, img_r = cv2.split(img)\n",
    "\n",
    "# merging back\n",
    "# merging using cv2.merge\n",
    "img_res = cv2.merge([img_b, img_g, img_r])\n",
    "\n",
    "e2 = cv2.getTickCount()\n",
    "opencv_time = (e2 - e1)/ cv2.getTickFrequency()\n",
    "print(\"OpenCV implementation execution time : %.6fs\" % opencv_time)\n",
    "print(\"Speedup improvement over Numpy implementation : %.4f\" % (numpy_time/opencv_time))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 Using GPU Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initialization\n",
    "h, w = 344, 354\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8U -> 8bit image 3 channel (default)\n",
    "ch1_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "ch1_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "ch2_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "ch2_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "ch3_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "ch3_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "img_res_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_res_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8U -> 8bit image 3 channel (default)\n",
    "\n",
    "\n",
    "\n",
    "e1 = cv2.getTickCount()\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "# upload to GpuMat (GPU Memory)\n",
    "img_GpuMat.upload(img)\n",
    "\n",
    "# split using cv2.cuda.split\n",
    "cv2.cuda.split(img_GpuMat, [ch1_GpuMat, ch2_GpuMat, ch3_GpuMat])\n",
    "\n",
    "# merging back\n",
    "# merging using cv2.cuda.merge\n",
    "cv2.cuda.merge([ch1_GpuMat, ch2_GpuMat, ch3_GpuMat], img_res_GpuMat)\n",
    "\n",
    "e2 = cv2.getTickCount()\n",
    "cuda_time = (e2 - e1)/ cv2.getTickFrequency()\n",
    "print(\"OpenCV CUDA implementation execution time : %.6fs\" % cuda_time)\n",
    "print(\"Speedup improvement over Numpy implementation : %.4f\" % (numpy_time/cuda_time))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 3. Image Croping & Resizing\n",
    "- Croping using Numpy\n",
    "- Resize using OpenCV\n",
    "- CUDA Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 Crop using Numpy Slicing\n",
    "- We can use *numpy slicing* to Crop Image Matrix\n",
    "- using this format `image_array[y_min:y_max , x_min:x_max]`\n",
    "- where `y_min`, `y_max`, `x_min` and `x_max` is pixel coordinate where the image cropped.<br>\n",
    "    <img src=\"res/crop_img.png\" style=\"width: 400px;\"></img><br><br>\n",
    "    <img src=\"res/crop_image_il.png\" style=\"width: 450px;\"></img>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "# Cropping using Numpy slicing, img[y_min:y_max, x_min:x_max]\n",
    "img_crop = img[50:-50, 50:-50]\n",
    "\n",
    "cv2.imshow(\"original\", img)\n",
    "cv2.imshow(\"Cropped\", img_crop)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Resize using OpenCV Method\n",
    "- untuk melakukan resize image pada OpenCV diprkenalkan beberapa method berikut :\n",
    "    - `cv2.resize(img, (w_new, h_new))` : resize `img` ke ukuran `w_new` x `h_new`\n",
    "    <img src=\"res/resize.jpg\" style=\"width: 600px;\"></img>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "# resize image (new_widht, new_height)\n",
    "img_resize = cv2.resize(img, (320, 240))  \n",
    "\n",
    "cv2.imshow(\"original\", img)\n",
    "cv2.imshow(\"Resized\", img_resize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Resize Image and keep aspec ratio\n",
    "\n",
    "ratio = 0.5 # resize ratio\n",
    "\n",
    "img = cv2.imread('lena.jpg')\n",
    "h, w, c = img.shape\n",
    "\n",
    "width = int(w* ratio)\n",
    "height = int(h * ratio)\n",
    "\n",
    "# resize image (new_widht, new_height)\n",
    "img_resize = cv2.resize(img, (width, height))  \n",
    "\n",
    "cv2.imshow(\"original\", img)\n",
    "cv2.imshow(\"Resized\", img_resize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- OpenCV resize using `fx` and `fy` parameter,"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "# resize image \n",
    "img_resize = cv2.resize(img, (0,0), fx=0.5, fy=0.5)  \n",
    "\n",
    "cv2.imshow(\"original\", img)\n",
    "cv2.imshow(\"Resized\", img_resize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- resize with **interpolation**\n",
    "- Interpolation parameter :\n",
    "    - `cv2.INTER_NEAREST` : This is using a **nearest-neighbor interpolation** to **shrink an image**.\n",
    "    - `cv2.INTER_LINEAR` : This is primarily used when **larging** is required (default).\n",
    "    - `cv2.INTER_AREA` : This is used when we need need to **shrink an image** (the best).\n",
    "    - `cv2.INTER_CUBIC` : This is **slow** for **larging image**, but more efficient (**higer quality**).<br><br>\n",
    "- Interpolation Method : <br>\n",
    "    <img src=\"res/interpolation.png\" style=\"width: 400px;\"></img><br><br>\n",
    "- Nearest Neighbor Interpolation : <br>\n",
    "    <img src=\"res/Nearest_Neighbor.png\" style=\"width: 400px;\"></img><br><br>\n",
    "- Linear Interpolation : <br>\n",
    "    <img src=\"res/Bilinear_interpolation.png\" style=\"width: 400px;\"></img><br><br>\n",
    "- Cubic Interpolation : <br>\n",
    "    <img src=\"res/Bicubic_interpolation.png\" style=\"width: 400px;\"></img><br><br>\n",
    "- Inter Area Interpolationis :\n",
    "    - is a **linear interpolation** with slightly more complicated coefficient values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ---------- shringking -------\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "# resize image (new_widht, new_height)\n",
    "img_resize_INTER_LINEAR = cv2.resize(img, (0,0), fx=2.5, fy=2.5) \n",
    "img_resize_INTER_NEAREST = cv2.resize(img, (0,0), fx=2.5, fy=2.5, interpolation=cv2.INTER_NEAREST) \n",
    "\n",
    "# show image \n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('INTER_LINEAR Resized Image', img_resize_INTER_LINEAR)\n",
    "cv2.imshow('INTER_NEAREST Resized Image', img_resize_INTER_NEAREST)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ---------- larging -------\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "# resize image (new_widht, new_height)\n",
    "img_resize = cv2.resize(img, (0,0), fx=3.5, fy=3.5) \n",
    "img_resize_INTER_CUBIC = cv2.resize(img, (0,0), fx=3.5, fy=3.5, interpolation=cv2.INTER_CUBIC) \n",
    "img_resize_INTER_NEAREST = cv2.resize(img, (0,0), fx=3.5, fy=3.5, interpolation=cv2.INTER_NEAREST) \n",
    "img_resize_INTER_AREA = cv2.resize(img, (0,0), fx=3.5, fy=3.5, interpolation=cv2.INTER_AREA) \n",
    "\n",
    "# show image \n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('INTER_LINEAR Resized Image', img_resize)\n",
    "cv2.imshow('INTER_CUBIC Resized Image', img_resize_INTER_CUBIC)\n",
    "cv2.imshow('INTER_NEAREST Resized Image', img_resize_INTER_NEAREST)\n",
    "cv2.imshow('INTER_AREA Resized Image', img_resize_INTER_AREA)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Crop & Resize Image using OpenCV CUDA Module"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initialization\n",
    "h, w = 344-100, 354-100\n",
    "ratio = 0.5\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8U -> 8bit image 3 channel (default)\n",
    "\n",
    "img_resize_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_resize_GpuMat.create((int(w*ratio), int(h*ratio)), cv2.CV_8UC3) # cv2.CV_8U -> 8bit image 3 channel (default)\n",
    "\n",
    "\n",
    "\n",
    "e1 = cv2.getTickCount()\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "# Cropping using Numpy slicing, img[y_min:y_max, x_min:x_max]\n",
    "img_crop = img[50:-50, 50:-50]\n",
    "\n",
    "# upload to GpuMat (GPU Memory)\n",
    "img_GpuMat.upload(img_crop)\n",
    "\n",
    "# Resize image using cv2.cuda.resize()\n",
    "cv2.cuda.resize(img_GpuMat, (0,0), img_resize_GpuMat, fx=ratio, fy=ratio)\n",
    "\n",
    "e2 = cv2.getTickCount()\n",
    "cuda_time = (e2 - e1)/ cv2.getTickFrequency()\n",
    "print(\"OpenCV CUDA implementation execution time : %.6fs\" % cuda_time)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv2.imshow(\"original\", img)\n",
    "cv2.imshow(\"Resized\", img_resize_GpuMat.download())\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 4. Image Color Conversion\n",
    "\n",
    "![](res/gray_image.png)\n",
    "- Diperkenalkan method `cv2.cvtColor()` untuk color conversion pada OpenCV\n",
    "- Berikut adalah parameter convert color yang dapat digunakan :\n",
    "    - convert BGR <--> RGB \\\n",
    "    `cv2.COLOR_BGR2RGB` \\\n",
    "    `cv2.COLOR_RGB2BGR`\n",
    "    - convert BGR <--> HSV \\\n",
    "    `cv2.COLOR_BGR2HSV` \\\n",
    "    `cv2.COLOR_HSV2RGB`\n",
    "    - convert BGR <--> BGRA \\\n",
    "    `cv2.COLOR_BGR2BGRA` \\\n",
    "    `cv2.COLOR_BGRA2BGR`\n",
    "    - convert RGB <--> RGBA \\\n",
    "    `cv2.COLOR_RGB2BGRA` \\\n",
    "    `cv2.COLOR_RGBA2BGR`\n",
    "    - convert BGR <--> GRAY \\\n",
    "    `cv2.COLOR_BGR2GRAY` \\\n",
    "    `cv2.COLOR_GRAY2RGB` <br><br>\n",
    "- Convert BGR to RGB Ilustration <br>\n",
    "    - OpenCV using **Rec. 601 luma** formula to calculate grayscale image :\n",
    "    $\\text{RGB[A] to Gray:} \\quad Y \\leftarrow 0.299 \\cdot R + 0.587 \\cdot G + 0.114 \\cdot B$ <br><br>\n",
    "    <img src=\"res/gray_image_2.png\" style=\"width: 400px;\"></img><br><br>\n",
    "- Source :\n",
    "    - [OpenCV cvtColor Doc](https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#void%20cvtColor%28InputArray%20src,%20OutputArray%20dst,%20int%20code,%20int%20dstCn%29)\n",
    "    - [Luma Formula (Grayscale Transformation)](https://en.wikipedia.org/wiki/Luma_%28video%29#Rec._601_luma_versus_Rec._709_luma_coefficients)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 OpenCV Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "# convert BGR to Gray\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Gray', img_gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 Opencv CUDA Module Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initialization\n",
    "h, w = 344, 354\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel (default)\n",
    "\n",
    "gray_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "gray_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC3 -> 8bit image 1 channel\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "img_GpuMat.upload(img)\n",
    "\n",
    "# convert BGR to Gray using CUDA\n",
    "cv2.cuda.cvtColor(img_GpuMat, cv2.COLOR_BGR2GRAY, gray_GpuMat)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Gray', gray_GpuMat.download())\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Source\n",
    "- https://docs.opencv.org/master/da/d49/tutorial_py_bindings_basics.html\n",
    "- https://en.wikipedia.org/wiki/OpenCL\n",
    "- https://jeanvitor.com/opencv-opencl-umat-performance/\n",
    "- https://opencv.org/opencl/\n",
    "- https://opencv.org/platforms/cuda/\n",
    "- https://www.techpowerup.com/gpu-specs/jetson-nano-gpu.c3643\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}