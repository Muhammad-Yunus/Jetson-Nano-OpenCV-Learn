{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pertemuan 10\n",
    "- Image Transformation\n",
    "    - Fourier Transform (DFT & IDFT)\n",
    "    - Performance Optimization of DFT\n",
    "    - CUDA Implementation\n",
    "- Image Histogram\n",
    "    - Find & Plot Histogram\n",
    "    - Histogram Equalization (Global Contrast & CLAHE)\n",
    "    - CUDA Implementation\n",
    "___\n",
    "### Maximizing Jetson Nano Perfomance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sudo nvpmodel -m 0\n",
    "# sudo jetson_clocks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# check OpenCV Version\n",
    "\n",
    "cv2.__version__"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "# 1. Image Transform\n",
    "## 1.1 Fourier Transform (DFT & IDFT)\n",
    "- Fourier Transform is used to analyze the frequency characteristics of various filters.<br>\n",
    "<img src=\"resource/fourier.jpeg\" style=\"width:450px\"></img><br>\n",
    "*1D Fourier Transform*<br><br>\n",
    "- For images, **2D Discrete Fourier Transform (DFT)** is used to find the **frequency domain**. \n",
    "- The output of the transformation represents the image in the Fourier or **frequency domain**, \n",
    "- while the input image is the **spatial domain** equivalent. \n",
    "- A fast algorithm called **Fast Fourier Transform (FFT)** is used for calculation of **DFT**. \n",
    "- Then we can revert frequency domain data back into image using **Inverse DFT**.<br>\n",
    "<img src=\"resource/Fourier2.png\" style=\"width:450px\"></img><br>\n",
    "*2D Fourier Transform in Image*<br><br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Fourier Transform (Numpy)\n",
    "- Numpy has an FFT package to find Fourier Transform on Image. \n",
    "- Funtion `np.fft.fft2(a, s)` provides us the **frequency transform** which will be a **complex array**. \n",
    "- Where : \n",
    "    - `a` : is the input image (array), which is grayscale image(`cv2.CV_8UC1`).\n",
    "    - `s` : is optional which decides the size of output array. (`s[0]` refers to `axis 0`, `s[1]` to `axis 1`).\n",
    "- Then, we need to move zero frequency component to the center using `np.fft.fftshift(a)`, (It is more easier to analyze).\n",
    "- Where : \n",
    "    - `a` : in input array generated by `np.fft.fft2(a, s)`\n",
    "- After that, we can find the **magnitude spectrum** using formula : <br><br>\n",
    "$magnitude = 20*log(|f_{shift}|)$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "# conver to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# apply FFT to gray image (result frequency transform matrix)\n",
    "f = np.fft.fft2(gray)\n",
    "\n",
    "# move zero frequency component to the center using `np.fft.fftshift()`\n",
    "fshift = np.fft.fftshift(f)\n",
    "\n",
    "# find magnitude spectrum = 20*log(|fshift|)\n",
    "magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "\n",
    "# show result\n",
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Input Image') \n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(magnitude_spectrum, cmap = 'gray')\n",
    "plt.title('Magnitude Spectrum')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- See, You can see **more white region** at the center showing **low frequency** content is more.\n",
    "- So you found the **frequency transform** Now you can do some operations in **frequency domain**, like **high pass filtering** and **reconstruct the image**, ie find **inverse DFT**. \n",
    "<br><br><br>\n",
    "____\n",
    "## Apply HPF and Do Image Reconstruction From Frequency Domain To Generate Edge Image\n",
    "- Remove the low frequencies by masking with a rectangular window of size 60x60.\n",
    "- Then apply the inverse shift using `np.fft.ifftshift()`, (DC component come at the top-left corner).\n",
    "- Then find inverse FFT using `np.ifft2()` function. \n",
    "- The result, will be a complex number, use `np.real()` to convert that into real number."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "h, w = gray.shape\n",
    "ch, cw = h//2 , w//2\n",
    "\n",
    "# create 0 masking window with size 60x60 at the center of fshift to remove the low frequencies\n",
    "# We call it as HPF (High Pass Filter) that will be produce Edge image later.\n",
    "fshift[ch-30 : ch+31, cw-30 : cw+31] = 0\n",
    "\n",
    "# apply inverse FFT Shift (move DC component to top-left corner)\n",
    "f_ishift = np.fft.ifftshift(fshift)\n",
    "\n",
    "# apply inverse FFT \n",
    "img_back = np.fft.ifft2(f_ishift)\n",
    "\n",
    "# convert to real number using `np.real()`\n",
    "img_back = np.real(img_back)\n",
    "\n",
    "\n",
    "# show result\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Input Image')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img_back, cmap = 'gray')\n",
    "plt.title('Image after HPF')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_back)\n",
    "plt.title('Result in JET')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Colormap Jet vs gray, <br>\n",
    "![](resource/colormap.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "## Fourier Transform in OpenCV\n",
    "- OpenCV provides the functions `cv2.dft(src, dst, flags, nonzeroRows)` and `cv2.idft(src, dst, flags, nonzeroRows)` for this. \n",
    "- Where : \n",
    "    - `src` : input array that could be real or complex.\n",
    "    - `dst` : output array whose size and type depends on the flags .\n",
    "    - `flags` : transformation flags,\n",
    "        - `cv2.DFT_INVERSE` : performs an inverse 1D or 2D transform instead of the default forward transform.\n",
    "        - `cv2.DFT_SCALE` : scales the result: divide it by the number of array elements. Normally, it is combined with `cv2.DFT_INVERSE`.\n",
    "        - `cv2.DFT_ROWS` : performs a forward or inverse transform of every individual row of the input matrix.\n",
    "        - `cv2.DFT_COMPLEX_OUTPUT` : performs a forward transformation of 1D or 2D real array; the result, though being a complex array.\n",
    "        - `cv2.DFT_REAL_OUTPUT` : performs an inverse transformation of a 1D or 2D complex array; the result, though being a real array.\n",
    "    - `nonzeroRows` :\tnumber of dst rows to process; the rest of the rows have undefined content (see the convolution sample in dft description.\n",
    "- Then calculate magnitude from 2D vector using `cv2.magnitude(x, y)`,\n",
    "- Where : \n",
    "    - `x` : array in x coordinate.\n",
    "    - `y` : array in y coordinate.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread('messi.jpg')\n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# convert grayscale image from uint8 (CV_8UC1) to float32 (CV_32FC1)\n",
    "gray = gray.astype(np.float32)\n",
    "\n",
    "# apply DFT to find frequency transform matrix\n",
    "dft = cv2.dft(gray, flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "\n",
    "# move zero frequency component to the center using `np.fft.fftshift()`\n",
    "dft_shift = np.fft.fftshift(dft)\n",
    "\n",
    "# find magnitude spectrum = 20*log(|magnitude|)\n",
    "x = dft_shift[:,:,0]\n",
    "y = dft_shift[:,:,1]\n",
    "magnitude = cv2.magnitude(x, y)\n",
    "magnitude_spectrum = 20*np.log(magnitude)\n",
    "\n",
    "\n",
    "# show result\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Input Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(magnitude_spectrum, cmap = 'gray')\n",
    "plt.title('Magnitude Spectrum')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Note : \n",
    "- You can also use `cv2.cartToPolar(x, y)` which returns both **magnitude** and **angel** in a single shot.<br><br><br>\n",
    "\n",
    "____\n",
    "## Apply LPF and Do Image Reconstruction in Frequency Domain To Generate Blur Image\n",
    "- Apply Inverse DFT using `cv2.idft(src, dst, flags, nonzeroRows)`\n",
    "- Then remove high frequency contents in the image, by applying LPF (Low Pass Filter) to image taht will be **blurs the image**. \n",
    "- For this, we create a mask first with **high value (1)** at **low frequencies**, (we pass the `LF` content, and `0` at `HF` region)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "h, w = gray.shape\n",
    "ch, cw = h//2 , w//2\n",
    "\n",
    "# create a mask first, center square is 1 with size 60x60 (pass the LF content), remaining all 0.\n",
    "mask = np.zeros((h, w, 2), np.uint8)\n",
    "mask[ch-40 : ch+40, cw-40 : cw+40] = 1\n",
    "\n",
    "# apply mask to frequency domain matrix\n",
    "fshift = dft_shift*mask\n",
    "\n",
    "# apply inverse FFT Shift (move DC component to top-left corner)\n",
    "f_ishift = np.fft.ifftshift(fshift)\n",
    "\n",
    "# apply inverse DFT\n",
    "img_back = cv2.idft(f_ishift)\n",
    "\n",
    "# find a magnitude from 2D IDFT vector\n",
    "x = img_back[:,:,0]\n",
    "y = img_back[:,:,1]\n",
    "img_back = cv2.magnitude(x, y)\n",
    "\n",
    "\n",
    "# show result\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Input Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_back, cmap = 'gray')\n",
    "plt.title('Magnitude Spectrum')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_____\n",
    "## 1.2 Performance Optimization of DFT\n",
    "- Performance of DFT calculation is fastest when array size is **power of two**. \n",
    "- The arrays whose size is a product of 2’s, 3’s, and 5’s are also processed quite efficiently. \n",
    "- OpenCV provides a function, `cv2.getOptimalDFTSize(n)` for this. \n",
    "- Where : \n",
    "    - `n` : is number of columns or rows in our input matrix.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread('messi.jpg')\n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "h, w = gray.shape\n",
    "print(\"Original Size %d, %d\" % (h, w))\n",
    "\n",
    "# Find optimal rows and column for DFT & IDFT\n",
    "nh = cv2.getOptimalDFTSize(h)\n",
    "nw = cv2.getOptimalDFTSize(w)\n",
    "print(\"Optimize Size %d, %d\" % (nh, nw))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to use the optimized rows and columns above, we need to add padding into the image, \n",
    "# simply just using zero matrix \n",
    "\n",
    "# create zero matrix with size of optimized matrix size above\n",
    "nimg = np.zeros((nh, nw))\n",
    "\n",
    "# insert the grayscale image into zero matrix image\n",
    "nimg[:h, :w] = gray"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# measure perfomance DFT calculation for original image with size (342, 549) - messi.jpg\n",
    "\n",
    "gray = gray.astype(np.float32)\n",
    "\n",
    "%timeit dft1 = cv2.dft(gray, flags=cv2.DFT_COMPLEX_OUTPUT)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# measure perfomance DFT calculation for zero padded image with optimized size (360, 576) - messi.jpg\n",
    "nimg = nimg.astype(np.float32)\n",
    "\n",
    "%timeit dft2 = cv2.dft(nimg, flags = cv2.DFT_COMPLEX_OUTPUT)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Note :\n",
    "- `%timeit` is python magic syntax for measure execution time of small code snippets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "## 1.3 CUDA Implementation\n",
    "- Create Object using class `cv2.cuda.createDFT(dft_size, flags=0)`\n",
    "- Where : \n",
    "    - `dft_size` : is the image size.\n",
    "    - `flags` : \n",
    "        - `cv2.DFT_INVERSE` : performs an inverse 1D or 2D transform instead of the default forward transform.\n",
    "        - `cv2.DFT_SCALE` : scales the result: divide it by the number of array elements. Normally, it is combined with `cv2.DFT_INVERSE`.\n",
    "        - `cv2.DFT_ROWS` : performs a forward or inverse transform of every individual row of the input matrix.\n",
    "        - `cv2.DFT_COMPLEX_INPUT` : performs a forward transformation of 1D or 2D real array; the result, though being a complex array.\n",
    "        - `cv2.DFT_REAL_OUTPUT` : performs an inverse transformation of a 1D or 2D complex array; the result, though being a real array.\n",
    "- Then use method `.compute(src, dst)` to find frequency matrix of DFT\n",
    "- Where : \n",
    "    - `src` : input image matrix (GPU Mat), Only `cv2.CV_32FC1` images are supported for now.\n",
    "    - `dst` : output frequency matrix (GPU Mat)\n",
    "- And to convert from Frequency matrix to magnitude, we can use `cv2.cuda.magnitude(x, y)`\n",
    "- Where : \n",
    "    - `x` : array in x coordinate.\n",
    "    - `y` : array in y coordinate."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image in Host memory\n",
    "img = cv2.imread(\"messi.jpg\")\n",
    "h, w, c = img.shape\n",
    "\n",
    "# GPU memory initialization\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_32FC3) # cv2.CV_32FC3 -> 32 bit float image 3 channel\n",
    "gray_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "gray_GpuMat.create((w, h), cv2.CV_32FC1) # cv2.CV_32FC1 -> 32 bit float image 1 channel\n",
    "\n",
    "# Create DFT Object\n",
    "DFT = cv2.cuda.createDFT((w, h), flags=0)\n",
    "\n",
    "# upload to GPU memory as 32 bit float matrix\n",
    "img_GpuMat.upload(img.astype(np.float32))\n",
    "\n",
    "# convert to grayscale using CUDA\n",
    "cv2.cuda.cvtColor(img_GpuMat, cv2.COLOR_BGR2GRAY, gray_GpuMat)\n",
    "\n",
    "# compute DFT to grayscale to find frequency transform matrix\n",
    "dft_GpuMat = DFT.compute(gray_GpuMat)\n",
    "\n",
    "# download to host memory\n",
    "gray = gray_GpuMat.download() \n",
    "dft = dft_GpuMat.download()\n",
    "\n",
    "# move zero frequency component to the center using `np.fft.fftshift()`\n",
    "dft_shift = np.fft.fftshift(dft)\n",
    "\n",
    "# find magnitude spectrum = 20*log(|magnitude|)\n",
    "x = dft_shift[:,:,0]\n",
    "y = dft_shift[:,:,1]\n",
    "magnitude = cv2.magnitude(x, y)\n",
    "magnitude_spectrum = 20*np.log(magnitude)\n",
    "\n",
    "# show result\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Input Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(magnitude_spectrum, cmap = 'gray')\n",
    "plt.title('Magnitude Spectrum')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "____\n",
    "# 2. Image Histogram\n",
    "- Histogram Image is a graph or plot to find out intensity distribution of an image.\n",
    "- It is a plot with pixel values (ranging from 0 to 255, not always) in **X-axis**,\n",
    "- and corresponding number of pixels in the image on **Y-axis**.<br>\n",
    "    ![](resource/histogram_sample.jpg)<br>\n",
    "- By looking at the histogram of an image, you get intuition about **contrast**, **brightness**, **intensity** distribution etc of that image.\n",
    "- **Left** region of histogram shows the amount of **darker pixels** in image.\n",
    "- **Right** region shows the amount of **brighter pixels** in image. \n",
    "<br><br><br>\n",
    "____\n",
    "## 2.1 Find & Plot Histogram\n",
    "### 2.1.1 Find Histogram using OpenCV\n",
    "- OpenCV provide `cv2.calcHist([img], [channels], mask, [histSize], [ranges])`,\n",
    "- Where : \n",
    "    - `img` : it is the source image of type uint8 or float32.\n",
    "    - `channels` : It is the index of channel for which we calculate histogram. 0, 1, 2 for RGB image. 0 for Grayscale image.\n",
    "    - `mask` : mask image. To find histogram of full image, it is given as `None`. But if you want to find histogram of particular region of image, you have to create a mask image for that and give it as mask.\n",
    "    - `histSize` : this represents our BIN count, we pass [256].\n",
    "    - `ranges` : this is our RANGE. Normally, it is [0,256]."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "# convert ot grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# find histogram using OpenCV for grayscale image, channel 0, mask=None, histSize=256, ranges = [0,256]\n",
    "hist = cv2.calcHist([gray], [0], None, [256], [0,256])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "hist.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 2.1.2 Find Histogram Using Numpy\n",
    "- Numpy also provides you a function, `np.histogram()`. \n",
    "- So instead of `cv2.calcHist()` function, you can try below line :"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "# convert ot grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# find histogram using Numpy for grayscale image, bins=256, range = [0,256]\n",
    "hist, bins = np.histogram(gray.ravel(),256,[0,256])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gray.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "## 2.2 Plot Histogram\n",
    "### 2.2.1 Plot Histogram Using Matplotlib [OPTION 1]\n",
    "- Matplotlib comes with a histogram plotting function : `matplotlib.pyplot.hist()`\n",
    "- It directly finds the histogram and plot it. \n",
    "- You need not use `cv2.calcHist()` or `np.histogram()` function to find the histogram."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "# convert ot grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.hist(gray.ravel(), 256, [0,256])\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2.2 Plot Histogram Using Matplotlib + OpenCV [OPTION 2]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "# convert ot grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# find histogram for grayscale image\n",
    "histr = cv2.calcHist([gray],[0],None,[256],[0,256])\n",
    "\n",
    "# plot result\n",
    "plt.plot(histr)\n",
    "plt.xlim([0,256])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Or, Plot all channel histogram\n",
    "\n",
    "# load image\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "# loop to all channel\n",
    "color = ('b','g','r') # color for each channel\n",
    "for i,col in enumerate(color):\n",
    "    # find histogram in channel i-th\n",
    "    histr = cv2.calcHist([img],[i],None,[256],[0,256])\n",
    "\n",
    "    # plot histogram for each channel\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "## 2.3 Histogram Equalization\n",
    "- Consider an image whose pixel values are confined to some specific range of values only. \n",
    "- For eg, brighter image will have all pixels confined to high values. \n",
    "- But a good image will have pixels from all regions of the image. \n",
    "So you need to stretch this histogram to either ends (as given in below image, from wikipedia) and that is what **Histogram Equalization** does (in simple words). \n",
    "- This normally improves the contrast of the image. <br><br>\n",
    "    ![](resource/histogram_equalization.png)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread('Unequalized_Hawkes_Bay_NZ.jpg')\n",
    "\n",
    "# convert ot grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# find histogram from grayscale image\n",
    "hist = cv2.calcHist([gray],[0],None,[256],[0,256])\n",
    "\n",
    "# calculate cummulative histogram data\n",
    "cdf = hist.cumsum() # cumulative distribution functions (CDF) of histogram value\n",
    "cdf_normalized = cdf * float(hist.max()) / cdf.max() # normalize CDF data\n",
    "\n",
    "\n",
    "# show result\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "# plot histogram (red) & cumulative distribution functions data (blue)\n",
    "plt.plot(cdf_normalized, color = 'b')\n",
    "plt.plot(hist, color = 'r')\n",
    "plt.xlim([0,256])\n",
    "plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- You can see histogram lies in brighter region. \n",
    "- We need the full spectrum (strech histogram into minimum and maximum value). \n",
    "- For that, we need a transformation function which maps the input pixels in brighter region to output pixels in full region. \n",
    "- That is what histogram equalization does.<br><br><br>\n",
    "\n",
    "___\n",
    "## Histogram Equalization using Numpy\n",
    "- Now, we need to strech histogram into minimum and maximum value.\n",
    "- Find the minimum histogram value (excluding 0) and apply the histogram equalization equation. \n",
    "- To do this mask all 0 value in CDF data using numpy `np.ma.masked_equal()`, who will be mask array with a given value."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Example how numpy mask array work\n",
    "\n",
    "a = np.arange(4)\n",
    "print(a)\n",
    "print(list(np.ma.masked_equal(a, 1)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Strech Histogram using simple normalization formula<br><br>\n",
    "$X = (x - min)/(max - min)$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# apply mask to zero value\n",
    "cdf_m = np.ma.masked_equal(cdf,0)\n",
    "\n",
    "# streach CDF to full range histogram (min - max)\n",
    "cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
    "\n",
    "# apply unmask and set to zero\n",
    "cdf = np.ma.filled(cdf_m,0).astype(np.uint8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cdf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cdf[145]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gray"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# convert each pixel value in grayscale image into cdf value at the same index pixel\n",
    "gray2 = cdf[gray]\n",
    "\n",
    "# find histogram from grayscale 2 image\n",
    "hist = cv2.calcHist([gray2],[0],None,[256],[0,256])\n",
    "\n",
    "# calculate cummulative histogram data\n",
    "cdf = hist.cumsum() # cumulative distribution functions (CDF) of histogram value\n",
    "cdf_normalized = cdf * float(hist.max()) / cdf.max() # normalize CDF data\n",
    "\n",
    "# show result\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(gray2, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(cdf_normalized, color = 'b')\n",
    "plt.plot(hist, color = 'r')\n",
    "plt.xlim([0,256])\n",
    "plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Histograms Equalization in OpenCV\n",
    "- OpenCV has a function to do this, `cv2.equalizeHist(src)`. \n",
    "- Its input is just grayscale image and output is our histogram equalized image."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread('tsukuba_l.png')\n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# apply OpenCV Histogram Equalization to grayscale image\n",
    "equ = cv2.equalizeHist(gray)\n",
    "\n",
    "# find histogram from equalized image\n",
    "hist = cv2.calcHist([equ],[0],None,[256],[0,256])\n",
    "\n",
    "\n",
    "# show result\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "plt.title(\"Original\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(equ, cmap=\"gray\")\n",
    "plt.title(\"Equalized\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(hist, color = 'r')\n",
    "plt.xlim([0,256])\n",
    "plt.legend(('histogram'), loc = 'upper left')\n",
    "plt.title(\"Equalized Histogram Plot\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "## 2.4 Histogram Equalization using CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "- The first histogram equalization we just saw, considers the **global contrast** of the image. \n",
    "- In many cases, it is not a good idea. \n",
    "- For example, result after global histogram equalization for `tsukuba_l.png.png`, <br>\n",
    "![](resource/global_contrast.png)<br><br>\n",
    "- It is true that the **background contrast has improved** after histogram equalization. \n",
    "- But compare the face of statue in both images. \n",
    "- We lost most of the information there due to over-brightness. \n",
    "- It is because its histogram is not confined to a particular region as we saw in previous cases.<br><br><br>\n",
    "- So to solve this problem, **adaptive histogram equalization** (CLAHE) is used. \n",
    "- In this, image is divided into **small blocks** called **\"tiles\"** (tileSize is 8x8 by default in OpenCV). \n",
    "- Then each of these blocks are histogram equalized as usual. \n",
    "- So in a small area, histogram would confine to a small region (unless there is noise).\n",
    "<br><br>\n",
    "- Create object using `cv2.createCLAHE(clipLimit , tileGridSize)`,\n",
    "- Where : \n",
    "    - `clipLimit` : Threshold for contrast limiting.\n",
    "    - `tileGridSize` : Size of grid for histogram equalization. Input image will be divided into equally sized rectangular tiles. tileGridSize defines the number of tiles in row and column.\n",
    "- Then use method `.apply(img)`, to generate equalized image,"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image\n",
    "img = cv2.imread('tsukuba_l.png')\n",
    "\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# create a CLAHE object (Arguments are optional).\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "# apply CLAHE\n",
    "cl = clahe.apply(gray)\n",
    "\n",
    "\n",
    "# find histogram from clahe equalized image\n",
    "hist = cv2.calcHist([cl],[0],None,[256],[0,256])\n",
    "\n",
    "# calculate cummulative histogram data\n",
    "cdf = hist.cumsum() # cumulative distribution functions (CDF) of histogram value\n",
    "cdf_normalized = cdf * float(hist.max()) / cdf.max() # normalize CDF data\n",
    "\n",
    "\n",
    "# show result\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "plt.title(\"Original\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(cl, cmap=\"gray\")\n",
    "plt.title(\"CLAHE Equalized\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(cdf_normalized, color = 'b')\n",
    "plt.plot(hist, color = 'r')\n",
    "plt.xlim([0,256])\n",
    "plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "plt.title(\"CLAHE Equalized Histogram Plot\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____\n",
    "## 2.5 CUDA Implementation\n",
    "### CUDA Find Histogram \n",
    "- Using method `cv2.cuda.calcHist(src, hist)`\n",
    "- Where : \n",
    "    - `src` : source image, `CV_8UC1`.\n",
    "    - `hist` : Destination histogram with one row, `256` columns, and the `CV_32SC1` type.\n",
    "### CUDA Equalize Histogram \n",
    "- Using Method `cv2.cuda.equalizeHist(src, dst)`,\n",
    "- Where : \n",
    "    - `src` : Source image with `CV_8UC1` type.\n",
    "    - `dst` : Destination image.\n",
    "### CUDA CLAHE\n",
    "- Using Method `cv2.cuda.createCLAHE(clipLimit, tileGridSize)`\n",
    "- Where : \n",
    "    - `clipLimit` : Threshold for contrast limiting.\n",
    "    - `tileGridSize` : Size of grid for histogram equalization. Input image will be divided into equally sized rectangular tiles. tileGridSize defines the number of tiles in row and column.\n",
    "- Then use method `.apply(src, Stream, dst)` to find equalized image,\n",
    "- Where : \n",
    "    - `Stream` : is CUDA Stream, if not set : `cv2.cuda_Stream.Null()`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load image in Host memory\n",
    "img = cv2.imread(\"tsukuba_l.png\")\n",
    "h, w, c = img.shape\n",
    "\n",
    "# GPU memory initialization\n",
    "img_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "img_GpuMat.create((w, h), cv2.CV_8UC3) # cv2.CV_8UC3 -> 8bit image 3 channel\n",
    "gray_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "gray_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "equ_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "equ_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "clahe_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "clahe_GpuMat.create((w, h), cv2.CV_8UC1) # cv2.CV_8UC1 -> 8bit image 1 channel\n",
    "hist_equ_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "hist_equ_GpuMat.create((1, 256), cv2.CV_32SC1) # cv2.CV_32SC1\n",
    "hist_clahe_GpuMat = cv2.cuda_GpuMat() # Create GpuMat object \n",
    "hist_clahe_GpuMat.create((1, 256), cv2.CV_32SC1) # cv2.CV_32SC1\n",
    "\n",
    "\n",
    "# Create CLAHE Object\n",
    "CLAHE = cv2.cuda.createCLAHE(clipLimit=5.0, tileGridSize=(8,8))\n",
    "\n",
    "# upload to GPU memory as 32 bit float matrix\n",
    "img_GpuMat.upload(img)\n",
    "\n",
    "# convert to grayscale using CUDA\n",
    "cv2.cuda.cvtColor(img_GpuMat, cv2.COLOR_BGR2GRAY, gray_GpuMat)\n",
    "\n",
    "\n",
    "# apply CUDA Equalize Histogram & CLAHE\n",
    "cv2.cuda.equalizeHist(gray_GpuMat, equ_GpuMat)\n",
    "CLAHE.apply(gray_GpuMat, cv2.cuda_Stream.Null(), clahe_GpuMat)\n",
    "\n",
    "# CUDA find histogram\n",
    "cv2.cuda.calcHist(equ_GpuMat, hist_equ_GpuMat)\n",
    "cv2.cuda.calcHist(clahe_GpuMat, hist_clahe_GpuMat)\n",
    "\n",
    "# download to host memory\n",
    "hist_cl = hist_clahe_GpuMat.download()\n",
    "hist_equ = hist_equ_GpuMat.download() \n",
    "cl = clahe_GpuMat.download()\n",
    "equ = equ_GpuMat.download() \n",
    "\n",
    "# show result\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "plt.title(\"Original\")\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(cl, cmap=\"gray\")\n",
    "plt.title(\"CLAHE Equalized\")\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "plt.plot(hist_cl, color = 'r')\n",
    "plt.xlim([0,256])\n",
    "plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "plt.title(\"CLAHE Equalized Histogram Plot\")\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "plt.title(\"Original\")\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(equ, cmap=\"gray\")\n",
    "plt.title(\"Equalized\")\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "plt.plot(hist_equ, color = 'r')\n",
    "plt.xlim([0,256])\n",
    "plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "plt.title(\"Equalized Histogram Plot\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Source : \n",
    "- [https://docs.opencv.org/4.5.2/de/dbc/tutorial_py_fourier_transform.html](https://docs.opencv.org/4.5.2/de/dbc/tutorial_py_fourier_transform.html)\n",
    "- [https://docs.opencv.org/4.5.2/d2/de8/group__core__array.html#gadd6cf9baf2b8b704a11b5f04aaf4f39d](https://docs.opencv.org/4.5.2/d2/de8/group__core__array.html#gadd6cf9baf2b8b704a11b5f04aaf4f39d)\n",
    "- [https://docs.opencv.org/4.5.2/d2/de8/group__core__array.html#gaf4dde112b483b38175621befedda1f1c](https://docs.opencv.org/4.5.2/d2/de8/group__core__array.html#gaf4dde112b483b38175621befedda1f1c)\n",
    "- [https://en.wikipedia.org/wiki/Histogram_equalization](https://en.wikipedia.org/wiki/Histogram_equalization)\n",
    "- [https://docs.opencv.org/4.5.2/d5/daf/tutorial_py_histogram_equalization.html](https://docs.opencv.org/4.5.2/d5/daf/tutorial_py_histogram_equalization.html)\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}